#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RYU å®‰å…¨æ§åˆ¶å™¨ï¼ˆé»‘ç™½åå•â†’å­¤ç«‹æ£®æ—â†’LLMé™é€Ÿâ†’ç®¡ç†å‘˜å¤„ç½®ï¼‰
1. é»‘åå•ï¼šç›´æ¥ä¸¢å¼ƒ
2. ç™½åå•ï¼šç›´æ¥æ”¾è¡Œï¼Œä¸”**æ°¸ä¸é™é€Ÿ**
3. å­¤ç«‹æ£®æ—å¼‚å¸¸ â†’ è°ƒç”¨ LLM
   Â· LLM è¿”å›åˆæ³•ä¸” confidenceâ‰¥0.5 â†’ ç«‹å³é™é€Ÿï¼ˆ5 minï¼‰
   Â· LLM è¿”å›éæ³• â†’ åªå‘Šè­¦ã€ä¸é™é€Ÿ
4. ç®¡ç†å‘˜åç»­ï¼š
   Â· ç¡®è®¤æ”»å‡»ï¼šai: åŠ é»‘ x.x.x.x
   Â· è¯¯æŠ¥ï¼šai: è§£é™¤é™é€Ÿ x.x.x.xï¼ˆåŒæ—¶å¢é‡å­¦ä¹ ï¼‰
5. é™é€ŸçŠ¶æ€æŒä¹…åŒ–ï¼Œé‡å¯ä¸ä¸¢
6. åŸå§‹æµé‡å®æ—¶å†™åº“ï¼ˆREALTIME_INSERT = Trueï¼‰
"""
import time
import pymysql
import csv, io
import matplotlib.pyplot as plt
from io import BytesIO
import base64
from collections import deque
import threading
from weasyprint import HTML
import tempfile
import ipaddress
ANOMALY_QUEUE = deque()          # å†…å­˜é˜Ÿåˆ—
QUEUE_LOCK  = threading.Lock()   # ä¿æŠ¤é”
import geoip2.database
GEO_DB = '/usr/share/GeoIP/GeoLite2-City.mmdb' 

import eventlet

eventlet.monkey_patch(socket=True, select=True, thread=True)

import json, os, time, pymysql, requests, pickle, math, re, numpy as np
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from sklearn.ensemble import IsolationForest
from ryu.base import app_manager
from ryu.controller import ofp_event
from ryu.controller.handler import CONFIG_DISPATCHER, MAIN_DISPATCHER, set_ev_cls
from ryu.lib import hub
from ryu.lib.packet import packet, ethernet, ipv4, icmp, tcp, udp, arp, ether_types
from ryu.ofproto import ofproto_v1_3
from ryu.app.wsgi import WSGIApplication, ControllerBase, route
from ryu.base import app_manager as ry_app_mgr
from ryu.app.wsgi import Response

# -------------------------- é…ç½® -----------------------------
DB_CONFIG = {
    'host': '192.168.44.1', 'user': 'root', 'password': 'yyr0218...',
    'db': 'network_management', 'charset': 'utf8mb4'
}
# ---------- é™é€Ÿæ¡£ä½ ----------
RATE_LIMIT_OPTIONS = {
    "ä½é€Ÿ": 256,
    "ä¸­é€Ÿ": 1024,
    "é«˜é€Ÿ": 2048,
    "è‡ªå®šä¹‰": None
}

MODEL_PATH = 'isolation_forest_model.pkl'
ANOMALY_LOG = 'anomaly_traffic.log'
SUMMARY_JSON = 'anomaly_summary.json'
LOG_MAX_SIZE = 10 * 1024 * 1024
WHITE_FILE = 'white_list.json'
BLACK_FILE = 'black_list.json'

RATE_LIMIT_DURATION = 300  # é™é€Ÿ 5 åˆ†é’Ÿ
REALTIME_INSERT = False  # å…³é—­å®æ—¶å†™åº“ï¼Œæ”¹ä¸ºæ‰¹é‡å†™åº“ï¼ˆå‡å°‘I/Oï¼‰

# æ”»å‡»é˜ˆå€¼ï¼ˆICMP è°ƒé«˜åˆ° 500ï¼Œé¿å…æ­£å¸¸ ping è¯¯åˆ¤ï¼‰
# ---------- æ”»å‡»æ£€æµ‹é˜ˆå€¼ ----------
THRESH = {
    'arp': {'mac_change': 1, 'spoof_cnt': 1},   # ARPæ¬ºéª—ï¼šMACå˜åŒ–æ£€æµ‹
    'udp': {'flood_rate': 200},                  # UDP Floodï¼š200 pps
    'icmp': {'flood_rate': 2000},                # âœ… ICMP Floodï¼š2000 ppsï¼ˆé¿å…pingallè¯¯æŠ¥ï¼‰
    'syn': {'ratio': 0.8, 'rate': 200, 'min_tcp': 20},  # SYN Floodï¼š200 pps
    'botnet': {'dst_ip_cnt': 10, 'port_entropy': 3.0, 'pkt_rate': 2000}  # åƒµå°¸ç½‘ç»œ
}





ISOLATION_PARAM = dict(n_estimators=100, max_samples='auto', contamination=0.1, random_state=42, n_jobs=-1)
OLLAMA_URL = 'http://192.168.44.1:11435/api/generate'
MEMORY_TURNS = 20

# ç©æ³•1: AIæ‘˜è¦ & ç©æ³•2: å£è¯­è§„åˆ™ & ç©æ³•4: å‘¨æŠ¥
AI_SUMMARY_ENABLED = True
CUSTOM_RULES = {}  # å­˜å‚¨å£è¯­è§„åˆ™ï¼Œå¦‚ {'udp_threshold': 100}
WEEKLY_REPORT_DATA = []  # å­˜å‚¨å‘¨æŠ¥æ•°æ®


# -------------------------------------------------------------


class SDNSecurityController(app_manager.RyuApp):
    OFP_VERSIONS = [ofproto_v1_3.OFP_VERSION]
    _CONTEXTS = {'wsgi': WSGIApplication}

    def __init__(self, *args, **kwargs):
        super(SDNSecurityController, self).__init__(*args, **kwargs)
        self.mac_to_port, self.arp_table = {}, {}
        self.datapaths = {}
        self.db_conn = None
        self.flow_cache = []
        self.anomaly_cache = []
        self.limited_ips = {}
        self.switch_flow_stats = {}  # ç¼“å­˜æ¯ä¸ªäº¤æ¢æœºçš„æµè¡¨: {dpid: [flow_stats]}
        self.anomaly_counter = defaultdict(int)
                # Land Attack æ ‡è®°
        self.land_attack_seen = set()   # å·²åŠ é»‘çš„ IPï¼Œé¿å…é‡å¤æ—¥å¿—
        self.scan_tracker = defaultdict(lambda: {'ports': set(), 'last': time.time()})



        # æ»‘åŠ¨äº‹ä»¶çª—å£ï¼š{ (ip,æ”»å‡»ç±»å‹) : æœ€åæ—¶é—´æˆ³ }
        # æ»‘åŠ¨äº‹ä»¶çª—å£ï¼š{ (ip,æ”»å‡»ç±»å‹) : æœ€åæ—¶é—´æˆ³ }
        self.SLIDE_WINDOW = {}
        self.WINDOW_SEC = 30          # 30 ç§’çª—å£ï¼Œå¯æ”¹
        
        self.ssh_brute = defaultdict(lambda: {'conns': 0, 'last': time.time()})

        # âœ… è®¾å¤‡å¼‚å¸¸è¿½è¸ªå™¨
        self.port_flap_tracker = defaultdict(list)  # ç«¯å£æŠ–åŠ¨è¿½è¸ª: {(dpid, port): [æ—¶é—´æˆ³åˆ—è¡¨]}
        self.mac_port_map = {}  # MAC-ç«¯å£æ˜ å°„: {mac: (dpid, port)}
        self.ip_subnet_checked = set()  # å·²æ£€æŸ¥è¿‡çš„IPï¼ˆé¿å…é‡å¤æŠ¥è­¦ï¼‰
        self.VALID_SUBNET = '192.168.1.0/24'  # åˆæ³•IPç½‘æ®µ

        # è®­ç»ƒæœŸæ­£å¸¸é€Ÿç‡å‡å€¼ï¼ˆä¿åº•å€¼ï¼‰
        self.normal_tcp_rate = defaultdict(lambda: 200)
        self.normal_arp_rate = defaultdict(lambda: 50)
        self.port_stats = defaultdict(dict)   # ç«¯å£åç§°æ˜ å°„



        self.src_dst_counter = defaultdict(set)
        self.src_port_counter = defaultdict(set)
        self.arp_stats = defaultdict(lambda: {'count': 0, 'last_time': time.time(), 'macs': set(), 'spoof_count': 0})
        self.tcp_flag_stats = defaultdict(lambda: {'syn': 0, 'total': 0, 'last': time.time()})
        self.udp_stats = defaultdict(lambda: {'count': 0, 'last': time.time()})
        self.icmp_stats = defaultdict(lambda: {'count': 0, 'last': time.time()})
        self.raw_pkt_counter = defaultdict(int)
        self.raw_last_time = defaultdict(float)

        self.flow_features_with_info = []
        self.isolation_model = None
        self.is_training = False
        self.training_seconds = 300

        # ACL - å…ˆä»JSONæ–‡ä»¶åŠ è½½ï¼Œå†ä»æ•°æ®åº“è¦†ç›–ï¼ˆæ•°æ®åº“ä¼˜å…ˆï¼‰
        self.white = self._load_acl_file(WHITE_FILE)
        self.black = self._load_acl_file(BLACK_FILE)

        # Web
        wsgi = kwargs['wsgi']
        wsgi.register(ChatController, {'ctrl': self})

        # åå°
        self._init_anomaly_files()
        self._restore_model()
        hub.spawn(self._db_loop)
        hub.spawn(self._stats_loop)
        hub.spawn(self._detect_loop)
        hub.spawn(self._cleanup_loop)
        hub.spawn(self._reset_loop)
        hub.spawn(self._summarize_loop)
        hub.spawn(self._db_writer_loop)
        hub.spawn(self._auto_close_attack_sessions_loop)  # âœ… æ–°å¢ï¼šè‡ªåŠ¨å…³é—­è¿‡æœŸæ”»å‡»ä¼šè¯
        hub.spawn(self._device_anomaly_detection_loop)  # âœ… æ–°å¢ï¼šè®¾å¤‡å¼‚å¸¸æ£€æµ‹å®šæ—¶å™¨
        if REALTIME_INSERT:
            hub.spawn(self._realtime_insert_loop)  ### å®æ—¶å†™åº“
        self.logger.info("âœ… SDN å®‰å…¨æ§åˆ¶å™¨ï¼ˆLLM é™é€Ÿâ†’ç®¡ç†å‘˜å¤„ç½®ï¼‰åˆå§‹åŒ–å®Œæˆ")
        self._restore_rate_limit_from_db()
        self._restore_acl_from_db()  # ä»æ•°æ®åº“æ¢å¤é»‘ç™½åå•
        
        # ğŸ¯ å»¶è¿Ÿ3ç§’åæ›´æ–°æ‰€æœ‰äº¤æ¢æœºçš„é»˜è®¤è§„åˆ™ï¼ˆç¡®ä¿äº¤æ¢æœºå·²è¿æ¥ï¼‰
        hub.spawn_after(3, self.update_all_table_miss_rules)

    # ---------------- å·¥å…· ----------------
    def _load_acl_file(self, path):
        return json.load(open(path)) if os.path.exists(path) else {}

    def _save_acl_file(self, acl, path):
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(acl, f, ensure_ascii=False)

    def _init_anomaly_files(self):
        for f, desc in [(ANOMALY_LOG, "å¼‚å¸¸æ—¥å¿—"), (SUMMARY_JSON, "æ±‡æ€»æ–‡ä»¶")]:
            if not os.path.exists(f):
                with open(f, 'w', encoding='utf-8') as wf:
                    json.dump({"desc": desc, "create": time.strftime('%Y-%m-%d %H:%M:%S')}, wf, ensure_ascii=False)
                    wf.write('\n')

    def get_limit_list(self):
        """è¿”å›å½“å‰é™é€Ÿåˆ—è¡¨ï¼ˆå«åŸå› ã€é€Ÿç‡ã€å¼€å§‹æ—¶é—´ã€å‰©ä½™ç§’æ•°ï¼‰"""
        now = time.time()
        conn = None
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                sql = """
                    SELECT src_ip, kbps, reason, created_at, expire_at
                    FROM rate_limit_active
                    WHERE expire_at > NOW()
                    ORDER BY created_at DESC
                """
                cur.execute(sql)
                rows = cur.fetchall()
        except Exception as e:
            self.logger.error(f"get_limit_list æŸ¥è¯¢å¤±è´¥: {e}")
            rows = []
        finally:
            if conn: conn.close()

        data = []
        for r in rows:
            # é˜²å¾¡å¼ï¼šexpire_at å¯èƒ½æ˜¯ datetime ä¹Ÿå¯èƒ½æ˜¯ int
            expire_val = r[4]
            if hasattr(expire_val, 'timestamp'):   # datetime
                expire_ts = expire_val.timestamp()
            else:                                    # ä¸‡ä¸€å­˜æˆ int
                expire_ts = int(expire_val)
            ttl = max(0, int(expire_ts - now))

            data.append({
                'ip': r[0],
                'kbps': int(r[1]),
                'reason': r[2],
                'start_time': r[3].strftime('%Y-%m-%d %H:%M:%S'),
                'ttl_left': ttl
            })
        return data




    def _restore_model(self):
        if os.path.exists(MODEL_PATH):
            try:
                with open(MODEL_PATH, 'rb') as f:
                    data = pickle.load(f)
                    self.isolation_model = data['model']
                    ISOLATION_PARAM['contamination'] = data.get('contamination', 0.1)
                self.logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                self.is_training = True
                hub.spawn(self._train_task)
        else:
            self.is_training = True
            hub.spawn(self._train_task)
    
    # ---------------- å¯åŠ¨æ—¶æŠŠæ•°æ®åº“ä¸­æœªè¿‡æœŸçš„é™é€Ÿé‡æ–°è½½å…¥å†…å­˜ + é‡æ–°ä¸‹å‘æµè¡¨ ----------------
    def _restore_acl_from_db(self):
        """
        é‡å¯æ§åˆ¶å™¨åï¼Œä»æ•°æ®åº“æ¢å¤é»‘ç™½åå•åˆ°å†…å­˜ï¼ˆæ•°æ®åº“ä¼˜å…ˆäºJSONæ–‡ä»¶ï¼‰
        """
        conn = None
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                # æŸ¥è¯¢æ‰€æœ‰ACLæ¡ç›®
                sql = "SELECT ip, list_type FROM acl_entries"
                cur.execute(sql)
                rows = cur.fetchall()
                
                if not rows:
                    self.logger.info("âœ… æ•°æ®åº“ä¸­æ— ACLè®°å½•ï¼Œä½¿ç”¨JSONæ–‡ä»¶æ•°æ®")
                    return
                
                # æ¸…ç©ºå†…å­˜ä¸­çš„ACLï¼ˆæ•°æ®åº“ä¼˜å…ˆï¼‰
                self.white.clear()
                self.black.clear()
                
                white_count = 0
                black_count = 0
                
                for ip, list_type in rows:
                    if list_type == 'white':
                        self.white[ip] = -1  # -1 è¡¨ç¤ºæ°¸ä¹…
                        white_count += 1
                    elif list_type == 'black':
                        self.black[ip] = -1  # -1 è¡¨ç¤ºæ°¸ä¹…
                        black_count += 1
                
                self.logger.info(f"âœ… ä»æ•°æ®åº“æ¢å¤ACL: ç™½åå• {white_count} ä¸ª, é»‘åå• {black_count} ä¸ª")
                
                # æ›´æ–°JSONæ–‡ä»¶ï¼Œä¿æŒåŒæ­¥
                self._save_acl_file(self.white, WHITE_FILE)
                self._save_acl_file(self.black, BLACK_FILE)
                
        except Exception as e:
            self.logger.error(f"âŒ ä»æ•°æ®åº“æ¢å¤ACLå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        finally:
            if conn:
                conn.close()

    def _restore_rate_limit_from_db(self):
        """
        é‡å¯æ§åˆ¶å™¨åï¼ŒæŠŠ rate_limit_active è¡¨é‡Œæœªè¿‡æœŸçš„è®°å½•é‡æ–°è¯»å…¥å†…å­˜ï¼Œ
        å¹¶é‡æ–°ä¸‹å‘æµè¡¨é™é€Ÿè§„åˆ™ï¼ˆ5 min ç¡¬è¶…æ—¶ï¼‰ã€‚
        """
        conn = None
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                sql = """
                    SELECT src_ip, kbps, UNIX_TIMESTAMP(expire_at) AS expire_ts
                    FROM rate_limit_active
                    WHERE expire_at > NOW()
                """
                cur.execute(sql)
                rows = cur.fetchall()
                if not rows:
                    self.logger.info("âœ… æ•°æ®åº“ä¸­æ— æœªè¿‡æœŸé™é€Ÿè®°å½•ï¼Œè·³è¿‡æ¢å¤")
                    return

                now = time.time()
                restored = 0
                for ip, kbps, expire_ts in rows:
                    remain = max(1, int(expire_ts - now))          # è‡³å°‘ 1 ç§’
                    self.limited_ips[str(ip)] = float(expire_ts)   # å†™å›å†…å­˜

                    # é‡æ–°ä¸‹å‘æµè¡¨ï¼ˆç›´æ¥æŠ„ _apply_rate_limit çš„é˜Ÿåˆ—é€»è¾‘ï¼‰
                    if kbps <= 256:
                        q = 1
                    elif kbps <= 1024:
                        q = 2
                    elif kbps <= 2048:
                        q = 3
                    else:
                        q = 3
                    for dp in self.datapaths.values():
                        ofp, ps = dp.ofproto, dp.ofproto_parser
                        match = ps.OFPMatch(eth_type=ether_types.ETH_TYPE_IP,
                                            ipv4_src=str(ip))
                        acts = [ps.OFPActionSetQueue(queue_id=q),
                                ps.OFPActionOutput(ofp.OFPP_NORMAL)]
                        # âœ… ä¿®å¤ï¼šæ·»åŠ idle=0ï¼Œé˜²æ­¢æµè¡¨å› ç©ºé—²è€Œè¢«åˆ é™¤
                        self._add_flow(dp, 50, match, acts, idle=0, hard=remain)
                    restored += 1
                    self.logger.warning(
                        f"ğŸ”’ æ¢å¤é™é€Ÿ: ip={ip}, kbps={kbps}, remain={remain}s, queue={q}")
                self.logger.info(f"âœ… å…±æ¢å¤ {restored} æ¡é™é€Ÿè®°å½•")
        except Exception as e:
            self.logger.error(f"âŒ æ¢å¤é™é€Ÿå¤±è´¥: {e}")
        finally:
            if conn:
                conn.close()


    # ---------------- æ•°æ®åº“ ----------------
    def _db_loop(self):
        while True:
            try:
                self.db_conn = pymysql.connect(**DB_CONFIG)
                self.logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
                return
            except Exception as e:
                self.logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}ï¼Œ10s åé‡è¯•")
                hub.sleep(10)

    def get_db_conn(self):
        try:
            if not hasattr(self, 'db_conn') or not self.db_conn or self.db_conn._closed:
                self._db_loop()
            # æµ‹è¯•è¿æ¥æ˜¯å¦æœ‰æ•ˆ
            self.db_conn.ping(reconnect=True)
            return self.db_conn
        except Exception as e:
            self.logger.error(f"æ•°æ®åº“è¿æ¥é”™è¯¯: {e}")
            self._db_loop()
            return self.db_conn

    # ---------------- ACLï¼ˆåŒæ­¥å…¥åº“ï¼‰ ----------------
    def acl_check(self, ip: str) -> str:
        now = time.time()
        if ip in self.white:
            if self.white[ip] == -1 or self.white[ip] > now:
                return 'white'
            else:
                self.white.pop(ip, None)
                self._save_acl_file(self.white, WHITE_FILE)
                self._del_acl_from_db(ip, 'white')
        if ip in self.black:
            if self.black[ip] == -1 or self.black[ip] > now:
                return 'black'
            else:
                self.black.pop(ip, None)
                self._save_acl_file(self.black, BLACK_FILE)
                self._del_acl_from_db(ip, 'black')
        return None

    def get_acl_lists(self):
        now = time.time()
        white_list, black_list = [], []
        for ip, exp in self.white.items():
            status = "æ°¸ä¹…" if exp == -1 else "æœ‰æ•ˆ" if exp > now else "å·²è¿‡æœŸ"
            expire_str = "æ°¸ä¹…" if exp == -1 else time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(exp))
            white_list.append({"ip": ip, "expire_time": exp, "expire_str": expire_str, "status": status})
        for ip, exp in self.black.items():
            status = "æ°¸ä¹…" if exp == -1 else "æœ‰æ•ˆ" if exp > now else "å·²è¿‡æœŸ"
            expire_str = "æ°¸ä¹…" if exp == -1 else time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(exp))
            black_list.append({"ip": ip, "expire_time": exp, "expire_str": expire_str, "status": status})
        return {"white_list": white_list, "black_list": black_list, "white_count": len(white_list),
                "black_count": len(black_list)}

    def _add_acl_to_db(self, ip: str, list_type: str):
        """æ·»åŠ ACLåˆ°æ•°æ®åº“ï¼ˆä½¿ç”¨ç‹¬ç«‹è¿æ¥ï¼‰"""
        conn = None
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                sql = """INSERT INTO acl_entries (ip, list_type)
                         VALUES (%s, %s) ON DUPLICATE KEY 
                         UPDATE updated_at = CURRENT_TIMESTAMP"""
                cur.execute(sql, (ip, list_type))
                conn.commit()
                self.logger.info(f"âœ… ACLå…¥åº“æˆåŠŸ: {ip} -> {list_type}")
        except Exception as e:
            self.logger.error(f"âŒ ACLå…¥åº“å¤±è´¥: {e}")
            if conn:
                conn.rollback()
            import traceback
            traceback.print_exc()
        finally:
            if conn:
                conn.close()

    def _del_acl_from_db(self, ip: str, list_type: str):
        """ä»æ•°æ®åº“åˆ é™¤ACLï¼ˆä½¿ç”¨ç‹¬ç«‹è¿æ¥ï¼‰"""
        conn = None
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                sql = "DELETE FROM acl_entries WHERE ip=%s AND list_type=%s"
                affected = cur.execute(sql, (ip, list_type))
                conn.commit()
                self.logger.info(f"âœ… ACLå‡ºåº“æˆåŠŸ: {ip} -> {list_type} (åˆ é™¤äº†{affected}è¡Œ)")
                return affected > 0
        except Exception as e:
            self.logger.error(f"âŒ ACLå‡ºåº“å¤±è´¥: {e}")
            if conn:
                conn.rollback()
            import traceback
            traceback.print_exc()
            return False
        finally:
            if conn:
                conn.close()

    def acl_add_white(self, ip: str, ttl: int = -1):
        self.white[ip] = -1
        self._save_acl_file(self.white, WHITE_FILE)
        self._add_acl_to_db(ip, 'white')

    def acl_add_black(self, ip: str, ttl: int = -1, operator: str = 'system', reason: str = 'æ‰‹åŠ¨åŠ é»‘'):
        ip = str(ip)
        # 1. è‹¥å½“å‰åœ¨é™é€Ÿï¼Œå…ˆå¸æ‰
        if ip in self.limited_ips:
            self._release_rate_limit(ip, operator='system', reason='è½¬é»‘åå•è‡ªåŠ¨è§£é™¤')
        # 2. å†™å†…å­˜ + æ–‡ä»¶ + åº“
        self.black[ip] = ttl
        self._save_acl_file(self.black, BLACK_FILE)
        self._add_acl_to_db(ip, 'black')
        self.logger.warning(f"ğŸš« {ip} å·²åŠ å…¥é»‘åå•ï¼ˆé™é€Ÿå·²è‡ªåŠ¨è§£é™¤ï¼‰åŸå› ï¼š{reason}")
        
        # 3. âœ… å¦‚æœæ˜¯ç®¡ç†å‘˜æ“ä½œï¼Œç›´æ¥INSERTæ–°è®°å½•åˆ°attack_sessions
        if operator == 'admin':
            try:
                conn = pymysql.connect(**DB_CONFIG, autocommit=False)
                with conn.cursor() as cur:
                    # ç›´æ¥æ’å…¥æ–°è®°å½•ï¼ˆæ¯æ¬¡ç®¡ç†å‘˜æ“ä½œéƒ½æ˜¯ç‹¬ç«‹çš„å†³ç­–ï¼‰
                    # âœ… ç®¡ç†å‘˜åŠ é»‘ï¼šstatus='handled', is_active=0ï¼ˆå·²ç»“æŸï¼‰
                    cur.execute("""
                        INSERT INTO attack_sessions (
                            src_ip, anomaly_type, packet_count, 
                            start_time, last_packet_time, end_time, duration_seconds,
                            is_active, status, handled_by, handled_at, handle_action
                        ) VALUES (
                            %s, %s, 1, 
                            NOW(), NOW(), NOW(), 0,
                            0, 'handled', %s, NOW(), 'blacklist'
                        )
                    """, (ip, reason, operator))
                    conn.commit()
                    self.logger.info(f"âœ… [ç®¡ç†å‘˜æ“ä½œ] å·²å°† {ip} åŠ å…¥é»‘åå•å¹¶è®°å½•åˆ°attack_sessionsï¼ˆåŸå› ï¼š{reason}ï¼‰")
            except Exception as e:
                self.logger.error(f"âš ï¸ é»‘åå•å·²æ·»åŠ ä½†attack_sessionsè®°å½•å¤±è´¥: {e}")
                if conn:
                    conn.rollback()
            finally:
                if conn:
                    conn.close()

    def acl_del_white(self, ip: str):
        """ä»ç™½åå•åˆ é™¤IP"""
        # 1. ä»å†…å­˜åˆ é™¤
        if ip in self.white:
            self.white.pop(ip, None)
            self._save_acl_file(self.white, WHITE_FILE)
            self.logger.info(f"âœ… ä»ç™½åå•å†…å­˜ä¸­åˆ é™¤: {ip}")
        else:
            self.logger.warning(f"âš ï¸ IPä¸åœ¨ç™½åå•å†…å­˜ä¸­: {ip}")
        
        # 2. ä»æ•°æ®åº“åˆ é™¤
        db_success = self._del_acl_from_db(ip, 'white')
        
        if db_success:
            self.logger.info(f"âœ… ç™½åå•åˆ é™¤å®Œæˆ: {ip}")
            return True
        else:
            self.logger.warning(f"âš ï¸ æ•°æ®åº“ä¸­æœªæ‰¾åˆ°è¯¥IPæˆ–åˆ é™¤å¤±è´¥: {ip}")
            return False

    def acl_del_black(self, ip: str):
        """ä»é»‘åå•åˆ é™¤IP"""
        # 1. ä»å†…å­˜åˆ é™¤
        if ip in self.black:
            self.black.pop(ip, None)
            self._save_acl_file(self.black, BLACK_FILE)
            self.logger.info(f"âœ… ä»é»‘åå•å†…å­˜ä¸­åˆ é™¤: {ip}")
        else:
            self.logger.warning(f"âš ï¸ IPä¸åœ¨é»‘åå•å†…å­˜ä¸­: {ip}")
        
        # 2. ä»æ•°æ®åº“åˆ é™¤
        db_success = self._del_acl_from_db(ip, 'black')
        
        if db_success:
            self.logger.info(f"âœ… é»‘åå•åˆ é™¤å®Œæˆ: {ip}")
            return True
        else:
            self.logger.warning(f"âš ï¸ æ•°æ®åº“ä¸­æœªæ‰¾åˆ°è¯¥IPæˆ–åˆ é™¤å¤±è´¥: {ip}")
            return False

    # ---------------- OpenFlow ----------------
    @set_ev_cls(ofp_event.EventOFPStateChange, [CONFIG_DISPATCHER, MAIN_DISPATCHER])
    def state_change(self, ev):
        dp = ev.datapath
        if ev.state == MAIN_DISPATCHER:
            if dp.id not in self.datapaths:
                self.datapaths[dp.id] = dp
                self._install_table_miss(dp)
                self.logger.info(f"âœ… äº¤æ¢æœº {dp.id} å·²è¿æ¥")
        else:
            # âœ… äº¤æ¢æœºæ–­è¿æ£€æµ‹
            if dp.id in self.datapaths:
                self.datapaths.pop(dp.id, None)
                self.logger.warning(f"âŒ äº¤æ¢æœº {dp.id} å·²æ–­å¼€")
                self._log_device_anomaly(
                    anomaly_type='äº¤æ¢æœºæ–­è¿',
                    device_type='switch',
                    device_id=str(dp.id),
                    description=f'äº¤æ¢æœº {dp.id} æ„å¤–æ–­å¼€è¿æ¥',
                    severity='high'
                )

    def _install_table_miss(self, dp):
        ofp, ps = dp.ofproto, dp.ofproto_parser
        match = ps.OFPMatch()
        # ğŸ¯ æ”¹å›CONTROLLERæ¨¡å¼ï¼Œä½†åœ¨packet_inå’Œ_extract_flowä¸­ä¸¥æ ¼è¿‡æ»¤
        actions = [ps.OFPActionOutput(ofp.OFPP_CONTROLLER, ofp.OFPCML_NO_BUFFER)]
        self._add_flow(dp, 0, match, actions, idle=0, hard=0)
        self.logger.info(f"ğŸ“Œ äº¤æ¢æœº {dp.id} å®‰è£… Table-Miss (CONTROLLERæ¨¡å¼ï¼Œä½†ä¸¥æ ¼è¿‡æ»¤)")

    def update_all_table_miss_rules(self):
        """ç«‹å³æ›´æ–°æ‰€æœ‰å·²è¿æ¥äº¤æ¢æœºçš„é»˜è®¤è§„åˆ™"""
        for dp_id, dp in self.datapaths.items():
            self.logger.info(f"ğŸ”„ æ­£åœ¨æ›´æ–°äº¤æ¢æœº {dp_id} çš„é»˜è®¤è§„åˆ™...")
            self._install_table_miss(dp)
        self.logger.info(f"âœ… å·²æ›´æ–° {len(self.datapaths)} ä¸ªäº¤æ¢æœºçš„é»˜è®¤è§„åˆ™")

    def _add_flow(self, dp, prio, match, acts, idle=60, hard=0):
        ofp, ps = dp.ofproto, dp.ofproto_parser
        inst = [ps.OFPInstructionActions(ofp.OFPIT_APPLY_ACTIONS, acts)]
        mod = ps.OFPFlowMod(datapath=dp, priority=prio, match=match, instructions=inst,
                            idle_timeout=idle, hard_timeout=hard)
        dp.send_msg(mod)
    

    @set_ev_cls(ofp_event.EventOFPPortStatsReply, MAIN_DISPATCHER)
    def port_stats_reply(self, ev):
        dpid = ev.msg.datapath.id
        
        for stat in ev.msg.body:
            # åªè®°å½•ç«¯å£åç§°ï¼Œä¸ç”¨äºæµé‡ç»Ÿè®¡ï¼ˆä½¿ç”¨æµè¡¨ç»Ÿè®¡ä»£æ›¿ï¼‰
            self.port_stats[dpid][stat.port_no] = f"port-{stat.port_no}"


    # ---------------- Packet-In & åè®®è§£æ ----------------
    @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER)
    def packet_in(self, ev):
        msg = ev.msg
        dp, ofp, ps = msg.datapath, msg.datapath.ofproto, msg.datapath.ofproto_parser
        in_port = msg.match['in_port']
        dpid = dp.id

        pkt = packet.Packet(msg.data)
        eth = pkt.get_protocol(ethernet.ethernet)
        if not eth or eth.ethertype == ether_types.ETH_TYPE_LLDP:
            return

        self.mac_to_port.setdefault(dpid, {})
        self.mac_to_port[dpid][eth.src] = in_port

        # âœ… è®¾å¤‡å¼‚å¸¸æ£€æµ‹
        self._check_mac_conflict(eth.src, dpid, in_port)  # MACå†²çªæ£€æµ‹

        # 1) é»‘ç™½åå•ä¼˜å…ˆæ£€æŸ¥
        acl = None
        ip_pkt = pkt.get_protocol(ipv4.ipv4)
        if ip_pkt:
            self.logger.info(f"ğŸ“¦ [packet_in] æ”¶åˆ°IPv4åŒ…: src={ip_pkt.src}, dst={ip_pkt.dst}")
            # âœ… IPé…ç½®å¼‚å¸¸æ£€æµ‹
            self._check_ip_subnet(ip_pkt.src)
            acl = self.acl_check(ip_pkt.src)
        else:
            self.logger.debug(f"ğŸ“¦ [packet_in] æ”¶åˆ°éIPv4åŒ…")
        if acl == 'white':
            self._normal_forward(dp, msg, eth, in_port)
            return
        if acl == 'black':
            self.logger.warning(f"ğŸš« é»‘åå•å‘½ä¸­ {ip_pkt.src}ï¼Œç›´æ¥ä¸¢å¼ƒ")
            self._raise_anomaly({'src_ip': ip_pkt.src, 'anomaly_type': 'é»‘åå•ä¸¢å¼ƒ', 'details': 'ACL ç­–ç•¥'})
            # é»‘åå•ä¹Ÿå†™ä¸€æ¡â€œ0 åŒ…â€è®°å½•åˆ° flow_stats
            ts = time.strftime('%Y-%m-%d %H:%M:%S')
            self.flow_cache.append({
                'timestamp': ts,
                'datapath_id': f"{dpid:016d}",
                'src_ip': ip_pkt.src,
                'dst_ip': '',
                'protocol': 'BLACKLIST',
                'src_port': 0,
                'dst_port': 0,
                'src_mac': eth.src,
                'dst_mac': eth.dst,
                'packet_count': 0,
                'byte_count': 0,
                'duration_sec': 0,
                'stats_day': ts[:10],
                'stats_hour': int(ts[11:13])
            })
            return

        # 2) æ­£å¸¸è½¬å‘
        self._handle_protocol(pkt, ip_pkt)
        self._normal_forward(dp, msg, eth, in_port)

        # 3) â† æ–°å¢ï¼šæ¯æ¥ä¸€ä¸ªåŒ…ï¼Œç«‹åˆ»å¾€ flow_cache å¡ä¸€æ¡â€œåŸå§‹åŒ…â€è®°å½•
        src_ip = None
        dst_ip = None
        proto_str = 'IP'
        src_port = 0
        dst_port = 0
        src_mac = eth.src
        dst_mac = eth.dst

        arp_pkt = pkt.get_protocol(arp.arp)
        if arp_pkt:
            src_ip = arp_pkt.src_ip
            dst_ip = arp_pkt.dst_ip
            proto_str = 'ARP'
            # âœ… åœ¨ARPåŒ…ä¸­ä¹Ÿæ£€æµ‹IPé…ç½®å¼‚å¸¸
            self.logger.info(f"ğŸ“¦ [packet_in] æ”¶åˆ°ARPåŒ…: src_ip={src_ip}, dst_ip={dst_ip}")
            self._check_ip_subnet(src_ip)
        else:
            ip_pkt = pkt.get_protocol(ipv4.ipv4)
            if ip_pkt:
                src_ip = ip_pkt.src
                dst_ip = ip_pkt.dst
                if pkt.get_protocol(tcp.tcp):
                    proto_str = 'TCP'
                    tcp_p = pkt.get_protocol(tcp.tcp)
                    src_port = tcp_p.src_port
                    dst_port = tcp_p.dst_port
                elif pkt.get_protocol(udp.udp):
                    proto_str = 'UDP'
                    udp_p = pkt.get_protocol(udp.udp)
                    src_port = udp_p.src_port
                    dst_port = udp_p.dst_port
                elif pkt.get_protocol(icmp.icmp):
                    proto_str = 'ICMP'

        # ğŸ” ä¸´æ—¶è°ƒè¯•ï¼šè®°å½•æ‰€æœ‰packet_inçš„æ•°æ®è§£æç»“æœ
        self.logger.debug(f"ğŸ” packet_inè§£æ: src_ip={src_ip}, dst_ip={dst_ip}, proto={proto_str}, sport={src_port}, dport={dst_port}")

        # âœ… åªè®°å½•ä¸»æœºäº§ç”Ÿçš„æµé‡ï¼Œè¿‡æ»¤SDNåŸºç¡€è®¾æ–½æµé‡
        # ğŸ¯ åŠ å¼ºIPæœ‰æ•ˆæ€§æ£€æŸ¥ï¼šå¿…é¡»æœ‰æœ‰æ•ˆçš„æºIPå’Œç›®æ ‡IP
        if (src_ip and dst_ip and 
            src_ip != '0.0.0.0' and dst_ip != '0.0.0.0' and
            src_ip != '' and dst_ip != '' and
            self._is_host_generated_traffic(src_ip, dst_ip, src_port, dst_port, proto_str)):
            ts = time.strftime('%Y-%m-%d %H:%M:%S')
            self.flow_cache.append({
                'timestamp': ts,
                'datapath_id': f"{dpid:016d}",
                'src_ip': src_ip,
                'dst_ip': dst_ip,
                'protocol': proto_str,
                'src_port': src_port,
                'dst_port': dst_port,
                'src_mac': src_mac,
                'dst_mac': dst_mac,
                'packet_count': 1,
                'byte_count': len(msg.data),
                'duration_sec': 0,
                'stats_day': ts[:10],
                'stats_hour': int(ts[11:13])
            })


    def _is_host_generated_traffic(self, src_ip, dst_ip, src_port, dst_port, protocol):
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºä¸»æœºäº§ç”Ÿçš„æµé‡ï¼ˆè€ŒéSDNåŸºç¡€è®¾æ–½æµé‡ï¼‰
        
        æ³¨æ„ï¼š_extract_flowå·²ç»åšäº†ä¸¥æ ¼çš„IPv4è¿‡æ»¤ï¼Œè¿™é‡Œåªéœ€å¤„ç†packet_inäº‹ä»¶
        """
        
        # è¿‡æ»¤æ— æ•ˆIPåœ°å€
        if not src_ip or not dst_ip or src_ip == '0.0.0.0' or dst_ip == '0.0.0.0':
            return False
        
        # 1. OpenFlowæ§åˆ¶æµé‡ï¼ˆæ§åˆ¶å™¨â†”äº¤æ¢æœºé€šä¿¡ï¼‰
        if src_port == 6633 or dst_port == 6633:
            return False
        
        # 2. RYUæ§åˆ¶å™¨ç®¡ç†æµé‡
        controller_ips = ['192.168.44.129', '127.0.0.1', 'localhost']
        if src_ip in controller_ips or dst_ip in controller_ips:
            if dst_port in [8080, 8001] or src_port in [8080, 8001]:
                return False
        
        # 3. äº¤æ¢æœºç®¡ç†IP
        if (src_ip.startswith('192.168.100.') or 
            dst_ip.startswith('192.168.100.')):
            return False
        
        # æ‰€æœ‰å…¶ä»–æµé‡éƒ½è®¤ä¸ºæ˜¯ä¸»æœºäº§ç”Ÿçš„
        return True

    def _normal_forward(self, dp, msg, eth, in_port):
        dpid = dp.id
        ofp, ps = dp.ofproto, dp.ofproto_parser
        dst_mac = eth.dst
        out_port = self.mac_to_port[dpid].get(dst_mac, ofp.OFPP_FLOOD)
        acts = [ps.OFPActionOutput(out_port)]
        data = msg.data if msg.buffer_id == ofp.OFP_NO_BUFFER else None
        out = ps.OFPPacketOut(datapath=dp, buffer_id=msg.buffer_id,
                              in_port=in_port, actions=acts, data=data)
        dp.send_msg(out)
        if out_port != ofp.OFPP_FLOOD and msg.buffer_id != ofp.OFP_NO_BUFFER:
            match = ps.OFPMatch(in_port=in_port, eth_dst=dst_mac)
            self._add_flow(dp, 1, match, acts, idle=60, hard=0)


    # ---------------- åè®®ç»Ÿè®¡ & æ”»å‡»æ£€æµ‹ ----------------
    def _handle_protocol(self, pkt, ip_pkt):
        """
        åè®®ç»Ÿè®¡ + æ”»å‡»æ£€æµ‹ï¼ˆå« Land Attack & Port Scanï¼‰
        å…¥å£ï¼špacket_in æ¯åŒ…å¿…è°ƒ
        """
        # 0. Land Attackï¼šæº IP == ç›®çš„ IP â†’ é™é€Ÿå¤„ç†ï¼ˆ256Kbpsï¼‰
        if ip_pkt and ip_pkt.src == ip_pkt.dst:
            if ip_pkt.src not in self.land_attack_seen:
                self.land_attack_seen.add(ip_pkt.src)
                # âœ… æ”¹æˆé™é€Ÿè€Œä¸æ˜¯åŠ é»‘åå•
                self._apply_rate_limit(ip_pkt.src, 'Land Attack', kbps=256)
                self._raise_anomaly({
                    'src_ip': ip_pkt.src,
                    'dst_ip': ip_pkt.dst,
                    'protocol': 'IP',
                    'anomaly_type': 'Land Attack',
                    'details': 'æºåœ°å€ç­‰äºç›®çš„åœ°å€ï¼ˆå·²é™é€Ÿ256Kbpsï¼‰'
                })
            # âš ï¸ ç»§ç»­ç»Ÿè®¡ï¼Œä¸å†ç›´æ¥ä¸¢å¼ƒï¼ˆè®©é™é€Ÿæµè¡¨ç”Ÿæ•ˆï¼‰
            # return  # æ³¨é‡Šæ‰ï¼Œå…è®¸ç»§ç»­å¤„ç†

        # 1. æ‹¿æº IPï¼ˆARP ä¼˜å…ˆï¼Œå† IPv4ï¼‰
        src_ip = None
        arp_pkt = pkt.get_protocol(arp.arp)
        if arp_pkt:
            src_ip = arp_pkt.src_ip
        elif ip_pkt:
            src_ip = ip_pkt.src

        if not src_ip:                      # æ‹¿ä¸åˆ° IP ç›´æ¥æ”¾è¡Œ
            return

        # 2. é»‘ç™½åå•ä¼˜å…ˆæ”¾è¡Œ / ä¸¢å¼ƒ
        acl = self.acl_check(src_ip)
        if acl == 'white':                  # ç™½åå•ï¼šä¸€åˆ‡æ£€æµ‹éƒ½è·³è¿‡
            return
        if acl == 'black':                  # é»‘åå•ï¼šåªå‘Šè­¦ï¼Œä¸ç»Ÿè®¡
            self._raise_anomaly({'src_ip': src_ip,
                                 'anomaly_type': 'é»‘åå•ä¸¢å¼ƒ',
                                 'details': 'ACL ç­–ç•¥'})
            return

        # 3. æ­£å¸¸åè®®ç»Ÿè®¡
        tcp_pkt = pkt.get_protocol(tcp.tcp)
        udp_pkt = pkt.get_protocol(udp.udp)
        icmp_pkt = pkt.get_protocol(icmp.icmp)

        # åŸå§‹åŒ…é€Ÿç‡ç»Ÿè®¡ï¼ˆä½ åŸæœ‰é€»è¾‘ï¼‰
        self.raw_pkt_counter[src_ip] += 1
        now = time.time()
        if now - self.raw_last_time.get(src_ip, 0) >= 1:
            rate = self.raw_pkt_counter[src_ip]
            self.raw_pkt_counter[src_ip] = 0
            self.raw_last_time[src_ip] = now
            dst_cnt = len(self.src_dst_counter[src_ip])
            entropy = self._port_entropy(src_ip)
            features = [rate, 0, 0, dst_cnt, entropy]
            self.flow_features_with_info.append({
                'src_ip': src_ip,
                'dst_ip': arp_pkt.dst_ip if arp_pkt else (ip_pkt.dst if ip_pkt else ""),
                'protocol': 'ARP' if arp_pkt else 'ICMP' if icmp_pkt else 'TCP' if tcp_pkt else 'UDP',
                'features': features,
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'packet_count': 1,
                'byte_count': len(pkt.data)
            })

        # 4. æŒ‰åè®®åˆ†æµæ£€æµ‹ï¼ˆä½ åŸæœ‰è°ƒç”¨ï¼‰
        if tcp_pkt and ip_pkt:
            self._tcp_stat(src_ip, ip_pkt.dst, tcp_pkt)
        elif udp_pkt and ip_pkt:
            self._udp_stat(src_ip, ip_pkt.dst, udp_pkt.dst_port)
        elif icmp_pkt and ip_pkt:
            self._icmp_stat(src_ip, ip_pkt.dst)
        elif arp_pkt:
            self._arp_stat(arp_pkt, src_ip)

        # 5. Port Scanï¼ˆæ¯ 60 ç§’ç»“ç®—ï¼Œé›¶åˆ å‡æ’å…¥ï¼‰
        if ip_pkt:
            now = time.time()
            tracker = self.scan_tracker[src_ip]
            if tcp_pkt:              # åªç»Ÿè®¡ TCP ç›®çš„ç«¯å£
                tracker['ports'].add(tcp_pkt.dst_port)
            if now - tracker['last'] >= 60:
                port_cnt = len(tracker['ports'])
                entropy  = self._port_entropy(src_ip)
                if port_cnt > 50 and entropy > 3.0:
                    self._apply_rate_limit(src_ip, 'Port Scan', 256)
                    self._raise_anomaly({
                        'src_ip': src_ip,
                        'dst_ip': ip_pkt.dst,
                        'protocol': 'IP',
                        'anomaly_type': 'Port Scan',
                        'details': f'ç«¯å£æ•°={port_cnt}, ç†µ={entropy:.2f}'
                    })
                tracker['ports'].clear()
                tracker['last'] = now



    # ---------------- ç»Ÿè®¡ ----------------
    def _tcp_stat(self, src_ip, dst_ip, tcp_pkt):
        dst_port = tcp_pkt.dst_port
        st = self.tcp_flag_stats[src_ip]
        st['total'] += 1
        if (tcp_pkt.bits & tcp.TCP_SYN) and not (tcp_pkt.bits & tcp.TCP_ACK):
            st['syn'] += 1
        self.src_dst_counter[src_ip].add(dst_ip)
        self.src_port_counter[src_ip].add(dst_port)
        self._check_syn_flood(src_ip, dst_ip)

        # ===== SSH Brute Force (TCP 22) =====
        if dst_port == 22:
            now = time.time()
            brute = self.ssh_brute[src_ip]
            brute['conns'] += 1
            if now - brute['last'] >= 60:           # æ¯ 60 ç§’ç»“ç®—
                if brute['conns'] > 50:             # é˜ˆå€¼ï¼š>50 è¿æ¥/åˆ†é’Ÿ
                    self._apply_rate_limit(src_ip, 'SSH Brute Force', 256)
                    self._raise_anomaly({
                        'src_ip': src_ip,
                        'dst_ip': dst_ip,
                        'protocol': 'TCP',
                        'anomaly_type': 'SSH Brute Force',
                        'details': f'22ç«¯å£è¿æ¥æ•°={brute["conns"]}'
                    })
                brute['conns'] = 0
                brute['last']  = now

        # ä½ åŸæœ‰â€œå­¤ç«‹æ£®æ—æ’æ ·â€é€»è¾‘ä¿ç•™
        now = time.time()
        t = now - st.get('last', now)
        if t <= 0:
            return
        ratio = st['syn'] / max(st['total'], 1)
        rate = st['syn'] / max(t, 0.001)
        if (ratio > THRESH['syn']['ratio'] or rate > THRESH['syn']['rate']) and self.acl_check(src_ip) != 'white':
            self._apply_rate_limit(src_ip, 'SYN Flood')
            self._raise_anomaly({'src_ip': src_ip, 'dst_ip': dst_ip, 'protocol': 'TCP',
                                 'anomaly_type': 'SYN Flood', 'details': f'ratio={ratio:.2f} rate={rate:.1f}'})
            st['syn'] = st['total'] = 0
            st['last'] = now
            entropy = self._port_entropy(src_ip)
            byte_rate = st['total'] * 64
            features = [rate, byte_rate, 0, len(self.src_dst_counter[src_ip]), entropy]
            self.flow_features_with_info.append({
                'src_ip': src_ip, 'dst_ip': dst_ip, 'protocol': 'TCP',
                'features': features, 'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'packet_count': 1, 'byte_count': 64
            })
            self.logger.info(f"[TCP->IF] æ”»å‡»ç¡®è®¤æ’å…¥: src={src_ip}, rate={rate:.0f}")



    def _udp_stat(self, src_ip, dst_ip, dst_port):
        st = self.udp_stats[src_ip]
        st['count'] += 1
        if not hasattr(st, 'dst_ports'):
            st['dst_ports'] = set()
        st['dst_ports'].add(dst_port)
        
        self.src_dst_counter[src_ip].add(dst_ip)
        self.src_port_counter[src_ip].add(dst_port)
        
        # è°ƒç”¨æ£€æµ‹å‡½æ•°
        self._check_udp_flood(src_ip, dst_ip)

    def _icmp_stat(self, src_ip, dst_ip):
        if self.acl_check(src_ip) == 'white':
            return
        st = self.icmp_stats[src_ip]
        st['count'] += 1
        
        self.src_dst_counter[src_ip].add(dst_ip)
        
        # è°ƒç”¨æ£€æµ‹å‡½æ•°
        self._check_icmp_flood(src_ip, dst_ip)

    # ---------------- ARP ç»Ÿè®¡ ----------------
    def _arp_stat(self, arp_pkt, src_ip):
        """
        ç²¾ç®€ç‰ˆ ARP æ¬ºéª—æ£€æµ‹ï¼š
        1. åªå…³æ³¨ src_ipï¼ˆå‘é€æ–¹ IPï¼‰å¯¹åº”çš„ MAC æ˜¯å¦ç¬é—´å˜åŒ–
        2. å˜åŒ–ä¸€æ¬¡å³è§¦å‘ï¼Œæ— éœ€å¤šä¸ª MAC ç´¯ç§¯
        3. ç™½åå•è·³è¿‡ï¼Œé»‘åå•åªå‘Šè­¦ä¸é™é€Ÿ
        """
        # 1. é»‘ç™½åå•å¿«é€Ÿé€šé“
        acl = self.acl_check(src_ip)
        if acl == 'white':
            return
        if acl == 'black':
            self._raise_anomaly({'src_ip': src_ip,
                                'dst_ip': arp_pkt.dst_ip,
                                'protocol': 'ARP',
                                'anomaly_type': 'é»‘åå•ä¸¢å¼ƒ',
                                'details': 'ACL ç­–ç•¥'})
            return

        # 2. åˆå§‹åŒ–/è·å–ä¸Šæ¬¡ MAC
        st = self.arp_stats[src_ip]          # å¤ç”¨åŸç»“æ„ï¼Œçœå†…å­˜
        prev_mac = st.get('last_mac', None)
        curr_mac = arp_pkt.src_mac

        if prev_mac is None:                 # ç¬¬ä¸€æ¬¡è§ï¼Œåªè®°å½•
            st['last_mac'] = curr_mac
            return

        # 3. å˜åŒ–ä¸€æ¬¡å³è§¦å‘
        if curr_mac != prev_mac:
            self.logger.warning(f"[ARP_SPOOF_DETECTED] {src_ip} MAC å˜åŒ–: "
                                f"{prev_mac} -> {curr_mac}")
            # 3-1 é™é€Ÿï¼ˆå†…å­˜+æµè¡¨+DBï¼‰
            self._apply_rate_limit(src_ip, 'ARP æ¬ºéª—ï¼ˆMACå˜åŒ–ä¸€æ¬¡ï¼‰')
            # 3-2 å†™å¼‚å¸¸æ—¥å¿—ï¼ˆæ–‡ä»¶+DBï¼‰
            self._raise_anomaly({
                'src_ip': src_ip,
                'dst_ip': arp_pkt.dst_ip,
                'protocol': 'ARP',
                'anomaly_type': 'ARP æ¬ºéª—',
                'details': f'MAC å˜åŒ–: {prev_mac} -> {curr_mac}'
            })
            # 3-3 æ›´æ–°è¿½è¸ªå€¼ï¼ˆç»§ç»­è§‚å¯Ÿåç»­å˜åŒ–ï¼‰
            st['last_mac'] = curr_mac


    # ---------------- æ”»å‡»åˆ¤å®šï¼ˆç™½åå• IP æ°¸ä¸é™é€Ÿï¼‰ ----------------
    def _check_syn_flood(self, src_ip, dst_ip):
        st = self.tcp_flag_stats[src_ip]
        if st['total'] < THRESH['syn']['min_tcp']:
            return
        ratio = st['syn'] / st['total']
        now = time.time()
        t = now - st['last']
        
        # âœ… å¿…é¡»è‡³å°‘1ç§’æ‰è®¡ç®—é€Ÿç‡ï¼Œé¿å…æ—¶é—´é—´éš”å¤ªå°å¯¼è‡´é€Ÿç‡çˆ†è¡¨
        if t < 1.0:
            return
        
        rate = st['syn'] / t
        
        # æ£€æŸ¥å£è¯­è§„åˆ™è‡ªå®šä¹‰é˜ˆå€¼
        syn_threshold = CUSTOM_RULES.get('syn_threshold')
        if syn_threshold and rate < syn_threshold:
            self.logger.info(f"[å£è¯­è§„åˆ™] SYNæµé‡ {rate:.1f} pkt/s ä½äºé˜ˆå€¼ {syn_threshold}ï¼Œè·³è¿‡é™é€Ÿ")
            return

        # é™ä½æ£€æµ‹é˜ˆå€¼ï¼Œæé«˜æ•æ„Ÿæ€§
        if ratio > THRESH['syn']['ratio'] * 0.8 or rate > THRESH['syn']['rate'] * 0.8:
            if self.acl_check(src_ip) != 'white':
                self._apply_rate_limit(src_ip, 'SYN Flood')
            self._raise_anomaly({
                'src_ip': src_ip,
                'dst_ip': dst_ip,
                'protocol': 'TCP',
                'anomaly_type': 'SYN Flood',
                'details': f'ratio={ratio:.2f} rate={rate:.1f}'
            })
            # âœ… æ¸…é›¶è®¡æ•°å™¨ï¼Œä½†ä¸æ›´æ–°lastï¼ˆç”±_reset_loopç»Ÿä¸€æ›´æ–°ï¼‰
            st['syn'] = st['total'] = 0
            # ä¸æ›´æ–°st['last']ï¼Œé¿å…å½±å“ä¸‹æ¬¡æ£€æµ‹çš„æ—¶é—´å·®

    def _check_udp_flood(self, src_ip, dst_ip):
        st = self.udp_stats[src_ip]
        now = time.time()
        t = now - st['last']
        
        # âœ… å¿…é¡»è‡³å°‘1ç§’æ‰è®¡ç®—é€Ÿç‡ï¼Œé¿å…æ—¶é—´é—´éš”å¤ªå°å¯¼è‡´é€Ÿç‡çˆ†è¡¨
        if t < 1.0:
            return
        
        rate = st['count'] / t

        # ç©æ³•2: å£è¯­è§„åˆ™ - æ£€æŸ¥è‡ªå®šä¹‰UDPé˜ˆå€¼
        udp_threshold = CUSTOM_RULES.get('udp_threshold', THRESH['udp']['flood_rate'])
        if rate < udp_threshold:
            self.logger.debug(f"UDPæµé‡ {rate:.1f} pkt/s ä½äºè‡ªå®šä¹‰é˜ˆå€¼ {udp_threshold}ï¼Œè·³è¿‡é™é€Ÿ")
            return

        # æ–°å¢ï¼šå¤šç«¯å£æ£€æµ‹é€»è¾‘
        port_count = len(getattr(st, 'dst_ports', set()))
        is_flood = rate > THRESH['udp']['flood_rate'] or (port_count > 50 and rate > THRESH['udp']['flood_rate'] * 0.5)

        if is_flood:
            if self.acl_check(src_ip) != 'white':
                self._apply_rate_limit(src_ip, 'UDP Flood')
            self._raise_anomaly({
                'src_ip': src_ip,
                'dst_ip': dst_ip,
                'protocol': 'UDP',
                'anomaly_type': 'UDP Flood',
                'details': f'é€Ÿç‡={rate:.1f} ç«¯å£æ•°={port_count}'
            })
            # âœ… æ¸…é›¶è®¡æ•°å™¨ï¼Œä½†ä¸æ›´æ–°lastï¼ˆç”±_reset_loopç»Ÿä¸€æ›´æ–°ï¼‰
            st['count'] = 0
            if hasattr(st, 'dst_ports'):
                st['dst_ports'].clear()

    def _check_icmp_flood(self, src_ip, dst_ip):
        if self.acl_check(src_ip) == 'white':          # â† ç»ˆæåŠ å¡
            return
        st = self.icmp_stats[src_ip]
        now = time.time()
        t = now - st['last']
        
        # âœ… å¿…é¡»è‡³å°‘1ç§’æ‰è®¡ç®—é€Ÿç‡ï¼Œé¿å…æ—¶é—´é—´éš”å¤ªå°å¯¼è‡´é€Ÿç‡çˆ†è¡¨ï¼ˆå¦‚pingallåœ¨0.001ç§’å†…å‘åŒ…ï¼‰
        if t < 1.0:
            return
        
        rate = st['count'] / t
        
        # æ£€æŸ¥å£è¯­è§„åˆ™è‡ªå®šä¹‰é˜ˆå€¼
        icmp_threshold = CUSTOM_RULES.get('icmp_threshold')
        if icmp_threshold and rate < icmp_threshold:
            self.logger.info(f"[å£è¯­è§„åˆ™] ICMPæµé‡ {rate:.1f} pkt/s ä½äºé˜ˆå€¼ {icmp_threshold}ï¼Œè·³è¿‡é™é€Ÿ")
            return
        
        if rate > THRESH['icmp']['flood_rate']:
            self._apply_rate_limit(src_ip, 'ICMP Flood')
            self._raise_anomaly({'src_ip': src_ip, 'dst_ip': dst_ip, 'protocol': 'ICMP',
                                 'anomaly_type': 'ICMP Flood',
                                 'details': f'rate={rate:.1f}'})
            # âœ… æ¸…é›¶è®¡æ•°å™¨ï¼Œä½†ä¸æ›´æ–°lastï¼ˆç”±_reset_loopç»Ÿä¸€æ›´æ–°ï¼‰
            st['count'] = 0

    # ARPæ”»å‡»æ£€æµ‹ï¼ˆä»…MACå˜åŒ–æ£€æµ‹ï¼‰
    def _check_arp_attack(self, src_ip, arp_pkt):
        if self.acl_check(src_ip) == 'white':
            return
        # æ­¤å‡½æ•°ç°åœ¨åªä½œä¸ºå ä½ç¬¦ï¼Œå®é™…æ£€æµ‹é€»è¾‘å·²ç§»è‡³_arp_statå‡½æ•°ä¸­
        # ä¿æŒå‡½æ•°å­˜åœ¨ä»¥é¿å…è°ƒç”¨é”™è¯¯
        pass

    # -----------------------------------------------------------
# -----------------------------------------------------------
# çœŸæ­£é™é€Ÿï¼šå†™å†…å­˜ + æ¸…è¿‡æœŸ + å†™å…³ç³»è¡¨ + ä¸‹å‘æµè¡¨ + å†™ log
# -----------------------------------------------------------
    def _apply_rate_limit(self, src_ip: str, reason: str, kbps: int = 1024, operator: str = 'system', duration_minutes: int = None):
        """
        åº”ç”¨é™é€Ÿè§„åˆ™
        å‚æ•°:
            operator: 'admin'(ç®¡ç†å‘˜æ‰‹åŠ¨) æˆ– 'system'(è‡ªåŠ¨æ£€æµ‹)
            duration_minutes: é™é€Ÿæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
        è¿”å›: (æˆåŠŸ/å¤±è´¥, å®é™…é€Ÿç‡kbps, é”™è¯¯ä¿¡æ¯)
        """
        if not src_ip:
            self.logger.error("é™é€Ÿå¤±è´¥ï¼šæºIPä¸ºç©º")
            return (False, 0, "æºIPä¸ºç©º")

        # â‘  è§£ææ¡£ä½ï¼ˆå£è¯­æˆ–æ•°å­—ï¼‰
        if isinstance(kbps, str):
            kbps = kbps.strip()
            if re.search(r'ä½é€Ÿ', kbps, re.I):
                kbps = 256
            elif re.search(r'ä¸­é€Ÿ', kbps, re.I):
                kbps = 1024
            elif re.search(r'é«˜é€Ÿ', kbps, re.I):
                kbps = 2048
            else:
                m = re.search(r'(\d+)\s*kbps|(\d+)\s*m', kbps, re.I)
                kbps = 1024
                if m:
                    kbps = int(m.group(1)) if m.group(1) else int(m.group(2)) * 1024
        else:
            kbps = int(kbps)

        if kbps <= 0:
            kbps = 1024

        # âœ… è®¡ç®—è¿‡æœŸæ—¶é—´ï¼ˆä½¿ç”¨æŒ‡å®šçš„durationæˆ–é»˜è®¤å€¼ï¼‰
        now = time.time()
        if duration_minutes is not None and duration_minutes > 0:
            duration_seconds = duration_minutes * 60  # åˆ†é’Ÿè½¬ç§’
        else:
            duration_seconds = RATE_LIMIT_DURATION  # é»˜è®¤5åˆ†é’Ÿ
        expire = now + duration_seconds

        # â‘¡ å…ˆæ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„äº¤æ¢æœº
        if not self.datapaths:
            self.logger.error(f"âŒ é™é€Ÿå¤±è´¥: {src_ip} - æ²¡æœ‰å¯ç”¨çš„äº¤æ¢æœºï¼ˆè¯·æ£€æŸ¥äº¤æ¢æœºè¿æ¥ï¼‰")
            return (False, kbps, "æ²¡æœ‰å¯ç”¨çš„äº¤æ¢æœºï¼Œè¯·æ£€æŸ¥äº¤æ¢æœºæ˜¯å¦è¿æ¥åˆ°æ§åˆ¶å™¨")

        # â‘¢ å†…å­˜è®°å½•
        self.limited_ips[src_ip] = expire

        # â‘£ ä¸‹å‘æµè¡¨ï¼ˆä¸‰æ¡£é˜Ÿåˆ—æ˜ å°„ï¼‰- å…ˆä¸‹å‘æµè¡¨ï¼ŒæˆåŠŸåå†å†™æ•°æ®åº“
        if kbps <= 256:
            queue_id = 1
        elif kbps <= 1024:
            queue_id = 2
        else:  # >= 2048
            queue_id = 3

        try:
            flow_success = False
            for dp in self.datapaths.values():
                ofp, ps = dp.ofproto, dp.ofproto_parser
                match = ps.OFPMatch(eth_type=ether_types.ETH_TYPE_IP,
                                    ipv4_src=src_ip)
                acts = [ps.OFPActionSetQueue(queue_id=queue_id),
                        ps.OFPActionOutput(ofp.OFPP_NORMAL)]
                # âœ… ä¿®å¤ï¼šè®¾ç½®idle_timeout=0ï¼ˆæ°¸ä¸å› ç©ºé—²åˆ é™¤ï¼‰å’Œhard_timeout=é™é€Ÿæ—¶é•¿
                # è¿™æ ·å³ä½¿æš‚æ—¶æ²¡æœ‰æµé‡ï¼Œæµè¡¨ä¹Ÿä¼šä¿æŒåˆ°é™é€ŸæœŸæ»¡
                self._add_flow(dp, 50, match, acts, idle=0, hard=int(duration_seconds))
                flow_success = True
                self.logger.info(f"âœ… æµè¡¨å·²ä¸‹å‘åˆ°äº¤æ¢æœº {dp.id}: {src_ip} -> queue={queue_id}, idle=0, hard={int(duration_seconds)}s")

            if not flow_success:
                self.logger.error(f"âŒ æµè¡¨ä¸‹å‘å¤±è´¥: {src_ip} - æ²¡æœ‰å¯ç”¨çš„äº¤æ¢æœº")
                return (False, kbps, "æ²¡æœ‰å¯ç”¨çš„äº¤æ¢æœº")

            self.logger.warning(f"ğŸ”’ å·²å¯¹ {src_ip} å…¨æ–¹å‘é™é€Ÿ {kbps} kbpsï¼ˆ{reason}ï¼‰queue={queue_id}")
            
        except Exception as e:
            self.logger.error(f"âŒ ä¸‹å‘æµè¡¨å¤±è´¥: {src_ip} - {e}")
            import traceback
            traceback.print_exc()
            return (False, kbps, f"ä¸‹å‘æµè¡¨å¤±è´¥: {str(e)}")
        
        # â‘¤ æµè¡¨ä¸‹å‘æˆåŠŸåï¼Œå†™å…¥æ•°æ®åº“
        conn = None
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                # 5-1 æ¸…ç†å·²è¿‡æœŸçš„ active è®°å½•
                cur.execute("DELETE FROM rate_limit_active WHERE expire_at < NOW()")

                # 5-2 å†™å…¥/æ›´æ–°æœ€æ–°é™é€Ÿï¼ˆå…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨ï¼Œå†å†³å®šINSERTè¿˜æ˜¯UPDATEï¼‰
                # æ£€æŸ¥è¯¥IPæ˜¯å¦å·²æœ‰é™é€Ÿè®°å½•
                cur.execute("SELECT 1 FROM rate_limit_active WHERE src_ip = %s", (src_ip,))
                exists = cur.fetchone()
                
                if exists:
                    # æ›´æ–°ç°æœ‰è®°å½•
                    sql = """
                        UPDATE rate_limit_active
                        SET expire_at = FROM_UNIXTIME(%s),
                            kbps = %s,
                            reason = %s
                        WHERE src_ip = %s
                    """
                    cur.execute(sql, (expire, kbps, reason, src_ip))
                else:
                    # æ’å…¥æ–°è®°å½•
                    sql = """
                        INSERT INTO rate_limit_active (src_ip, expire_at, kbps, reason)
                        VALUES (%s, FROM_UNIXTIME(%s), %s, %s)
                    """
                    cur.execute(sql, (src_ip, expire, kbps, reason))

                # 5-3 å†™ log è¡¨ï¼ˆè®°å½•æ‰€æœ‰é™é€Ÿæ“ä½œï¼‰
                cur.execute("""
                    INSERT INTO rate_limit_log (src_ip, operator, action, reason, kbps)
                    VALUES (%s, %s, %s, %s, %s)
                """, (src_ip, operator, 'limit', reason, kbps))

                # âœ… 5-4 ã€ç®¡ç†å‘˜æ‰‹åŠ¨é™é€Ÿã€‘ç›´æ¥INSERTåˆ°attack_sessionsï¼ˆæ¯æ¬¡æ“ä½œ=ç‹¬ç«‹è®°å½•ï¼‰
                # ç³»ç»Ÿè‡ªåŠ¨é™é€Ÿï¼ˆoperator='system'ï¼‰ç”±_log_attack_sessionè´Ÿè´£è®°å½•ä¸ºpending
                if operator == 'admin':
                    # æ‰€æœ‰æ”»å‡»ç›¸å…³çš„é™é€ŸåŸå› 
                    attack_types = [
                        'SYN Flood', 'UDP Flood', 'ICMP Flood', 'ARP æ¬ºéª—', 'ARPæ¬ºéª—', 
                        'å¸¦å®½è¶…é™', 'Port Scan', 'SSH Brute Force', 'Land Attack',
                        'å¼‚å¸¸æµé‡', 'æ‰‹åŠ¨é™åˆ¶', 'å…¶ä»–åŸå› ', 'ç®¡ç†å‘˜æ‰‹åŠ¨é™é€Ÿ'
                    ]
                    # âœ… ç®¡ç†å‘˜æ¯æ¬¡é™é€Ÿéƒ½ç›´æ¥INSERTæ–°è®°å½•ï¼ˆä¸ä½¿ç”¨æ—¶é—´çª—å£åˆå¹¶ï¼Œä¸æ£€æŸ¥flagï¼‰
                    # åŸå› ï¼šç®¡ç†å‘˜æ¯æ¬¡æ“ä½œéƒ½æ˜¯ç‹¬ç«‹çš„å†³ç­–ï¼Œéœ€è¦å•ç‹¬è®°å½•
                    # status='handled', is_active=0ï¼ˆå·²ç»“æŸï¼‰
                    cur.execute("""
                        INSERT INTO attack_sessions (
                            src_ip, anomaly_type, packet_count, 
                            start_time, last_packet_time, end_time, duration_seconds,
                            is_active, status, handled_by, handled_at, handle_action
                        ) VALUES (
                            %s, %s, 1, 
                            NOW(), NOW(), NOW(), 0,
                            0, 'handled', %s, NOW(), 'ratelimit'
                        )
                    """, (src_ip, reason, operator))
                    self.logger.info(f"âœ… [ç®¡ç†å‘˜æ“ä½œ] å·²ä¸º {src_ip} åˆ›å»ºé™é€Ÿè®°å½•åˆ°attack_sessionsï¼ˆåŸå› ï¼š{reason}ï¼‰")

                conn.commit()
            self.logger.warning(f"ğŸ“¥ é™é€Ÿè®°å½•å·²å†™å…¥æ•°æ®åº“: ip={src_ip}, kbps={kbps}, reason={reason}, operator={operator}")
        except Exception as e:
            self.logger.error(f"âš ï¸ æµè¡¨å·²ä¸‹å‘ä½†æ•°æ®åº“å†™å…¥å¤±è´¥: {e}")
            if conn:
                conn.rollback()
            # æ³¨æ„ï¼šæ­¤æ—¶æµè¡¨å·²ç»ä¸‹å‘æˆåŠŸï¼Œæ‰€ä»¥ä»ç„¶è¿”å›æˆåŠŸï¼Œä½†è®°å½•è­¦å‘Š
            self.logger.warning(f"âš ï¸ {src_ip} æµè¡¨å·²ç”Ÿæ•ˆï¼Œä½†æ•°æ®åº“æœªåŒæ­¥")
        finally:
            if conn:
                conn.close()

        # 6. â˜…â˜…â˜… è®°å½•"æœ¬æ¬¡é™é€Ÿäº‹ä»¶"(1 åˆ†é’Ÿåˆå¹¶) â˜…â˜…â˜…
        self._log_limit_session(src_ip, reason, kbps)
        
        return (True, kbps, "")







    # -----------------------------------------------------------
    # è§£é™¤é™é€Ÿï¼šå†…å­˜ + æµè¡¨ + æ•°æ®åº“ active è¡¨ + å†™ log è¡¨
    # çº¿ç¨‹å®‰å…¨ï¼šæ¯æ¬¡æ–°å»ºæ•°æ®åº“è¿æ¥ï¼Œç”¨å®Œç«‹å³å…³é—­
    # -----------------------------------------------------------
   # -----------------------------------------------------------
# è§£é™¤é™é€Ÿï¼šåˆ å†…å­˜ + åˆ æµè¡¨ + å†™ log
# -----------------------------------------------------------
    # -----------------------------------------------------------
# è§£é™¤é™é€Ÿï¼šå†…å­˜ + æµè¡¨ + æ•°æ®åº“ active è¡¨ + å†™ log
# é˜²å¾¡å¼ï¼šå¼ºåˆ¶å­—ç¬¦ä¸²é”®ã€æ—¶é—´æˆ³ç»Ÿä¸€ã€åŒè¡¨åŒæ­¥
# -----------------------------------------------------------
    def _release_rate_limit(self, src_ip: str, operator: str = 'admin', reason: str = 'æ‰‹åŠ¨è§£é™¤'):
        src_ip = str(src_ip)
        now = time.time()

        # 1. å†…å­˜å¿…é¡»å­˜åœ¨
        if src_ip not in self.limited_ips:
            self.logger.warning(f"[UNLIMIT] {src_ip} ä¸åœ¨å†…å­˜ï¼Œè·³è¿‡")
            return False

        # 2. åˆ å†…å­˜
        del self.limited_ips[src_ip]

        # 3. æ•°æ®åº“ï¼šç‹¬ç«‹è¿æ¥ï¼ŒåŒè¡¨æ“ä½œ
        conn = None
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                # 3-1 æ¸… active è¡¨
                cur.execute("DELETE FROM rate_limit_active WHERE src_ip = %s", (src_ip,))
                # 3-2 å†™ log è¡¨ï¼ˆoperator é•¿åº¦å®‰å…¨ï¼‰
                cur.execute("""
                    INSERT INTO rate_limit_log(src_ip, operator, action, reason)
                    VALUES (%s, %s, %s, %s)
                """, (src_ip, operator[:16], 'unlimit', reason))
                conn.commit()
            self.logger.warning(f"ğŸ”“ è§£é™¤é™é€Ÿ {src_ip} æ“ä½œäºº: {operator} åŸå› : {reason}")
        except Exception as e:
            self.logger.error(f"è§£é™¤é™é€Ÿæ•°æ®åº“å¤±è´¥: {e}")
            if conn:
                conn.rollback()
            return False
        finally:
            if conn:
                conn.close()

        # 4. åˆ é™¤æµè¡¨ï¼ˆå…¨æ–¹å‘ï¼‰
        for dp in self.datapaths.values():
            ofp, ps = dp.ofproto, dp.ofproto_parser
            match = ps.OFPMatch(eth_type=ether_types.ETH_TYPE_IP, ipv4_src=src_ip)
            mod = ps.OFPFlowMod(datapath=dp, match=match, command=ofp.OFPFC_DELETE,
                                out_group=ofp.OFPG_ANY, out_port=ofp.OFPP_ANY)
            dp.send_msg(mod)
        return True



    # ---------------- å¼‚å¸¸è®°å½•ï¼ˆä¸å†å»é‡ï¼Œæ¯åŒ…éƒ½å†™ï¼‰ ----------------
    def _raise_anomaly(self, entry):
        # 0. è¡¥æ—¶é—´å­—æ®µ
        entry['detect_time'] = time.strftime('%Y-%m-%d %H:%M:%S')
        entry['detect_day']  = entry['detect_time'][:10]

        # 1. å†™æœ¬åœ°æ–‡ä»¶
        self._write_anomaly(entry)

        # 2. å†™ anomaly_log è¡¨ï¼ˆå…¨é‡ç•™è¯æ®ï¼‰
        self._write_anomaly_db(entry)

        # 3. æ§åˆ¶å° warning
        self.logger.warning(
            f"âš ï¸ {entry['anomaly_type']} | {entry['details']} | "
            f"{entry['src_ip']} -> {entry.get('dst_ip', '')}"
        )

        # 4. æ¨å†…å­˜é˜Ÿåˆ—ï¼ˆAI æ‘˜è¦ã€å‘¨æŠ¥ï¼‰
        with QUEUE_LOCK:
            ANOMALY_QUEUE.append(entry)

        # 5. AI æ‘˜è¦ï¼ˆå¯é€‰ï¼‰
        if AI_SUMMARY_ENABLED:
            summary = f"ğŸ¤– AIæ‘˜è¦: {entry['src_ip']} å‘èµ· {entry['anomaly_type']} æ”»å‡»"
            self.logger.info(summary)
            WEEKLY_REPORT_DATA.append({'time': entry['detect_time'], 'summary': summary})

        # 6. è®°å½•æ”»å‡»äº‹ä»¶ï¼ˆ1 åˆ†é’Ÿåˆå¹¶ï¼Œä¸åŒç±»å‹ä¸€å®šåˆ†å®¶ï¼‰
        self._log_attack_session(entry)







    # --------- ç”Ÿäº§è€…ï¼šå·²é›†æˆåœ¨ _raise_anomaly é‡Œï¼Œæ— éœ€å†è°ƒ ---------

    # --------- æ¶ˆè´¹è€…ï¼šå•çº¿ç¨‹å†™åº“ ---------
    def _db_writer_loop(self):
        """
        ç»Ÿä¸€çš„æ•°æ®åº“å†™å…¥å¾ªç¯
        - å¤„ç†å¼‚å¸¸æ—¥å¿—æ‰¹é‡å†™å…¥
        - å¤„ç†æµé‡æ•°æ®æ‰¹é‡å†™å…¥ï¼ˆæ¯30ç§’æˆ–ç¼“å­˜æ»¡100æ¡æ—¶å†™å…¥ï¼‰
        """
        while True:
            # 1. å¤„ç†å¼‚å¸¸æ—¥å¿—
            if ANOMALY_QUEUE:
                with QUEUE_LOCK:
                    batch = list(ANOMALY_QUEUE)
                    ANOMALY_QUEUE.clear()
                try:
                    conn = pymysql.connect(**DB_CONFIG)  # âœ… æ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹è¿æ¥
                    with conn.cursor() as cur:
                        sql = """INSERT INTO anomaly_log
                                     (detect_time, src_ip, dst_ip, protocol, anomaly_type, details)
                                 VALUES (%s, %s, %s, %s, %s, %s)"""
                        cur.executemany(sql, [
                            (e['detect_time'], e['src_ip'], e.get('dst_ip', ''),
                             e.get('protocol', ''), e['anomaly_type'], e['details'])
                            for e in batch
                        ])
                        conn.commit()
                    self.logger.info(f'ğŸ“¥ å¼‚å¸¸æ—¥å¿—å†™å…¥ {len(batch)} æ¡')
                except Exception as e:
                    self.logger.error(f'æ‰¹é‡å†™å¼‚å¸¸æ—¥å¿—å¤±è´¥: {e}')
                finally:
                    if conn:
                        conn.close()
            
            # 2. å¤„ç†æµé‡æ•°æ®ï¼ˆæ™ºèƒ½æ‰¹é‡å†™å…¥ï¼‰
            should_write_flow = False
            if self.flow_cache:
                # æ¡ä»¶1ï¼šç¼“å­˜è¶…è¿‡100æ¡
                if len(self.flow_cache) >= 100:
                    should_write_flow = True
                # æ¡ä»¶2ï¼šç¼“å­˜æœ‰æ•°æ®ä¸”è¶…è¿‡30ç§’æœªå†™å…¥
                elif hasattr(self, '_last_flow_write_time'):
                    if time.time() - self._last_flow_write_time > 30:
                        should_write_flow = True
                else:
                    # é¦–æ¬¡è¿è¡Œï¼Œè®°å½•æ—¶é—´
                    self._last_flow_write_time = time.time()
            
            if should_write_flow:
                self._write_db()
                self._last_flow_write_time = time.time()
            
            hub.sleep(1)

        # ========== â‘  æ–°å¢ï¼šæ”»å‡»äº‹ä»¶è½åº“ ==========
        # ========== â‘  æ”»å‡»äº‹ä»¶ï¼š1 åˆ†é’Ÿåˆå¹¶ï¼Œä¸åŒç±»å‹ä¸€å®šåˆ†å¼€ ==========
    def _log_attack_session(self, entry):
        """
        âœ… FlagçŠ¶æ€æœº + æ»‘åŠ¨çª—å£æ–¹æ¡ˆ
        - æ£€æµ‹åˆ°æ”»å‡»åŒ…æ—¶ï¼Œå¦‚æœ15ç§’å†…æ— æ´»åŠ¨ä¼šè¯ï¼Œåˆ›å»ºæ–°ä¼šè¯ï¼ˆis_active=1ï¼‰
        - æŒç»­æ”»å‡»æ—¶ï¼Œæ›´æ–°packet_countå’Œlast_packet_time
        - å®šæœŸæ£€æŸ¥ï¼ˆ15ç§’æ— æ–°åŒ…ï¼‰è‡ªåŠ¨å…³é—­ä¼šè¯ï¼ˆis_active=0, è®¾ç½®end_timeï¼‰
        """
        conn = None
        try:
            src_ip = entry['src_ip']
            anomaly_type = entry['anomaly_type']
            now = datetime.now()
            
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                # 1. æŸ¥æ‰¾è¯¥IP+æ”»å‡»ç±»å‹çš„æ´»åŠ¨ä¼šè¯
                sql = """
                    SELECT id, start_time, packet_count, last_packet_time
                    FROM attack_sessions
                    WHERE src_ip = %s
                      AND anomaly_type = %s
                      AND is_active = 1
                    ORDER BY start_time DESC
                    LIMIT 1
                """
                cur.execute(sql, (src_ip, anomaly_type))
                row = cur.fetchone()
                
                if row:
                    # 2. å­˜åœ¨æ´»åŠ¨ä¼šè¯
                    session_id, start_time, packet_count, last_packet_time = row
                    
                    # âœ… è®¡ç®—ä¼šè¯æŒç»­æ—¶é—´ï¼Œå¦‚æœè¶…è¿‡1å°æ—¶ï¼Œå¼ºåˆ¶å…³é—­å¹¶åˆ›å»ºæ–°ä¼šè¯
                    if start_time:
                        session_duration = (now - start_time).total_seconds()
                    else:
                        session_duration = 0
                    
                    # è®¡ç®—è·ç¦»ä¸Šæ¬¡æ”»å‡»åŒ…çš„æ—¶é—´é—´éš”
                    # âœ… å¤„ç†last_packet_timeä¸ºNoneçš„æƒ…å†µ
                    if last_packet_time is None:
                        time_diff = 0
                    else:
                        time_diff = (now - last_packet_time).total_seconds()
                    
                    # âœ… å¦‚æœä¼šè¯æŒç»­è¶…è¿‡1å°æ—¶ OR è·ç¦»ä¸Šæ¬¡åŒ…è¶…è¿‡2ç§’ï¼Œå…³é—­æ—§ä¼šè¯åˆ›å»ºæ–°ä¼šè¯
                    # 2ç§’çª—å£ï¼šç¡®ä¿èƒ½åŒºåˆ†"æ”»å‡»åœæ­¢åç«‹å³å†æ¬¡æ”»å‡»"çš„æƒ…å†µ
                    if time_diff > 2 or session_duration > 3600:
                        # 2-1. è¶…è¿‡2ç§’æ— æ–°åŒ…ï¼Œè®¤ä¸ºæ˜¯æ–°ä¸€è½®æ”»å‡»
                        # å…ˆå…³é—­æ—§ä¼šè¯
                        if last_packet_time and start_time:
                            duration = (last_packet_time - start_time).total_seconds()
                        else:
                            duration = 0
                        cur.execute("""
                            UPDATE attack_sessions
                            SET is_active = 0,
                                end_time = %s,
                                duration_seconds = %s,
                                status = 'pending'
                            WHERE id = %s
                        """, (last_packet_time or now, int(duration), session_id))
                        
                        # åˆ›å»ºæ–°ä¼šè¯ï¼ˆç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹ï¼Œstatus='pending'ï¼‰
                        cur.execute("""
                            INSERT INTO attack_sessions
                            (src_ip, anomaly_type, start_time, last_packet_time, packet_count, is_active, status)
                            VALUES (%s, %s, %s, %s, 1, 1, 'pending')
                        """, (src_ip, anomaly_type, now, now))
                        
                        if session_duration > 3600:
                            self.logger.info(f"ğŸ†• [attack_session] {src_ip} {anomaly_type} æ—§ä¼šè¯è¶…æ—¶ï¼ˆæŒç»­{int(session_duration/3600)}å°æ—¶ï¼‰ï¼Œåˆ›å»ºæ–°ä¼šè¯")
                        else:
                            self.logger.info(f"ğŸ†• [attack_session] {src_ip} {anomaly_type} æ–°ä¼šè¯å¼€å§‹ï¼ˆè·ç¦»ä¸Šæ¬¡{int(time_diff)}ç§’ï¼‰")
                    else:
                        # 2-2. ç»§ç»­å½“å‰ä¼šè¯
                        cur.execute("""
                            UPDATE attack_sessions
                            SET packet_count = packet_count + 1,
                                last_packet_time = %s
                            WHERE id = %s
                        """, (now, session_id))
                else:
                    # 3. æ— æ´»åŠ¨ä¼šè¯ï¼Œåˆ›å»ºæ–°ä¼šè¯ï¼ˆç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹ï¼Œstatus='pending'ï¼‰
                    cur.execute("""
                        INSERT INTO attack_sessions
                        (src_ip, anomaly_type, start_time, last_packet_time, packet_count, is_active, status)
                        VALUES (%s, %s, %s, %s, 1, 1, 'pending')
                    """, (src_ip, anomaly_type, now, now))
                    
                    self.logger.info(f"ğŸ†• [attack_session] {src_ip} {anomaly_type} é¦–æ¬¡æ£€æµ‹ï¼Œåˆ›å»ºæ–°ä¼šè¯")
                
                conn.commit()
        except Exception as e:
            if conn: conn.rollback()
            self.logger.error(f"[attack_sessions] è®°å½•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()  # âœ… æ‰“å°å®Œæ•´é”™è¯¯å †æ ˆ
        finally:
            if conn: conn.close()

    # ========== â‘¡ é™é€Ÿäº‹ä»¶ï¼š1 åˆ†é’Ÿåˆå¹¶ï¼Œä¸åŒåŸå› åˆ†å¼€ ==========
    def _log_limit_session(self, src_ip: str, reason: str, kbps: int):
        """
        åŒä¸€ IPã€åŒä¸€é™é€ŸåŸå› ã€1 åˆ†é’Ÿå†…åªè®° 1 æ¬¡ï¼›
        ä¸åŒåŸå› ç«‹å³æ–°å¼€ä¸€è¡Œã€‚
        """
        conn = None
        try:
            minute = time.strftime('%Y-%m-%d %H:%M:00')   # å½“å‰åˆ†é’Ÿ
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                sql = """
                    SELECT id FROM limit_sessions
                    WHERE src_ip = %s
                      AND reason = %s
                      AND start_time = %s
                """
                cur.execute(sql, (src_ip, reason, minute))
                row = cur.fetchone()
                if row:                      # 60 ç§’å†…å·²å­˜åœ¨ â†’ åªæ›´æ–°é€Ÿç‡
                    cur.execute(
                        "UPDATE limit_sessions SET kbps = %s WHERE id = %s",
                        (kbps, row[0]))
                else:                        # æ–°ä¸€åˆ†é’Ÿ or æ–°åŸå›  â†’ æ’æ–°è¡Œ
                    cur.execute(
                        """INSERT INTO limit_sessions (src_ip, reason, start_time, kbps)
                           VALUES (%s, %s, %s, %s)""",
                        (src_ip, reason, minute, kbps))
                conn.commit()
        except Exception as e:
            if conn: conn.rollback()
            self.logger.error(f"[limit_sessions] åˆ†é’Ÿåˆå¹¶å¤±è´¥: {e}")
        finally:
            if conn: conn.close()

    # ========== â‘¢ è‡ªåŠ¨å…³é—­è¿‡æœŸæ”»å‡»ä¼šè¯ï¼ˆå®šæœŸæ‰§è¡Œï¼‰ ==========
    def _auto_close_attack_sessions_loop(self):
        """
        æ¯3ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œè‡ªåŠ¨å…³é—­è¶…è¿‡2ç§’æ— æ–°åŒ…çš„æ´»åŠ¨ä¼šè¯
        """
        while True:
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    # æŸ¥æ‰¾æ‰€æœ‰æ´»åŠ¨ä¼šè¯
                    cur.execute("""
                        SELECT id, src_ip, anomaly_type, start_time, last_packet_time
                        FROM attack_sessions
                        WHERE is_active = 1
                    """)
                    
                    rows = cur.fetchall()
                    now = datetime.now()
                    closed_count = 0
                    
                    for row in rows:
                        session_id, src_ip, anomaly_type, start_time, last_packet_time = row
                        
                        # âœ… å¤„ç†Noneå€¼
                        if last_packet_time is None:
                            continue  # è·³è¿‡æ²¡æœ‰last_packet_timeçš„è®°å½•
                        
                        # è®¡ç®—è·ç¦»æœ€åä¸€ä¸ªåŒ…çš„æ—¶é—´
                        time_diff = (now - last_packet_time).total_seconds()
                        
                        if time_diff > 2:
                            # è¶…è¿‡2ç§’æ— æ–°åŒ…ï¼Œå…³é—­ä¼šè¯
                            if start_time:
                                duration = (last_packet_time - start_time).total_seconds()
                            else:
                                duration = 0
                            
                            cur.execute("""
                                UPDATE attack_sessions
                                SET is_active = 0,
                                    end_time = %s,
                                    duration_seconds = %s,
                                    status = IFNULL(status, 'pending')
                                WHERE id = %s
                            """, (last_packet_time, int(duration), session_id))
                            
                            closed_count += 1
                            self.logger.info(f"â¹ï¸ [auto_close] {src_ip} {anomaly_type} ä¼šè¯#{session_id} è‡ªåŠ¨å…³é—­ï¼ˆæŒç»­{int(duration)}ç§’ï¼‰")
                    
                    if closed_count > 0:
                        conn.commit()
                        self.logger.info(f"âœ… [auto_close] æœ¬è½®å…³é—­ {closed_count} ä¸ªè¿‡æœŸä¼šè¯")
            except Exception as e:
                self.logger.error(f"[auto_close] è‡ªåŠ¨å…³é—­ä¼šè¯å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
            finally:
                # âœ… ä¿®å¤ï¼šä½¿ç”¨finallyç¡®ä¿åªå…³é—­ä¸€æ¬¡ï¼Œé¿å…"Already closed"é”™è¯¯
                if conn:
                    try:
                        conn.close()
                    except Exception as close_err:
                        self.logger.debug(f"[auto_close] å…³é—­è¿æ¥æ—¶å‡ºé”™ï¼ˆå·²å¿½ç•¥ï¼‰: {close_err}")
            
            hub.sleep(3)  # æ¯3ç§’æ£€æŸ¥ä¸€æ¬¡

    # ========== â‘£ è®¾å¤‡å¼‚å¸¸æ£€æµ‹å‡½æ•° ==========
    def _log_device_anomaly(self, anomaly_type, device_type, device_id, description, severity='medium'):
        """
        è®°å½•è®¾å¤‡å¼‚å¸¸åˆ°device_anomaliesè¡¨
        """
        conn = None
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO device_anomalies
                    (anomaly_type, device_type, device_id, description, severity, status)
                    VALUES (%s, %s, %s, %s, %s, 'pending')
                """, (anomaly_type, device_type, device_id, description, severity))
                conn.commit()
                self.logger.warning(f"ğŸ”§ [device_anomaly] {anomaly_type}: {description}")
        except Exception as e:
            self.logger.error(f"[device_anomaly] è®°å½•å¤±è´¥: {e}")
            if conn:
                conn.rollback()
        finally:
            if conn:
                conn.close()

    def _check_ip_subnet(self, src_ip):
        """
        æ£€æµ‹IPé…ç½®å¼‚å¸¸ï¼ˆä¸åœ¨åˆæ³•ç½‘æ®µï¼‰
        """
        self.logger.info(f"ğŸ” [_check_ip_subnet] æ£€æŸ¥IP: {src_ip}")
        
        # è·³è¿‡å·²æ£€æŸ¥è¿‡çš„IP
        if src_ip in self.ip_subnet_checked:
            self.logger.info(f"ğŸ” [_check_ip_subnet] IP {src_ip} å·²æ£€æŸ¥è¿‡ï¼Œè·³è¿‡")
            return
        
        try:
            # æ£€æŸ¥IPæ˜¯å¦åœ¨åˆæ³•ç½‘æ®µ
            ip_obj = ipaddress.ip_address(src_ip)
            subnet_obj = ipaddress.ip_network(self.VALID_SUBNET, strict=False)
            
            self.logger.info(f"ğŸ” [_check_ip_subnet] IPå¯¹è±¡: {ip_obj}, ç½‘æ®µå¯¹è±¡: {subnet_obj}")
            
            if ip_obj not in subnet_obj:
                self.logger.warning(f"âš ï¸ [_check_ip_subnet] IP {src_ip} ä¸åœ¨åˆæ³•ç½‘æ®µ {self.VALID_SUBNET}ï¼Œå‡†å¤‡è®°å½•å¼‚å¸¸")
                self._log_device_anomaly(
                    anomaly_type='IPé…ç½®å¼‚å¸¸',
                    device_type='host',
                    device_id=src_ip,
                    description=f'ä¸»æœºIP {src_ip} ä¸åœ¨åˆæ³•ç½‘æ®µ {self.VALID_SUBNET}',
                    severity='high'
                )
            else:
                self.logger.info(f"âœ… [_check_ip_subnet] IP {src_ip} åœ¨åˆæ³•ç½‘æ®µå†…")
            
            # æ ‡è®°ä¸ºå·²æ£€æŸ¥
            self.ip_subnet_checked.add(src_ip)
        except Exception as e:
            self.logger.error(f"âŒ [_check_ip_subnet] æ£€æŸ¥IP {src_ip} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

    def _device_anomaly_detection_loop(self):
        """
        âœ… å®šæ—¶æ£€æµ‹è®¾å¤‡å¼‚å¸¸ï¼ˆä¸ä¾èµ–packet_inäº‹ä»¶ï¼‰
        - æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡MACåœ°å€å†²çª
        - å®šæœŸæ£€æŸ¥IPé…ç½®å¼‚å¸¸ï¼ˆé€šè¿‡ARPè¡¨æˆ–æµé‡ç»Ÿè®¡ï¼‰
        """
        while True:
            try:
                hub.sleep(10)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
                
                # æ£€æŸ¥MACåœ°å€å†²çª
                self._check_mac_conflicts_periodic()
                
            except Exception as e:
                self.logger.error(f"âŒ è®¾å¤‡å¼‚å¸¸æ£€æµ‹å¾ªç¯å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
    
    def _check_mac_conflicts_periodic(self):
        """
        å®šæœŸæ£€æŸ¥MACåœ°å€å†²çªï¼ˆä¸ä¾èµ–packet_inï¼‰
        """
        try:
            # éå†æ‰€æœ‰äº¤æ¢æœºçš„MAC-ç«¯å£æ˜ å°„
            for dpid, mac_dict in self.mac_to_port.items():
                for mac, port in mac_dict.items():
                    # æ£€æŸ¥è¿™ä¸ªMACæ˜¯å¦åœ¨å…¶ä»–ç«¯å£å‡ºç°è¿‡
                    for other_dpid, other_mac_dict in self.mac_to_port.items():
                        if other_dpid == dpid:
                            continue
                        if mac in other_mac_dict:
                            other_port = other_mac_dict[mac]
                            if (dpid, port) != (other_dpid, other_port):
                                self.logger.warning(f"âš ï¸ MACå†²çªæ£€æµ‹: MAC {mac} åŒæ—¶å‡ºç°åœ¨äº¤æ¢æœº{dpid}ç«¯å£{port}å’Œäº¤æ¢æœº{other_dpid}ç«¯å£{other_port}")
                                self._log_device_anomaly(
                                    anomaly_type='MACåœ°å€å†²çª',
                                    device_type='host',
                                    device_id=mac,
                                    description=f'MAC {mac} åŒæ—¶å‡ºç°åœ¨äº¤æ¢æœº{dpid}ç«¯å£{port}å’Œäº¤æ¢æœº{other_dpid}ç«¯å£{other_port}',
                                    severity='high'
                                )
        except Exception as e:
            self.logger.error(f"âŒ MACå†²çªæ£€æµ‹å¤±è´¥: {e}")

    def _check_port_flapping(self, dpid, port_no):
        """
        æ£€æµ‹ç«¯å£é¢‘ç¹æŠ–åŠ¨ï¼ˆ60ç§’å†…up/downè¶…è¿‡5æ¬¡ï¼‰
        """
        key = (dpid, port_no)
        now = time.time()
        
        # è®°å½•çŠ¶æ€å˜åŒ–
        self.port_flap_tracker[key].append(now)
        
        # æ¸…ç†60ç§’å‰çš„è®°å½•
        self.port_flap_tracker[key] = [t for t in self.port_flap_tracker[key] if now - t < 60]
        
        # æ£€æµ‹æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        if len(self.port_flap_tracker[key]) > 5:
            self._log_device_anomaly(
                anomaly_type='ç«¯å£é¢‘ç¹æŠ–åŠ¨',
                device_type='switch',
                device_id=f'{dpid}:port{port_no}',
                description=f'äº¤æ¢æœº {dpid} ç«¯å£ {port_no} åœ¨60ç§’å†…up/down {len(self.port_flap_tracker[key])}æ¬¡',
                severity='medium'
            )
            # é‡ç½®è®¡æ•°å™¨ï¼Œé¿å…é‡å¤æŠ¥è­¦
            self.port_flap_tracker[key] = []

    def _check_mac_conflict(self, src_mac, dpid, in_port):
        """
        æ£€æµ‹MACåœ°å€å†²çªï¼ˆåŒä¸€MACå‡ºç°åœ¨ä¸åŒç«¯å£ï¼‰
        """
        if src_mac in self.mac_port_map:
            old_dpid, old_port = self.mac_port_map[src_mac]
            if (old_dpid, old_port) != (dpid, in_port):
                self._log_device_anomaly(
                    anomaly_type='MACåœ°å€å†²çª',
                    device_type='host',
                    device_id=src_mac,
                    description=f'MAC {src_mac} åŒæ—¶å‡ºç°åœ¨äº¤æ¢æœº{old_dpid}ç«¯å£{old_port} å’Œ äº¤æ¢æœº{dpid}ç«¯å£{in_port}',
                    severity='high'
                )
        
        # æ›´æ–°æ˜ å°„
        self.mac_port_map[src_mac] = (dpid, in_port)


    # ========== â‘¡ æ–°å¢ï¼šæŸ¥è¯¢æ¥å£ï¼ˆæµ‹è¯•ç”¨ï¼‰ ==========
    def get_attack_count(self, ip=None, days=1):
        """
        è¿”å›æœ€è¿‘ N å¤©æ¯ IP æ¯åè®®çš„çœŸå®æ”»å‡»æ¬¡æ•°
        å‰ç«¯æˆ– CLI å¯ç›´æ¥è°ƒå®ƒéªŒè¯
        """
        conn = None
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                if ip:
                    sql = """
                        SELECT anomaly_type, COUNT(*) AS cnt
                        FROM attack_sessions
                        WHERE src_ip = %s
                          AND start_time >= DATE_SUB(NOW(), INTERVAL %s DAY)
                        GROUP BY anomaly_type
                    """
                    cur.execute(sql, (ip, days))
                else:
                    sql = """
                        SELECT src_ip, anomaly_type, COUNT(*) AS cnt
                        FROM attack_sessions
                        WHERE start_time >= DATE_SUB(NOW(), INTERVAL %s DAY)
                        GROUP BY src_ip, anomaly_type
                    """
                    cur.execute(sql, (days,))
                return cur.fetchall()
        except Exception as e:
            self.logger.error(f"[get_attack_count] æŸ¥è¯¢å¤±è´¥: {e}")
            return []
        finally:
            if conn:
                conn.close()


    def _write_anomaly_db(self, entry):
        """å¼‚å¸¸æ—¥å¿—å®æ—¶æ’å…¥ anomaly_log è¡¨"""
        try:
            conn = self.get_db_conn()
            with conn.cursor() as cur:
                sql = """INSERT INTO anomaly_log (detect_time, src_ip, dst_ip, protocol, anomaly_type, details)
                         VALUES (%s, %s, %s, %s, %s, %s)"""
                cur.execute(sql, (entry['detect_time'],
                                  entry['src_ip'],
                                  entry.get('dst_ip', ''),
                                  entry.get('protocol', ''),
                                  entry['anomaly_type'],
                                  entry['details']))
                conn.commit()
        except Exception as e:
            self.logger.error(f"å®æ—¶å†™å¼‚å¸¸æ—¥å¿—å¤±è´¥: {e}")
            if self.db_conn:
                self.db_conn.rollback()

    # ---------------- å†™å¼‚å¸¸æ—¥å¿—ï¼ˆæ–‡ä»¶ + æ•°æ®åº“ï¼‰ ----------------
    def _write_anomaly(self, entry):
        try:
            if os.path.getsize(ANOMALY_LOG) >= LOG_MAX_SIZE:
                bk = f"{ANOMALY_LOG}.bak_{int(time.time())}"
                os.rename(ANOMALY_LOG, bk)
                self._init_anomaly_files()
            with open(ANOMALY_LOG, 'a', encoding='utf-8') as f:
                json.dump(entry, f, ensure_ascii=False)
                f.write('\n')
        except Exception as e:
            self.logger.error(f"å†™æ—¥å¿—å¤±è´¥: {e}")




    # ---------------- ç«¯å£ç†µ ----------------
    def _port_entropy(self, src_ip):
        ports = self.src_port_counter[src_ip]
        if not ports:
            return 0.0
        cnt = Counter(ports)
        total = sum(cnt.values())
        entropy = 0.0
        for v in cnt.values():
            p = v / total
            entropy -= p * math.log2(p) if p > 0 else 0
        return entropy

    # ---------------- æ¨¡å‹è®­ç»ƒ ----------------
    def _train_task(self):
        hub.sleep(10)
        self.logger.info("ğŸ“Š å¼€å§‹æ”¶é›†æ­£å¸¸æµé‡è®­ç»ƒå­¤ç«‹æ£®æ— â€¦")
        start = time.time()
        while time.time() - start < self.training_seconds:
            hub.sleep(1)
        feats = [f['features'] for f in self.flow_features_with_info]
        if len(feats) >= 5:
            self.isolation_model = IsolationForest(**ISOLATION_PARAM)
            self.isolation_model.fit(np.array(feats))
            with open(MODEL_PATH, 'wb') as f:
                pickle.dump({'model': self.isolation_model, 'contamination': ISOLATION_PARAM['contamination']}, f)
            self.is_training = False
            self.logger.info("âœ… å­¤ç«‹æ£®æ—è®­ç»ƒå®Œæˆ")
        else:
            self.logger.warning("âš ï¸ æ ·æœ¬ä¸è¶³ï¼Œ30s åé‡è¯•")
            hub.sleep(30)
            self._train_task()

    # ---------------- æ£€æµ‹å¾ªç¯ ----------------
    def _detect_loop(self):
        while True:
            if not self.is_training and self.isolation_model:
                self._iforest_detect()
            hub.sleep(2)

    def _iforest_detect(self):
        if not self.flow_features_with_info:
            return
        snapshot = self.flow_features_with_info.copy()
        if not snapshot:
            return
        feats = np.array([f['features'] for f in snapshot])
        if feats.shape[0] == 0:
            return
        preds = self.isolation_model.predict(feats)
        if preds.size != len(snapshot):
            self.logger.warning(f"[IF] predsé•¿åº¦{preds.size}ä¸snapshoté•¿åº¦{len(snapshot)}ä¸ä¸€è‡´ï¼Œè·³è¿‡æœ¬è½®")
            return
        for i, flow in enumerate(snapshot):
            if preds[i] == -1:
                # ç™½åå•ç›´æ¥è·³è¿‡
                if self.acl_check(flow['src_ip']) == 'white':
                    continue

                # ä½é€Ÿé—¸é—¨ï¼šé™ä½é˜ˆå€¼ä»¥æé«˜æ•æ„Ÿæ€§
                if flow['features'][0] < 500:  # å·²ä»2000è°ƒæ•´ä¸º1000
                    self.logger.debug(f"burst é€Ÿç‡{flow['features'][0]} ä½äºé—¸é—¨ï¼Œä»…è®°å½•")
                    continue

                # RAGä¸‰åˆ¤å·²åˆ é™¤ï¼Œåªä¿ç•™å­¤ç«‹æ£®æ—æ£€æµ‹
        # æ¸…ç†å·²å¤„ç†çš„æµé‡ç‰¹å¾ï¼Œä¿ç•™æœ€æ–°500æ¡
        self.flow_features_with_info = self.flow_features_with_info[len(snapshot):]
        if len(self.flow_features_with_info) > 500:
            self.flow_features_with_info = self.flow_features_with_info[-500:]


    # ---------------- ç»Ÿè®¡è¯·æ±‚ ----------------
    def _stats_loop(self):
        while True:
            hub.sleep(1)  # âœ… æ”¹å›æ¯1ç§’é‡‡é›†ä¸€æ¬¡ï¼ˆä¸ä¹‹å‰ä¸€è‡´ï¼‰
            for dp in self.datapaths.values():
                # âœ… åŒæ—¶è¯·æ±‚æµè¡¨ç»Ÿè®¡å’Œç«¯å£ç»Ÿè®¡
                dp.send_msg(dp.ofproto_parser.OFPFlowStatsRequest(dp))
                dp.send_msg(dp.ofproto_parser.OFPPortStatsRequest(dp, 0, dp.ofproto.OFPP_ANY))

    @set_ev_cls(ofp_event.EventOFPFlowStatsReply, MAIN_DISPATCHER)
    def stats_reply(self, ev):
        dpid = ev.msg.datapath.id
        
        # ç¼“å­˜æµè¡¨æ•°æ®ä¾›REST APIä½¿ç”¨
        flow_list = []
        for flow in ev.msg.body:
            self._extract_flow(flow, dpid)
            # å°†æµè¡¨è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸æ ¼å¼
            flow_dict = {
                'priority': flow.priority,
                'cookie': flow.cookie,
                'idle_timeout': flow.idle_timeout,
                'hard_timeout': flow.hard_timeout,
                'packet_count': flow.packet_count,
                'byte_count': flow.byte_count,
                'duration_sec': flow.duration_sec,
                'match': {k: str(v) for k, v in flow.match.items()},
                'actions': []
            }
            # è§£æactions
            for inst in flow.instructions:
                if hasattr(inst, 'actions'):
                    for act in inst.actions:
                        if hasattr(act, 'port'):
                            port = act.port
                            # è½¬æ¢OpenFlowç‰¹æ®Šç«¯å£å·ä¸ºå¯è¯»åç§°
                            port_name = self._get_port_name(port)
                            flow_dict['actions'].append({
                                'type': 'OUTPUT', 
                                'port': port,
                                'port_name': port_name
                            })
            flow_list.append(flow_dict)
        
        # æ›´æ–°ç¼“å­˜
        self.switch_flow_stats[dpid] = flow_list
        
        if self.flow_cache:
            self._write_db()

    def _get_port_name(self, port):
        """è½¬æ¢OpenFlowç«¯å£å·ä¸ºå¯è¯»åç§°"""
        # OpenFlowç‰¹æ®Šç«¯å£å®šä¹‰
        OFPP_MAX = 0xffffff00
        OFPP_IN_PORT = 0xfffffff8  # 4294967288
        OFPP_TABLE = 0xfffffff9     # 4294967289
        OFPP_NORMAL = 0xfffffffa    # 4294967290
        OFPP_FLOOD = 0xfffffffb     # 4294967291
        OFPP_ALL = 0xfffffffc       # 4294967292
        OFPP_CONTROLLER = 0xfffffffd # 4294967293
        OFPP_LOCAL = 0xfffffffe     # 4294967294
        OFPP_ANY = 0xffffffff       # 4294967295
        
        special_ports = {
            OFPP_IN_PORT: 'IN_PORT',
            OFPP_TABLE: 'TABLE',
            OFPP_NORMAL: 'NORMAL',
            OFPP_FLOOD: 'NORMAL',  # âœ… å°†FLOODæ˜¾ç¤ºä¸ºNORMAL
            OFPP_ALL: 'ALL',
            OFPP_CONTROLLER: 'NORMAL',  # âœ… å°†CONTROLLERæ˜¾ç¤ºä¸ºNORMAL
            OFPP_LOCAL: 'LOCAL',
            OFPP_ANY: 'ANY'
        }
        
        if port in special_ports:
            return special_ports[port]
        elif port < OFPP_MAX:
            return f"ç«¯å£{port}"
        else:
            return f"æœªçŸ¥({port})"

    def _extract_flow(self, flow, dpid):
        """
        å‚è€ƒæ—§ç‰ˆæœ¬smart_defense_switch.pyçš„é€»è¾‘
        åªå¤„ç†æ˜ç¡®åŒ…å«ipv4_srcå’Œipv4_dstçš„æµè¡¨ï¼Œè‡ªåŠ¨è¿‡æ»¤ARP/LLDPç­‰éIPv4æµ
        """
        match = flow.match
        if flow.duration_sec <= 0:
            return
        
        # âœ… ä¸¥æ ¼æ£€æŸ¥ï¼šå¿…é¡»æœ‰IPv4æºå’Œç›®æ ‡åœ°å€
        src_ip = match.get('ipv4_src')
        dst_ip = match.get('ipv4_dst')
        if not src_ip or not dst_ip:
            # ğŸ§¹ è‡ªåŠ¨è¿‡æ»¤æ‰ARPã€LLDPã€é»˜è®¤æµç­‰éIPv4æµè¡¨
            return
        
        proto_num = match.get('ip_proto')
        proto_map = {1: 'ICMP', 6: 'TCP', 17: 'UDP'}
        proto = proto_map.get(proto_num, 'IP')

        src_port = match.get('tcp_src') or match.get('udp_src') or 0
        dst_port = match.get('tcp_dst') or match.get('udp_dst') or 0
        src_mac = match.get('eth_src', '00:00:00:00:00:00')
        dst_mac = match.get('eth_dst', '00:00:00:00:00:00')

        # âœ… åªå¯¹çœŸå®IPv4æµåšå¼‚å¸¸æ£€æµ‹ä¸å…¥åº“
        pkt_rate = min(flow.packet_count / flow.duration_sec, 10000)
        byte_rate = min(flow.byte_count / flow.duration_sec, 1000000)
        is_arp = 1 if proto == 'ARP' else 0
        self.src_dst_counter[src_ip].add(dst_ip)
        if dst_port:
            self.src_port_counter[src_ip].add(dst_port)
        entropy = self._port_entropy(src_ip)
        features = [pkt_rate, byte_rate, is_arp, len(self.src_dst_counter[src_ip]), entropy]

        # ç‰¹å¾ç¼“å­˜ï¼ˆç”¨äºå¼‚å¸¸æ£€æµ‹ï¼‰
        self.flow_features_with_info.append({
            'src_ip': src_ip, 'dst_ip': dst_ip, 'protocol': proto,
            'features': features, 'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'packet_count': flow.packet_count, 'byte_count': flow.byte_count
        })

        # âœ… æ‰€æœ‰çœŸå®IPv4æµè¡¨å†™å…¥æ•°æ®åº“ï¼ˆç”¨äºæµé‡è¶‹åŠ¿ç»Ÿè®¡ï¼‰
        ts = time.strftime('%Y-%m-%d %H:%M:%S')
        self.flow_cache.append({
            'timestamp': ts,
            'datapath_id': f"{dpid:016d}",
            'src_ip': src_ip, 
            'dst_ip': dst_ip,
            'protocol': proto,
            'src_port': src_port, 
            'dst_port': dst_port,
            'src_mac': src_mac, 
            'dst_mac': dst_mac,
            'packet_count': flow.packet_count,
            'byte_count': flow.byte_count,
            'duration_sec': flow.duration_sec,
            'stats_day': ts[:10],
            'stats_hour': int(ts[11:13])
        })


    def _write_db(self):
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                sql = """INSERT INTO flow_stats
                         (timestamp, datapath_id, src_ip, dst_ip, protocol,
                          src_port, dst_port, src_mac, dst_mac,
                          packet_count, byte_count, duration_sec,
                          stats_day, stats_hour)
                         VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)"""
                args = [(r['timestamp'], r['datapath_id'], r['src_ip'], r['dst_ip'],
                         r['protocol'], r['src_port'], r['dst_port'],
                         r['src_mac'], r['dst_mac'],
                         r['packet_count'], r['byte_count'], r['duration_sec'],
                         r['stats_day'], r['stats_hour'])        # <-- æ–°å¢ä¸¤åˆ—
                        for r in self.flow_cache]
                cur.executemany(sql, args)
                conn.commit()
                # âœ… æ™ºèƒ½æ—¥å¿—ï¼šæ˜¾ç¤ºè¿‡æ»¤æ•ˆæœå’Œæµé‡ç»Ÿè®¡
                if len(args) > 0:
                    total_packets = sum(r['packet_count'] for r in self.flow_cache)
                    total_bytes = sum(r['byte_count'] for r in self.flow_cache)
                    
                    # ç»Ÿè®¡åè®®åˆ†å¸ƒ
                    protocol_stats = {}
                    for r in self.flow_cache:
                        proto = r['protocol']
                        protocol_stats[proto] = protocol_stats.get(proto, 0) + 1
                    
                    # ğŸ” ä¸´æ—¶è°ƒè¯•ï¼šæ˜¾ç¤ºæ‰€æœ‰å…¥åº“æ•°æ®çš„è¯¦ç»†ä¿¡æ¯
                    proto_str = ', '.join([f"{k}:{v}" for k, v in protocol_stats.items()])
                    self.logger.info(f"ğŸ“¥ ä¸»æœºæµé‡å…¥åº“ {len(args)}æ¡ (æ€»åŒ…æ•°={total_packets}, æ€»å­—èŠ‚={total_bytes}) [{proto_str}]")
                    
                    # ğŸ” æ˜¾ç¤ºå‰3æ¡è®°å½•çš„è¯¦ç»†ä¿¡æ¯ï¼Œå¸®åŠ©åˆ†æ
                    for i, record in enumerate(self.flow_cache[:3]):
                        self.logger.info(f"   [{i+1}] {record['src_ip']}->{record['dst_ip']} {record['protocol']} "
                                       f"sport={record['src_port']} dport={record['dst_port']} "
                                       f"pkts={record['packet_count']} bytes={record['byte_count']}")
                    
                    if len(self.flow_cache) > 3:
                        self.logger.info(f"   ... è¿˜æœ‰ {len(self.flow_cache)-3} æ¡è®°å½•")
        except Exception as e:
            self.logger.error(f"æ•°æ®åº“å†™å…¥å¤±è´¥: {e}")
            if conn:
                conn.rollback()
        finally:
            if conn:
                conn.close()
        self.flow_cache = []


    # ---------------- å®æ—¶å†™åº“çº¿ç¨‹ï¼ˆREALTIME_INSERT = True æ—¶å¯åŠ¨ï¼‰ ----------------
    def _realtime_insert_loop(self):
        while True:
            hub.sleep(1)
            if self.flow_cache:
                self._write_db()

    # ---------------- å®šæ—¶ä»»åŠ¡ ----------------
    def _cleanup_loop(self):
        while True:
            hub.sleep(60)
            now = time.time()
            for ip, exp in list(self.limited_ips.items()):
                if exp <= now:
                    del self.limited_ips[ip]
                    # â‘  æ¸… active è¡¨ â‘¡ å†™ log è¡¨
                    try:
                        conn = self.get_db_conn()
                        with conn.cursor() as cur:
                            cur.execute("DELETE FROM rate_limit_active WHERE src_ip = %s", (ip,))
                            cur.execute("""
                                INSERT INTO rate_limit_log (src_ip, operator, action, reason)
                                VALUES (%s, %s, %s, %s)
                            """, (ip, 'system', 'unlimit', 'é™é€Ÿåˆ°æœŸè‡ªåŠ¨è§£é™¤'))
                            conn.commit()
                    except Exception as e:
                        self.logger.error(f"å®šæ—¶æ¸…ç†é™é€Ÿè®°å½•å¤±è´¥: {e}")
                        if self.db_conn:
                            self.db_conn.rollback()

                    self.logger.info(f"ğŸ”“ é™é€Ÿåˆ°æœŸ {ip}ï¼Œå·²ä» active è¡¨ç§»é™¤")


    def _reset_loop(self):
        while True:
            hub.sleep(1)                       # æ¯ç§’ä¸€æ¬¡
            now = time.time()

            # 1) æ¯ç§’æ¸… ARP
            for v in self.arp_stats.values():
                v['count'] = 0
                v['last_time'] = now
                # é˜²æ­¢ MAC é›†åˆæ— é™å¢é•¿
                if len(v['macs']) > 5:
                    v['macs'] = set(list(v['macs'])[-3:])

            # âœ… 2) æ¯ç§’æ¸…é›¶TCP/UDP/ICMPç»Ÿè®¡ï¼ˆæŒç»­ç›‘æ§æ”»å‡»ï¼‰
            for v in self.tcp_flag_stats.values():
                v['syn'] = v['total'] = 0
                v['last'] = now
            for v in self.udp_stats.values():
                v['count'] = 0
                v['last'] = now
            for v in self.icmp_stats.values():
                v['count'] = 0
                v['last'] = now

            # 3) æ¯ 300 s æ¸…å…¶ä½™è®¡æ•°å™¨
            if int(now) % 300 == 0:
                self.src_dst_counter.clear()
                self.src_port_counter.clear()
                self.raw_pkt_counter.clear()




    def _summarize_loop(self):
        while True:
            hub.sleep(300)
            if not self.anomaly_cache:
                continue
            try:
                with open(SUMMARY_JSON, 'r', encoding='utf-8') as f:
                    summary = json.load(f)
            except Exception:
                summary = {"total_anomalies": 0, "anomaly_types": {}, "top_offenders": [], "daily": {}, "latest": []}
            ### å…³é”®ï¼šé˜²æ­¢ KeyError
            summary.setdefault('daily', {})
            summary.setdefault('latest', [])
            new_cnt = len(self.anomaly_cache)
            summary['total_anomalies'] += new_cnt
            for a in self.anomaly_cache:
                t = a['anomaly_type']
                summary['anomaly_types'][t] = summary['anomaly_types'].get(t, 0) + 1
            today = time.strftime('%Y-%m-%d')
            summary['daily'][today] = summary['daily'].get(today, 0) + new_cnt
            ip_cnt = defaultdict(int)
            for a in summary['latest'] + self.anomaly_cache:
                ip_cnt[a['src_ip']] += 1
            summary['top_offenders'] = [{"ip": ip, "count": c} for ip, c in
                                        sorted(ip_cnt.items(), key=lambda x: x[1], reverse=True)[:5]]
            summary['latest'] = (self.anomaly_cache + summary['latest'])[:10]
            with open(SUMMARY_JSON, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            self.logger.info(f"ğŸ“Š å¼‚å¸¸æ±‡æ€»å·²æ›´æ–°ï¼Œä»Šæ—¥ {today} +{new_cnt}")
            self.anomaly_cache = []

    # ========================================================================
    # Web æ¥å£  â€”â€”  èŠå¤© + ç®¡ç†å‘˜ AI æŒ‡ä»¤ + é•¿æœŸè®°å¿†ï¼ˆé‡å¯ä¸ä¸¢ï¼‰
    # ========================================================================
    def get_anomaly_summary(self, ip=None):
        try:
            with open(SUMMARY_JSON, 'r', encoding='utf-8') as f:
                s = json.load(f)
            if ip:
                return [a for a in s.get('latest', []) if a['src_ip'] == ip]
            return s
        except Exception:
            return {}

    def db_insert_chat(self, user_id: str, role: str, content: str):
        role = role if role in ('admin', 'user') else 'user'
        try:
            conn = self.get_db_conn()
            with conn.cursor() as cur:
                sql = "INSERT INTO chat_memory (user_id, role, content) VALUES (%s, %s, %s)"
                cur.execute(sql, (user_id, role, content))
                conn.commit()
        except Exception as e:
            self.logger.error(f"èŠå¤©å…¥åº“å¤±è´¥: {e}")
            if self.db_conn:
                self.db_conn.rollback()

    def db_get_chat_memory(self, user_id: str, limit: int = MEMORY_TURNS):
        try:
            conn = self.get_db_conn()
            with conn.cursor() as cur:
                sql = """SELECT role, content \
                         FROM chat_memory
                         WHERE user_id = %s
                         ORDER BY created_at DESC
                             LIMIT %s"""
                cur.execute(sql, (user_id, limit * 2))
                rows = cur.fetchall()
                return [{'role': r[0], 'content': r[1]} for r in rows[::-1]]
        except Exception as e:
            self.logger.error(f"è¯»å–è®°å¿†å¤±è´¥: {e}")
            return []
    
    # ---------------- å¡ç‰‡ï¼š4 ä¸ªçº¯æ•°å­—ï¼ˆçœŸå®äº‹ä»¶æ•°ï¼‰ ----------------
    def get_dashboard_cards(self):
        import datetime, pymysql
        from collections import Counter

        today_str = datetime.date.today().isoformat()
        yesterday_str = (datetime.date.today() - datetime.timedelta(days=1)).isoformat()
        conn = None
        try:
            conn = pymysql.connect(**DB_CONFIG, autocommit=True)
            with conn.cursor() as cur:
                # 1. å½“å‰é™é€Ÿ IP æ•°ï¼ˆå»é‡ï¼‰
                cur.execute("SELECT COUNT(DISTINCT src_ip) FROM rate_limit_active")
                current_limit_cnt = int(cur.fetchone()[0])

                # 2. ä»Šæ—¥æ–°å¢é™é€Ÿï¼ˆçœŸå®æ¬¡æ•°ï¼‰
                cur.execute("""
                    SELECT COUNT(*)
                    FROM limit_sessions
                    WHERE DATE(start_time) = %s
                """, (today_str,))
                today_new_limit = int(cur.fetchone()[0])

                # 2.1 æ˜¨æ—¥æ–°å¢é™é€Ÿï¼ˆç”¨äºè®¡ç®—ç¯æ¯”ï¼‰
                cur.execute("""
                    SELECT COUNT(*)
                    FROM limit_sessions
                    WHERE DATE(start_time) = %s
                """, (yesterday_str,))
                yesterday_new_limit = int(cur.fetchone()[0])

                # è®¡ç®—ä»Šæ—¥æ–°å¢é™é€Ÿçš„ç¯æ¯”
                if yesterday_new_limit > 0:
                    today_limit_change_pct = round(((today_new_limit - yesterday_new_limit) / yesterday_new_limit) * 100)
                else:
                    today_limit_change_pct = 0 if today_new_limit == 0 else 100

                # 2.2 æ˜¨æ—¥å½“å‰é™é€Ÿæ•°ï¼ˆç”¨äºè®¡ç®—ç¯æ¯”ï¼‰
                cur.execute("""
                    SELECT COUNT(DISTINCT src_ip)
                    FROM rate_limit_active
                    WHERE DATE(created_at) = %s
                """, (yesterday_str,))
                yesterday_limit_cnt = int(cur.fetchone()[0])

                # è®¡ç®—å½“å‰é™é€Ÿæ•°çš„ç¯æ¯”
                if yesterday_limit_cnt > 0:
                    current_limit_change_pct = round(((current_limit_cnt - yesterday_limit_cnt) / yesterday_limit_cnt) * 100)
                else:
                    current_limit_change_pct = 0 if current_limit_cnt == 0 else 100

                # 3. ä¸»è¦é™é€ŸåŸå› ï¼ˆçœŸå®æœ€å¤šï¼‰
                cur.execute("""
                    SELECT reason, COUNT(*) AS cnt
                    FROM limit_sessions
                    WHERE DATE(start_time) = %s
                    GROUP BY reason
                    ORDER BY cnt DESC
                    LIMIT 1
                """, (today_str,))
                row = cur.fetchone()
                top_reason = row[0] if row else "æ— æ•°æ®"

                # 4. é«˜é¢‘é™é€Ÿ IPï¼ˆçœŸå®è¢«é™é€Ÿæ¬¡æ•°ï¼‰
                cur.execute("""
                    SELECT src_ip, COUNT(*) AS real_times
                    FROM limit_sessions
                    WHERE DATE(start_time) = %s
                    GROUP BY src_ip
                    ORDER BY real_times DESC
                    LIMIT 1
                """, (today_str,))
                row = cur.fetchone()
                top_ip = row[0] if row else "æ— æ•°æ®"
                top_ip_count = int(row[1]) if row else 0
        except Exception as e:
            self.logger.error(f"get_dashboard_cards error: {e}")
            current_limit_cnt = today_new_limit = 0
            current_limit_change_pct = today_limit_change_pct = 0
            top_reason = top_ip = "æ— æ•°æ®"
            top_ip_count = 0
        finally:
            if conn:
                conn.close()

        return {
            "current_limit_cnt": current_limit_cnt,
            "current_limit_change_pct": current_limit_change_pct,
            "today_new_limit": today_new_limit,
            "today_limit_change_pct": today_limit_change_pct,
            "top_reason": top_reason,
            "top_ip": top_ip,
            "top_ip_count": top_ip_count
        }







# -------------- ä»¥ä¸‹æ•´æ®µç›´æ¥æ›¿æ¢åŸ ChatController --------------
class ChatController(ControllerBase):
    def __init__(self, req, link, data, **config):
        super(ChatController, self).__init__(req, link, data, **config)
        self.ctrl = data['ctrl']

    # ---------------- HTTP å•è½®æ¥å£ï¼ˆcurl ç”¨ï¼‰ ----------------
    @route('chat', '/v1/chat', methods=['POST'])
    def chat(self, req, **_):
        try:
            body = json.loads(req.body.decode('utf-8'))
            # âœ… æ”¯æŒusernameå’Œuser_idä¸¤ç§æ–¹å¼
            username = body.get('username') or body.get('user_id', 'anonymous')
            user_text = body.get('user', '').strip()
            
            self.ctrl.logger.info(f"[CHAT API] æ”¶åˆ°è¯·æ±‚ - username: {username}, message: {user_text[:50]}")
        except Exception as e:
            self.ctrl.logger.error(f"[CHAT API] JSONè§£æå¤±è´¥: {e}")
            return self._json_resp({'error': 'invalid json'}, 400)
        reply = self._process_one_shot(username, user_text)
        return self._json_resp({'reply': reply})

    @route('anomalies_day', '/v1/anomalies/day', methods=['GET'])
    def get_anomalies_day(self, req, **_):
        """æœ€è¿‘ 1 å¤©å¼‚å¸¸æ•°æ®"""
        return self._get_anomalies_by_hours(24)

    @route('anomalies_3days', '/v1/anomalies/3days', methods=['GET'])
    def get_anomalies_3days(self, req, **_):
        """æœ€è¿‘ 3 å¤©å¼‚å¸¸æ•°æ®"""
        return self._get_anomalies_by_hours(72)

    @route('anomalies_7days', '/v1/anomalies/7days', methods=['GET'])
    def get_anomalies_7days(self, req, **_):
        """æœ€è¿‘ 7 å¤©å¼‚å¸¸æ•°æ®"""
        return self._get_anomalies_by_hours(168)
    
    @route('attack_sessions', '/v1/attack_sessions', methods=['GET'])
    def get_attack_sessions(self, req, **_):
        """
        æŸ¥è¯¢æ”»å‡»ä¼šè¯æ•°æ®ï¼ˆä»attack_sessionsè¡¨ï¼‰
        æ¯ä¸ªä¼šè¯ä»£è¡¨ä¸€æ¬¡çœŸå®çš„æ”»å‡»ï¼Œè€Œä¸æ˜¯å•ä¸ªæ•°æ®åŒ…
        å¦‚æœattack_sessionsè¡¨ä¸å­˜åœ¨ï¼Œé™çº§ä½¿ç”¨anomaly_logå¹¶å»é‡
        """
        conn = None
        try:
            # è·å–æŸ¥è¯¢å‚æ•°
            hours = int(req.params.get('hours', 12))  # é»˜è®¤12å°æ—¶
            limit = req.params.get('limit', 10)  # é»˜è®¤è¿”å›10æ¡
            
            self.ctrl.logger.info(f"[attack_sessions] æŸ¥è¯¢å‚æ•°: hours={hours}, limit={limit}")
            
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # å…ˆæ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                cur.execute("SHOW TABLES LIKE 'attack_sessions'")
                table_exists = cur.fetchone() is not None
                
                if not table_exists:
                    self.ctrl.logger.warning("âš ï¸ attack_sessionsè¡¨ä¸å­˜åœ¨ï¼Œé™çº§ä½¿ç”¨anomaly_logå¹¶å»é‡")
                    # âœ… é™çº§æ–¹æ¡ˆï¼šä»anomaly_logæŸ¥è¯¢å¹¶æŒ‰IP+ç±»å‹å»é‡ï¼ˆä¸æŸ¥è¯¢dst_ipä»¥å…¼å®¹ï¼‰
                    sql = """
                        SELECT 
                            src_ip,
                            anomaly_type,
                            MAX(detect_time) as latest_time,
                            COUNT(*) as packet_count,
                            MAX(details) as details
                        FROM anomaly_log
                        WHERE detect_time >= DATE_SUB(NOW(), INTERVAL %s HOUR)
                        GROUP BY src_ip, anomaly_type
                        ORDER BY latest_time DESC
                        LIMIT %s
                    """
                    cur.execute(sql, (hours, int(limit)))
                    rows = cur.fetchall()
                    
                    # æ ¼å¼åŒ–æ•°æ®ï¼ˆä»anomaly_logï¼‰
                    data = []
                    for idx, row in enumerate(rows, 1):
                        latest_time = row[2]  # âœ… è°ƒæ•´ç´¢å¼•
                        data.append({
                            'id': idx,
                            'src_ip': row[0],
                            'dst_ip': '',  # âœ… ç©ºå­—ç¬¦ä¸²ï¼Œä¸æŸ¥è¯¢
                            'type': row[1],
                            'anomaly_type': row[1],
                            'start_time': latest_time.strftime('%Y-%m-%d %H:%M:%S') if latest_time else '',
                            'end_time': latest_time.strftime('%Y-%m-%d %H:%M:%S') if latest_time else '',
                            'timestamp': int(latest_time.timestamp() * 1000) if latest_time else 0,
                            'detect_time': latest_time.strftime('%Y-%m-%d %H:%M:%S') if latest_time else '',
                            'packet_count': row[3] or 0,
                            'details': row[4] or ''
                        })
                    
                else:
                    # âœ… æ­£å¸¸æŸ¥è¯¢attack_sessionsè¡¨ï¼ˆè¿”å›æ‰€æœ‰æ•°æ®ï¼Œä¸è¿‡æ»¤statusï¼‰
                    # âš ï¸ ç‰¹æ®Šå¤„ç†ï¼šhours=24æ—¶ï¼ŒæŸ¥è¯¢ä»Šæ—¥0ç‚¹å¼€å§‹ï¼Œè€Œä¸æ˜¯æœ€è¿‘24å°æ—¶
                    # å°è¯•æŸ¥è¯¢dst_ipå­—æ®µï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸ºç©º
                    
                    # âœ… ç›´æ¥ä½¿ç”¨ä¸åŒ…å«dst_ipçš„æŸ¥è¯¢ï¼ˆå› ä¸ºattack_sessionsè¡¨æ²¡æœ‰dst_ipå­—æ®µï¼‰
                    if hours == 24:
                        # ä»Šæ—¥0ç‚¹å¼€å§‹
                        sql = """
                            SELECT 
                                id,
                                src_ip,
                                anomaly_type,
                                start_time,
                                packet_count,
                                IFNULL(status, 'pending') as status
                            FROM attack_sessions
                            WHERE DATE(start_time) = CURDATE()
                            ORDER BY start_time DESC
                            LIMIT %s
                        """
                        params = (int(limit),)
                        self.ctrl.logger.info(f"ğŸ“… æŸ¥è¯¢ä»Šæ—¥æ•°æ®ï¼ˆä»0ç‚¹å¼€å§‹ï¼‰: DATE(start_time) = CURDATE()")
                    else:
                        # æœ€è¿‘Nå°æ—¶
                        sql = """
                            SELECT 
                                id,
                                src_ip,
                                anomaly_type,
                                start_time,
                                packet_count,
                                IFNULL(status, 'pending') as status
                            FROM attack_sessions
                            WHERE start_time >= DATE_SUB(NOW(), INTERVAL %s HOUR)
                            ORDER BY start_time DESC
                            LIMIT %s
                        """
                        params = (hours, int(limit))
                    
                    # æ‰§è¡ŒæŸ¥è¯¢ï¼ˆä¸å†å°è¯•æŸ¥è¯¢dst_ipå­—æ®µï¼‰
                    cur.execute(sql, params)
                    rows = cur.fetchall()
                    has_dst_ip = False  # attack_sessionsè¡¨æ²¡æœ‰dst_ipå­—æ®µ
                    
                    # æ ¼å¼åŒ–æ•°æ®ï¼ˆä»attack_sessionsï¼‰
                    self.ctrl.logger.info(f"âœ… æŸ¥è¯¢attack_sessionsæˆåŠŸ: hours={hours}, è¿”å›{len(rows)}æ¡è®°å½•")
                    if len(rows) > 0:
                        self.ctrl.logger.info(f"ğŸ“‹ ç¬¬ä¸€æ¡æ•°æ®æ—¶é—´: {rows[0][4] if has_dst_ip else rows[0][3]}")
                    
                    data = []
                    for row in rows:
                        if has_dst_ip:
                            row_id = row[0]
                            src_ip = row[1]
                            dst_ip = row[2] or ''
                            anomaly_type = row[3]
                            start_time = row[4]
                            packet_count = row[5]
                            status = row[6]
                        else:
                            row_id = row[0]
                            src_ip = row[1]
                            dst_ip = ''
                            anomaly_type = row[2]
                            start_time = row[3]
                            packet_count = row[4]
                            status = row[5]
                        
                        # æ ¹æ®packet_countç”Ÿæˆdetails
                        if packet_count is None:
                            details = 'ç®¡ç†å‘˜è®¤å®š'
                        else:
                            details = f'{packet_count} ä¸ªå¼‚å¸¸æ•°æ®åŒ…'
                        
                        # âœ… æ ¹æ®æ”»å‡»ç±»å‹åˆ¤æ–­ä¸¥é‡ç¨‹åº¦
                        severity = 'low'  # é»˜è®¤ä½é£é™©
                        if anomaly_type in ['SYN Flood', 'UDP Flood', 'ICMP Flood']:
                            severity = 'high'  # DDoSæ”»å‡»ä¸ºé«˜é£é™©
                        elif anomaly_type in ['ARP æ¬ºéª—', 'ARPæ¬ºéª—']:
                            severity = 'high'  # ARPæ¬ºéª—ä¸ºé«˜é£é™©
                        elif anomaly_type in ['é»‘åå•å…³è”', 'å¸¦å®½è¶…é™']:
                            severity = 'medium'  # ä¸­ç­‰é£é™©
                        
                        data.append({
                            'id': row_id,
                            'src_ip': src_ip,
                            'dst_ip': dst_ip,
                            'type': anomaly_type,
                            'anomaly_type': anomaly_type,
                            'start_time': start_time.strftime('%Y-%m-%d %H:%M:%S') if start_time else '',
                            'end_time': start_time.strftime('%Y-%m-%d %H:%M:%S') if start_time else '',
                            'timestamp': int(start_time.timestamp() * 1000) if start_time else 0,
                            'detect_time': start_time.strftime('%Y-%m-%d %H:%M:%S') if start_time else '',
                            'packet_count': packet_count,
                            'details': details,
                            'status': status,
                            'severity': severity  # âœ… æ·»åŠ é£é™©ç­‰çº§
                        })
            
            self.ctrl.logger.info(f"âœ… æŸ¥è¯¢attack_sessionsæˆåŠŸ: {hours}å°æ—¶å†…å…±{len(data)}æ¡")
            return self._json_resp(data)
            
        except Exception as e:
            self.ctrl.logger.error(f"âŒ æŸ¥è¯¢attack_sessionså¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'error': str(e)}, 500)
        finally:
            if conn:
                conn.close()
                self.ctrl.logger.debug("[attack_sessions] æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    @route('handled_ips', '/v1/handled-ips', methods=['GET'])
    def get_handled_ips(self, req, **_):
        """
        æŸ¥è¯¢å·²å¤„ç†çš„IPåˆ—è¡¨ï¼ˆä»limit_sessionsè¡¨è·å–å†å²é™é€Ÿè®°å½•ï¼‰
        è¿”å›æŒ‡å®šå¤©æ•°å†…æœ‰é™é€Ÿè®°å½•çš„å»é‡IPåˆ—è¡¨
        ç‰¹æ®Šå¤„ç†ï¼šå½“days=1æ—¶ï¼ŒæŸ¥è¯¢ä»Šæ—¥ï¼ˆä»0ç‚¹åˆ°ç°åœ¨ï¼‰è€Œéæœ€è¿‘24å°æ—¶
        """
        conn = None
        try:
            days = int(req.params.get('days', 1))  # é»˜è®¤æœ€è¿‘1å¤©
            days = max(1, min(days, 7))  # é™åˆ¶åœ¨1-7å¤©
            
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                cur.execute("SHOW TABLES LIKE 'limit_sessions'")
                table_exists = cur.fetchone() is not None
                
                if not table_exists:
                    self.ctrl.logger.warning("âš ï¸ limit_sessionsè¡¨ä¸å­˜åœ¨")
                    return self._json_resp({'ips': []})
                
                # âœ… å½“days=1æ—¶ï¼Œä½¿ç”¨CURDATE()æŸ¥è¯¢ä»Šæ—¥æ•°æ®ï¼ˆä¸Dashboardä¸€è‡´ï¼‰
                if days == 1:
                    sql = """
                        SELECT DISTINCT src_ip 
                        FROM limit_sessions
                        WHERE DATE(start_time) = CURDATE()
                    """
                    cur.execute(sql)
                    time_desc = "ä»Šæ—¥"
                else:
                    sql = """
                        SELECT DISTINCT src_ip 
                        FROM limit_sessions
                        WHERE start_time >= DATE_SUB(NOW(), INTERVAL %s DAY)
                    """
                    cur.execute(sql, (days,))
                    time_desc = f"æœ€è¿‘{days}å¤©"
                
                rows = cur.fetchall()
                ips = [row[0] for row in rows if row[0]]
                
                self.ctrl.logger.info(f"âœ… æŸ¥è¯¢handled_ipsæˆåŠŸ: {time_desc}å†…æœ‰{len(ips)}ä¸ªIPè¢«å¤„ç†è¿‡")
                return self._json_resp({'ips': ips, 'count': len(ips), 'days': days})
                
        except Exception as e:
            self.ctrl.logger.error(f"âŒ æŸ¥è¯¢handled_ipså¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'error': str(e), 'ips': []}, 500)
        finally:
            if conn:
                conn.close()
    
    @route('attack_sessions_trend', '/v1/attack-sessions/trend', methods=['GET'])
    def get_attack_sessions_trend(self, req, **_):
        """
        è·å–attack_sessionsçš„æ—¶é—´è¶‹åŠ¿æ•°æ®ï¼ˆæŒ‰å°æ—¶ç»Ÿè®¡ä¼šè¯æ•°é‡ï¼‰
        ç”¨äºå¼‚å¸¸æ£€æµ‹é¡µé¢çš„"å¼‚å¸¸æ—¶é—´è¶‹åŠ¿"å›¾è¡¨
        å‚æ•°: hours - æ—¶é—´èŒƒå›´ï¼ˆé»˜è®¤24å°æ—¶ï¼‰
        è¿”å›: [{hour: '11-08 14:00', count: 5}, ...]ï¼ˆåŒ…å«æ—¥æœŸï¼‰
        """
        conn = None
        try:
            hours = int(req.params.get('hours', 24))
            hours = max(1, min(hours, 168))  # é™åˆ¶åœ¨1-168å°æ—¶ï¼ˆ7å¤©ï¼‰
            
            # âœ… ä½¿ç”¨ç‹¬ç«‹è¿æ¥ï¼Œé¿å…å½±å“æŒä¹…è¿æ¥
            conn = pymysql.connect(**DB_CONFIG, autocommit=True)
            with conn.cursor() as cur:
                # âœ… ç»Ÿä¸€æŸ¥è¯¢é€»è¾‘ï¼šæŒ‰å°æ—¶åˆ†ç»„ï¼Œæ—¶é—´æ ¼å¼åŒ…å«æ—¥æœŸ
                sql = """
                    SELECT 
                        DATE_FORMAT(start_time, '%%m-%%d %%H:00') as hour,
                        COUNT(*) as count
                    FROM attack_sessions
                    WHERE start_time >= DATE_SUB(NOW(), INTERVAL %s HOUR)
                    GROUP BY DATE_FORMAT(start_time, '%%m-%%d %%H:00')
                    ORDER BY hour
                """
                cur.execute(sql, (hours,))
                
                rows = cur.fetchall()
                trend_data = [{'hour': row[0], 'count': row[1]} for row in rows]
                
                # æ—¶é—´æè¿°
                if hours == 24:
                    time_desc = "æœ€è¿‘24å°æ—¶"
                elif hours == 72:
                    time_desc = "æœ€è¿‘3å¤©"
                elif hours == 168:
                    time_desc = "æœ€è¿‘7å¤©"
                else:
                    time_desc = f"æœ€è¿‘{hours}å°æ—¶"
                
                self.ctrl.logger.info(f"âœ… æŸ¥è¯¢attack_sessions_trendæˆåŠŸ: {time_desc}å†…æœ‰{len(trend_data)}ä¸ªæ—¶é—´ç‚¹")
                return self._json_resp({
                    'success': True,
                    'data': trend_data,
                    'hours': hours,
                    'message': f'{time_desc}çš„æ”»å‡»ä¼šè¯è¶‹åŠ¿'
                })
                
        except Exception as e:
            self.ctrl.logger.error(f"âŒ æŸ¥è¯¢attack_sessions_trendå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'success': False, 'error': str(e), 'data': []}, 500)
        finally:
            if conn:
                conn.close()
    
    @route('update_attack_status', '/v1/attack-sessions/update-status', methods=['POST'])
    def update_attack_status(self, req, **_):
        """
        æ›´æ–°attack_sessionsçš„å¤„ç†çŠ¶æ€
        å½“ç®¡ç†å‘˜å¤„ç†æ”»å‡»åï¼ˆå°ç¦/é™é€Ÿï¼‰ï¼Œæ ‡è®°ä¸ºå·²å¤„ç†
        
        å‚æ•°:
        - ip: æºIPåœ°å€
        - action: å¤„ç†åŠ¨ä½œ (blacklist/ratelimit)
        - handled_by: å¤„ç†äººï¼ˆé»˜è®¤'admin'ï¼‰
        """
        conn = None
        try:
            # è·å–è¯·æ±‚å‚æ•°
            body = req.json if hasattr(req, 'json') else {}
            src_ip = body.get('ip', '')
            action = body.get('action', '')
            handled_by = body.get('handled_by', 'admin')
            
            if not src_ip or not action:
                return self._json_resp({
                    'success': False,
                    'message': 'Missing required parameters: ip, action'
                }, 400)
            
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # æ›´æ–°è¯¥IPçš„æ‰€æœ‰pendingçŠ¶æ€çš„æ”»å‡»ä¸ºhandled
                sql = """
                    UPDATE attack_sessions
                    SET status = 'handled',
                        handled_by = %s,
                        handled_at = NOW(),
                        handle_action = %s
                    WHERE src_ip = %s 
                      AND IFNULL(status, 'pending') = 'pending'
                """
                cur.execute(sql, (handled_by, action, src_ip))
                conn.commit()
                affected_rows = cur.rowcount
                
                self.ctrl.logger.info(f"âœ… æ›´æ–°attack_sessionsçŠ¶æ€: IP={src_ip}, action={action}, å½±å“{affected_rows}æ¡è®°å½•")
                
                return self._json_resp({
                    'success': True,
                    'message': f'Successfully updated {affected_rows} attack sessions',
                    'affected_rows': affected_rows
                })
                
        except Exception as e:
            self.ctrl.logger.error(f"âŒ æ›´æ–°attack_sessionsçŠ¶æ€å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'success': False, 'error': str(e)}, 500)
        finally:
            if conn:
                conn.close()
    
    @route('handled_sessions_count', '/v1/handled-sessions/count', methods=['GET'])
    def get_handled_sessions_count(self, req, **_):
        """
        ç»Ÿè®¡ä¸åŒæ—¶é—´æ®µçš„å·²å¤„ç†æ”»å‡»ä¼šè¯æ•°é‡ï¼ˆstatus='handled'ï¼‰
        ç”¨äºå¼‚å¸¸æ£€æµ‹é¡µé¢çš„"å·²å¤„ç†å¼‚å¸¸"ç»Ÿè®¡å¡ç‰‡
        è¿”å›: {day: ä»Šæ—¥, three_days: æœ€è¿‘3å¤©, week: æœ€è¿‘7å¤©}
        """
        conn = None
        try:
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                cur.execute("SHOW TABLES LIKE 'attack_sessions'")
                table_exists = cur.fetchone() is not None
                
                if not table_exists:
                    self.ctrl.logger.warning("âš ï¸ attack_sessionsè¡¨ä¸å­˜åœ¨ï¼Œè¿”å›0")
                    return self._json_resp({
                        'day': 0,
                        'three_days': 0,
                        'week': 0
                    })
                
                # âœ… ç»Ÿè®¡ä»Šæ—¥å·²å¤„ç†ï¼ˆstatus='handled'ï¼‰
                cur.execute("""
                    SELECT COUNT(*) FROM attack_sessions
                    WHERE DATE(start_time) = CURDATE()
                      AND status = 'handled'
                """)
                day_count = cur.fetchone()[0] or 0
                
                # æ·»åŠ è°ƒè¯•ï¼šæŸ¥çœ‹ä»Šæ—¥handledè®°å½•
                cur.execute("""
                    SELECT id, src_ip, anomaly_type, start_time 
                    FROM attack_sessions
                    WHERE DATE(start_time) = CURDATE()
                      AND status = 'handled'
                    LIMIT 10
                """)
                debug_rows = cur.fetchall()
                self.ctrl.logger.info(f"ğŸ“Š ä»Šæ—¥handledè®°å½•ç¤ºä¾‹: {debug_rows}")
                
                # ç»Ÿè®¡æœ€è¿‘3å¤©å·²å¤„ç†
                cur.execute("""
                    SELECT COUNT(*) FROM attack_sessions
                    WHERE start_time >= DATE_SUB(NOW(), INTERVAL 3 DAY)
                      AND status = 'handled'
                """)
                three_days_count = cur.fetchone()[0] or 0
                
                # ç»Ÿè®¡æœ€è¿‘7å¤©å·²å¤„ç†
                cur.execute("""
                    SELECT COUNT(*) FROM attack_sessions
                    WHERE start_time >= DATE_SUB(NOW(), INTERVAL 7 DAY)
                      AND status = 'handled'
                """)
                week_count = cur.fetchone()[0] or 0
                
                self.ctrl.logger.info(f"ğŸ“Š å·²å¤„ç†å¼‚å¸¸ç»Ÿè®¡: ä»Šæ—¥={day_count}, 3å¤©={three_days_count}, 7å¤©={week_count}")
                
                result = {
                    'day': day_count,
                    'three_days': three_days_count,
                    'week': week_count
                }
                
                self.ctrl.logger.info(f"âœ… ç»Ÿè®¡å·²å¤„ç†æ”»å‡»ä¼šè¯æ•°é‡æˆåŠŸ: {result}")
                return self._json_resp(result)
                
        except Exception as e:
            self.ctrl.logger.error(f"âŒ ç»Ÿè®¡å·²å¤„ç†æ”»å‡»ä¼šè¯æ•°é‡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'error': str(e)}, 500)
        finally:
            if conn:
                conn.close()
    
    @route('attack_sessions_count', '/v1/attack-sessions/count', methods=['GET'])
    def get_attack_sessions_count(self, req, **_):
        """
        ç»Ÿè®¡ä¸åŒæ—¶é—´æ®µçš„æ”»å‡»ä¼šè¯æ•°é‡
        ç”¨äºå¼‚å¸¸æ£€æµ‹é¡µé¢çš„ç»Ÿè®¡å¡ç‰‡
        è¿”å›: {day: ä»Šæ—¥ï¼ˆä»0ç‚¹åˆ°ç°åœ¨ï¼‰, three_days: æœ€è¿‘3å¤©, week: æœ€è¿‘7å¤©}
        ç‰¹æ®Šå¤„ç†ï¼šdayå­—æ®µæ”¹ä¸ºæŸ¥è¯¢ä»Šæ—¥ï¼ˆä¸Dashboardä¸€è‡´ï¼‰
        """
        conn = None
        try:
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                cur.execute("SHOW TABLES LIKE 'attack_sessions'")
                table_exists = cur.fetchone() is not None
                
                if not table_exists:
                    self.ctrl.logger.warning("âš ï¸ attack_sessionsè¡¨ä¸å­˜åœ¨ï¼Œè¿”å›0")
                    return self._json_resp({
                        'day': 0,
                        'three_days': 0,
                        'week': 0
                    })
                
                # âœ… ç»Ÿè®¡ä»Šæ—¥ï¼ˆä»0ç‚¹åˆ°ç°åœ¨ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ”»å‡»ï¼Œä¸è¿‡æ»¤statusï¼‰
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                cur.execute("SELECT CURDATE() as today, NOW() as now")
                date_info = cur.fetchone()
                self.ctrl.logger.info(f"ğŸ“… å½“å‰æ—¥æœŸ: CURDATE()={date_info[0]}, NOW()={date_info[1]}")
                
                cur.execute("""
                    SELECT COUNT(*) FROM attack_sessions
                    WHERE DATE(start_time) = CURDATE()
                """)
                day_count = cur.fetchone()[0] or 0
                
                # ç»Ÿè®¡æœ€è¿‘3å¤©ï¼ˆæ‰€æœ‰æ”»å‡»ï¼‰
                cur.execute("""
                    SELECT COUNT(*) FROM attack_sessions
                    WHERE start_time >= DATE_SUB(NOW(), INTERVAL 3 DAY)
                """)
                three_days_count = cur.fetchone()[0] or 0
                
                # ç»Ÿè®¡æœ€è¿‘7å¤©ï¼ˆæ‰€æœ‰æ”»å‡»ï¼‰
                cur.execute("""
                    SELECT COUNT(*) FROM attack_sessions
                    WHERE start_time >= DATE_SUB(NOW(), INTERVAL 7 DAY)
                """)
                week_count = cur.fetchone()[0] or 0
                
                result = {
                    'day': day_count,
                    'three_days': three_days_count,
                    'week': week_count
                }
                
                self.ctrl.logger.info(f"âœ… ç»Ÿè®¡attack_sessionsæ•°é‡æˆåŠŸï¼ˆday=ä»Šæ—¥ï¼‰: {result}")
                return self._json_resp(result)
                
        except Exception as e:
            self.ctrl.logger.error(f"âŒ ç»Ÿè®¡attack_sessionsæ•°é‡å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'error': str(e)}, 500)
        finally:
            if conn:
                conn.close()
    
    def _get_anomalies_by_hours(self, hours: int):
        """ç»Ÿä¸€æŒ‰å°æ—¶æŸ¥å¼‚å¸¸ï¼Œè¿”å› JSON
        ç‰¹æ®Šå¤„ç†ï¼šå½“hours=24æ—¶ï¼ŒæŸ¥è¯¢ä»Šæ—¥ï¼ˆä»0ç‚¹åˆ°ç°åœ¨ï¼‰è€Œéæœ€è¿‘24å°æ—¶
        """
        try:
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # âœ… å½“hours=24æ—¶ï¼Œä½¿ç”¨CURDATE()æŸ¥è¯¢ä»Šæ—¥æ•°æ®ï¼ˆä¸Dashboardä¸€è‡´ï¼‰
                if hours == 24:
                    sql = """
                        SELECT detect_time, src_ip, dst_ip, anomaly_type, details
                        FROM anomaly_log
                        WHERE DATE(detect_time) = CURDATE()
                        ORDER BY detect_time DESC
                    """
                    cur.execute(sql)
                    time_desc = "ä»Šæ—¥"
                else:
                    sql = """
                        SELECT detect_time, src_ip, dst_ip, anomaly_type, details
                        FROM anomaly_log
                        WHERE detect_time >= DATE_SUB(NOW(), INTERVAL %s HOUR)
                        ORDER BY detect_time DESC
                    """
                    cur.execute(sql, (hours,))
                    time_desc = f"æœ€è¿‘{hours}å°æ—¶"
                
                rows = cur.fetchall()

            data = []
            for r in rows:
                detect_time = r[0]
                if hasattr(detect_time, 'strftime'):
                    detect_time = detect_time.strftime('%Y-%m-%d %H:%M:%S')
                data.append({
                    'detect_time': detect_time,
                    'src_ip': r[1] or '',
                    'dst_ip': r[2] or '',
                    'anomaly_type': r[3] or '',
                    'details': r[4] or ''
                })
            self.ctrl.logger.info(f"âœ… [anomalies] {time_desc}æŸ¥è¯¢åˆ°{len(data)}æ¡å¼‚å¸¸è®°å½•")
            return self._json_resp({'count': len(data), 'data': data})
        except Exception as e:
            self.ctrl.logger.error(f"âŒ [anomalies] æŸ¥è¯¢å¤±è´¥: {e}")
            return self._json_resp({'error': str(e)}, 500)

        # 0. MCPå·¥å…·è°ƒç”¨ï¼šåº”ç”¨é™é€Ÿ  POST /v1/rate/apply
    @route('rate_apply', '/v1/rate/apply', methods=['POST'])
    def rate_apply(self, req, **_):
        """
        MCPå·¥å…·è°ƒç”¨çš„é™é€Ÿæ¥å£ï¼ˆä¸å‰ç«¯/v1/limit/ipåŠŸèƒ½ç›¸åŒï¼‰
        body: {"ip":"192.168.1.200", "kbps":1024, "duration":300}
        """
        try:
            body = json.loads(req.body.decode('utf-8'))
            ip = body['ip']
            kbps = body.get('kbps', 1024)
            duration = body.get('duration', 300)  # ç§’
            reason = body.get('reason', 'MCPå·¥å…·é™é€Ÿ')
            operator = body.get('operator', 'system')
            
            # è½¬æ¢ç§’ä¸ºåˆ†é’Ÿ
            duration_minutes = max(1, duration // 60)
            
            self.ctrl.logger.info(f"[rate/apply] ip={ip}, kbps={kbps}, duration={duration}s, reason={reason}")
            
            # è°ƒç”¨é™é€Ÿå‡½æ•°
            success, actual_kbps, error_msg = self.ctrl._apply_rate_limit(
                ip, reason, kbps, operator=operator, duration_minutes=duration_minutes
            )
            
            if success:
                return self._json_resp({'success': True, 'message': f'âœ… å·²å¯¹ {ip} é™é€Ÿ {actual_kbps} kbps'})
            else:
                return self._json_resp({'success': False, 'message': f'âŒ é™é€Ÿå¤±è´¥: {error_msg}'}, 400)
        except Exception as e:
            self.ctrl.logger.error(f"[rate/apply] APIé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'success': False, 'message': f'âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}'}, 500)

        # 0.5 MCPå·¥å…·è°ƒç”¨ï¼šè§£é™¤é™é€Ÿ  DELETE /v1/rate/{ip}
    @route('rate_delete', '/v1/rate/{ip}', methods=['DELETE'])
    def rate_delete(self, req, ip, **_):
        """
        MCPå·¥å…·è°ƒç”¨çš„è§£é™¤é™é€Ÿæ¥å£
        """
        try:
            reason = req.params.get('reason', 'MCPå·¥å…·è§£é™¤')
            self.ctrl.logger.info(f"[rate/delete] è§£é™¤é™é€Ÿ: ip={ip}, reason={reason}")
            
            ok = self.ctrl._release_rate_limit(ip, operator='system', reason=reason)
            if ok:
                return self._json_resp({'success': True, 'message': f'âœ… å·²è§£é™¤ {ip} é™é€Ÿ'})
            else:
                return self._json_resp({'success': False, 'message': f'{ip} æš‚æ— é™é€Ÿè®°å½•'}, 404)
        except Exception as e:
            self.ctrl.logger.error(f"[rate/delete] APIé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'success': False, 'message': str(e)}, 500)

        # 1. å‰ç«¯è°ƒç”¨ï¼šæ‰‹åŠ¨é™é€Ÿ  POST /v1/limit/ip
    @route('limit_ip', '/v1/limit/ip', methods=['POST'])
    def limit_ip(self, req, **_):
        """
        å‰ç«¯æ‰‹åŠ¨é™é€Ÿæ¥å£
        æ”¯æŒFormDataå’ŒJSONä¸¤ç§æ ¼å¼
        body: {"ip":"192.168.1.200", "kbps":1024, "reason":"å‰ç«¯æ‰‹åŠ¨é™é€Ÿ", "duration_minutes":5, "operator":"admin"}
        """
        try:
            # âœ… å…¼å®¹FormDataå’ŒJSONä¸¤ç§æ ¼å¼
            content_type = req.headers.get('Content-Type', '')
            if 'application/x-www-form-urlencoded' in content_type:
                # FormDataæ ¼å¼
                from urllib.parse import parse_qs
                body_str = req.body.decode('utf-8')
                body_dict = parse_qs(body_str)
                ip = body_dict.get('ip', [''])[0]
                kbps = int(body_dict.get('kbps', ['1024'])[0])
                reason = body_dict.get('reason', ['å‰ç«¯æ‰‹åŠ¨é™é€Ÿ'])[0]
                duration_minutes = int(body_dict.get('duration_minutes', ['5'])[0])
                operator = body_dict.get('operator', ['admin'])[0]
            else:
                # JSONæ ¼å¼
                body = json.loads(req.body.decode('utf-8'))
                ip = body['ip']
                kbps = body.get('kbps', 1024)
                reason = body.get('reason', 'å‰ç«¯æ‰‹åŠ¨é™é€Ÿ')
                duration_minutes = body.get('duration_minutes', 5)
                operator = body.get('operator', 'admin')
            
            self.ctrl.logger.info(f"[é™é€ŸAPI] ip={ip}, kbps={kbps}, reason={reason}, duration={duration_minutes}min, operator={operator}")
            
            # è°ƒç”¨é™é€Ÿå‡½æ•°å¹¶è·å–è¿”å›å€¼
            success, actual_kbps, error_msg = self.ctrl._apply_rate_limit(
                ip, reason, kbps, operator=operator, duration_minutes=duration_minutes
            )
            
            if success:
                return self._json_resp({'success': True, 'message': f'âœ… å·²å¯¹ {ip} é™é€Ÿ {actual_kbps} kbps'})
            else:
                return self._json_resp({'success': False, 'message': f'âŒ é™é€Ÿå¤±è´¥: {error_msg}'}, 400)
        except Exception as e:
            self.ctrl.logger.error(f"[limit_ip] APIé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'success': False, 'message': f'âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}'}, 500)
    
    @route('dashboard_cards', '/v1/dashboard/cards', methods=['GET'])
    def dashboard_cards(self, req, **_):
        data = self.ctrl.get_dashboard_cards()
        return self._json_resp(data)


    # æ”¹é€Ÿç‡ï¼ˆkbps å¯æ•°å­—/å£è¯­ï¼‰
    @route('rate_change_speed', '/v1/rate/speed/{ip}', methods=['PUT'])
    def rate_change_speed(self, req, ip, **_):
        try:
            body = json.loads(req.body.decode('utf-8'))
            kbps = body['kbps']          # 512 / "é«˜é€Ÿ" / "1 Mbps"
            reason = body.get('reason', 'ç®¡ç†å‘˜è°ƒæ•´é€Ÿç‡')
            ctrl = self.ctrl

            # 1. æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å­˜åœ¨é™é€Ÿè®°å½•ï¼ˆè€Œä¸æ˜¯å†…å­˜ï¼‰
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    cur.execute("SELECT kbps FROM rate_limit_active WHERE src_ip = %s", (ip,))
                    row = cur.fetchone()
                    if not row:
                        return self._json_resp({'success': False, 'message': f'{ip} å½“å‰æ— é™é€Ÿ'}, 404)
            except Exception as e:
                ctrl.logger.error(f"âš ï¸ æŸ¥è¯¢æ•°æ®åº“å¤±è´¥: {e}")
                return self._json_resp({'success': False, 'message': f'æŸ¥è¯¢å¤±è´¥: {str(e)}'}, 500)
            finally:
                if conn:
                    conn.close()

            # 2. æ£€æŸ¥äº¤æ¢æœºè¿æ¥
            if not ctrl.datapaths:
                ctrl.logger.error(f"âŒ é€Ÿç‡è°ƒæ•´å¤±è´¥: {ip} - æ²¡æœ‰å¯ç”¨çš„äº¤æ¢æœº")
                return self._json_resp({'success': False, 'message': 'æ²¡æœ‰å¯ç”¨çš„äº¤æ¢æœºï¼Œè¯·æ£€æŸ¥äº¤æ¢æœºè¿æ¥'}, 503)

            # 3. è§£ææ¡£ä½
            if isinstance(kbps, str):
                kbps = kbps.strip()
                if re.search(r'ä½é€Ÿ', kbps, re.I):
                    kbps = 256
                elif re.search(r'ä¸­é€Ÿ', kbps, re.I):
                    kbps = 1024
                elif re.search(r'é«˜é€Ÿ', kbps, re.I):
                    kbps = 2048
                else:
                    m = re.search(r'(\d+)\s*kbps|(\d+)\s*m', kbps, re.I)
                    kbps = 1024
                    if m:
                        kbps = int(m.group(1)) if m.group(1) else int(m.group(2)) * 1024
            else:
                kbps = int(kbps)

            # 4. è·å–åŸæ¥çš„é€Ÿç‡ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            old_kbps = 1024  # é»˜è®¤å€¼
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    cur.execute("SELECT kbps FROM rate_limit_active WHERE src_ip = %s", (ip,))
                    row = cur.fetchone()
                    old_kbps = row[0] if row else 1024
            except Exception as e:
                ctrl.logger.error(f"âš ï¸ è·å–åŸå§‹é€Ÿç‡å¤±è´¥: {e}")
            finally:
                if conn:
                    conn.close()

            # 5. æ ¹æ®æ–°é€Ÿç‡é€‰æ‹©QoSé˜Ÿåˆ—ï¼ˆå›ºå®šä¸‰æ¡£ï¼‰
            if kbps <= 256:
                q = 1  # ä½é€Ÿé˜Ÿåˆ— 256Kbps
            elif kbps <= 1024:
                q = 2  # ä¸­é€Ÿé˜Ÿåˆ— 1024Kbps
            else:
                q = 3  # é«˜é€Ÿé˜Ÿåˆ— 2048Kbps
            
            # 6. ä»æ•°æ®åº“è¯»å–è¿‡æœŸæ—¶é—´ï¼Œè®¡ç®—hard_timeout
            hard_timeout = 300  # é»˜è®¤5åˆ†é’Ÿ
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    cur.execute("SELECT UNIX_TIMESTAMP(expire_at) FROM rate_limit_active WHERE src_ip = %s", (ip,))
                    row = cur.fetchone()
                    if row and row[0]:
                        hard_timeout = int(max(0, row[0] - time.time()))
                        ctrl.logger.info(f"[DEBUG] ä»æ•°æ®åº“è¯»å–è¿‡æœŸæ—¶é—´: {ip} expire_at={row[0]}, hard_timeout={hard_timeout}ç§’")
            except Exception as e:
                ctrl.logger.error(f"âš ï¸ è¯»å–è¿‡æœŸæ—¶é—´å¤±è´¥: {e}")
            finally:
                if conn:
                    conn.close()
            
            # 7. ä¸‹å‘OpenFlowæµè¡¨åˆ°æ‰€æœ‰äº¤æ¢æœº
            flow_success = False
            for dp in ctrl.datapaths.values():
                ofp, ps = dp.ofproto, dp.ofproto_parser
                match = ps.OFPMatch(eth_type=ether_types.ETH_TYPE_IP, ipv4_src=ip)
                acts = [ps.OFPActionSetQueue(queue_id=q), ps.OFPActionOutput(ofp.OFPP_NORMAL)]
                # âœ… ä¿®å¤ï¼šä»æ•°æ®åº“è¯»å–è¿‡æœŸæ—¶é—´ï¼Œç¡®ä¿hard_timeoutæ­£ç¡®
                ctrl._add_flow(dp, 50, match, acts, idle=0, hard=hard_timeout)
                flow_success = True
                ctrl.logger.info(f"âœ… æµè¡¨å·²æ›´æ–°: {ip} {old_kbps}â†’{kbps}Kbps, é˜Ÿåˆ—={q}, idle=0, hard={hard_timeout}ç§’")
            
            if not flow_success:
                ctrl.logger.error(f"âŒ æµè¡¨ä¸‹å‘å¤±è´¥: {ip} - æ²¡æœ‰å¯ç”¨çš„äº¤æ¢æœº")
                return self._json_resp({'success': False, 'message': 'æµè¡¨ä¸‹å‘å¤±è´¥'}, 500)

            # 8. æµè¡¨ä¸‹å‘æˆåŠŸåï¼Œæ›´æ–°æ•°æ®åº“
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    # âœ… åªæ›´æ–°é€Ÿç‡ï¼Œä¸ä¿®æ”¹é™é€ŸåŸå› 
                    affected_rows = cur.execute("""
                        UPDATE rate_limit_active
                        SET kbps = %s
                        WHERE src_ip = %s
                    """, (kbps, ip))
                    
                    ctrl.logger.info(f"ğŸ“ æ•°æ®åº“UPDATEå½±å“è¡Œæ•°: {affected_rows}")
                    
                    # ç”Ÿæˆç®€çŸ­çš„ä¸­æ–‡æè¿°ï¼ˆä¸‰æ¡£é™é€Ÿï¼‰
                    speed_names = {256: 'ä½é€Ÿ', 1024: 'ä¸­é€Ÿ', 2048: 'é«˜é€Ÿ'}
                    old_name = speed_names.get(old_kbps, str(old_kbps))
                    new_name = speed_names.get(kbps, str(kbps))
                    action_desc = f"è°ƒé€Ÿ:{old_name}â†’{new_name}"  # âœ… ç®€åŒ–æè¿°ï¼Œé¿å…è¶…é•¿
                    
                    # åœ¨logè¡¨ä¸­è®°å½•æ“ä½œï¼ˆactionä½¿ç”¨ä¸­æ–‡æè¿°ï¼‰
                    cur.execute("""
                        INSERT INTO rate_limit_log(src_ip,operator,action,reason,kbps)
                        VALUES (%s,%s,%s,%s,%s)
                    """, (ip, 'admin', action_desc, reason, kbps))
                    conn.commit()
                    
                    # âœ… éªŒè¯æ›´æ–°æ˜¯å¦æˆåŠŸ
                    cur.execute("SELECT kbps FROM rate_limit_active WHERE src_ip = %s", (ip,))
                    verify_row = cur.fetchone()
                    if verify_row:
                        actual_kbps = verify_row[0]
                        ctrl.logger.info(f"âœ… æ•°æ®åº“éªŒè¯æˆåŠŸ: {ip} é€Ÿç‡={actual_kbps}Kbps (é¢„æœŸ={kbps})")
                        if actual_kbps != kbps:
                            ctrl.logger.error(f"âš ï¸ æ•°æ®åº“å€¼ä¸åŒ¹é…! å®é™…={actual_kbps}, é¢„æœŸ={kbps}")
                    else:
                        ctrl.logger.error(f"âš ï¸ éªŒè¯å¤±è´¥: æœªæ‰¾åˆ° {ip} çš„è®°å½•")
            except Exception as e:
                ctrl.logger.error(f"âš ï¸ æ•°æ®åº“æ›´æ–°å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                if conn:
                    conn.rollback()
                # æµè¡¨å·²ç”Ÿæ•ˆï¼Œæ•°æ®åº“å¤±è´¥ä¸å½±å“è¿”å›ç»“æœ
            finally:
                if conn:
                    conn.close()
            
            return self._json_resp({'success': True, 'message': f'{ip} é€Ÿç‡å·²è°ƒæ•´ä¸º {kbps} kbps'})
        except Exception as e:
            ctrl.logger.error(f"âŒ é€Ÿç‡è°ƒæ•´å¼‚å¸¸: {ip} - {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'success': False, 'message': f'é€Ÿç‡è°ƒæ•´å¤±è´¥: {str(e)}'}, 500)

    # æ”¹æ—¶é•¿ï¼ˆç§’ï¼‰
    # ------------------------------------------------------------------
    # è°ƒæ•´é™é€Ÿå‰©ä½™æ—¶é•¿ï¼ˆå»¶é•¿æˆ–ç¼©çŸ­ï¼‰
    #  PUT /v1/rate/duration/{ip}
    #  body: {"extra_seconds":600,"reason":"åŠ é•¿10min"}  æ­£æ•°=å»¶é•¿ï¼Œè´Ÿæ•°=ç¼©çŸ­
    # ------------------------------------------------------------------
    @route('rate_change_duration', '/v1/rate/duration/{ip}', methods=['PUT'])
    def rate_change_duration(self, req, ip, **_):
        try:
            body = json.loads(req.body.decode('utf-8'))
            extra_sec = int(body['extra_seconds'])   # æ­£æ•°å»¶é•¿ï¼Œè´Ÿæ•°ç¼©çŸ­
            reason = body.get('reason', 'ç®¡ç†å‘˜è°ƒæ•´æ—¶é•¿')
            ctrl = self.ctrl

            # 1. æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å­˜åœ¨é™é€Ÿè®°å½•ï¼ˆè€Œä¸æ˜¯å†…å­˜ï¼‰
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    cur.execute("SELECT expire_at FROM rate_limit_active WHERE src_ip = %s", (ip,))
                    row = cur.fetchone()
                    if not row:
                        return self._json_resp({'success': False, 'message': f'{ip} å½“å‰æ— é™é€Ÿ'}, 404)
            except Exception as e:
                ctrl.logger.error(f"âš ï¸ æŸ¥è¯¢æ•°æ®åº“å¤±è´¥: {e}")
                return self._json_resp({'success': False, 'message': f'æŸ¥è¯¢å¤±è´¥: {str(e)}'}, 500)
            finally:
                if conn:
                    conn.close()

            # 2. æ£€æŸ¥äº¤æ¢æœºè¿æ¥
            if not ctrl.datapaths:
                ctrl.logger.error(f"âŒ æ—¶é•¿è°ƒæ•´å¤±è´¥: {ip} - æ²¡æœ‰å¯ç”¨çš„äº¤æ¢æœº")
                return self._json_resp({'success': False, 'message': 'æ²¡æœ‰å¯ç”¨çš„äº¤æ¢æœºï¼Œè¯·æ£€æŸ¥äº¤æ¢æœºè¿æ¥'}, 503)

            # 3. ä»æ•°æ®åº“è¯»å–å½“å‰è¿‡æœŸæ—¶é—´
            old_expire = None
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    cur.execute("SELECT UNIX_TIMESTAMP(expire_at) FROM rate_limit_active WHERE src_ip = %s", (ip,))
                    row = cur.fetchone()
                    old_expire = row[0] if row else time.time()
            except Exception as e:
                ctrl.logger.error(f"âš ï¸ è¯»å–è¿‡æœŸæ—¶é—´å¤±è´¥: {e}")
                old_expire = time.time()
            finally:
                if conn:
                    conn.close()

            # 4. è®¡ç®—æ–°è¿‡æœŸæ—¶é—´ï¼ˆä¸èƒ½æ—©äºç°åœ¨ï¼‰
            new_expire = max(time.time(), old_expire + extra_sec)
            if new_expire == time.time():
                # ç¼©çŸ­åˆ° <=0 â†’ ç›´æ¥è§£é™¤
                ok = ctrl._release_rate_limit(ip, operator='admin', reason=reason)
                return self._json_resp({'success': True, 'message': f'{ip} æ—¶é•¿å·²ç¼©çŸ­è‡³ 0ï¼Œå·²è§£é™¤'})

            # åŒæ—¶æ›´æ–°å†…å­˜ï¼ˆå¦‚æœIPåœ¨å†…å­˜ä¸­ï¼‰
            if ip in ctrl.limited_ips:
                ctrl.limited_ips[ip] = new_expire

            # 5. è·å–å½“å‰çš„kbpsï¼ˆç”¨äºé€‰æ‹©QoSé˜Ÿåˆ—ï¼‰
            current_kbps = 1024  # é»˜è®¤ä¸­é€Ÿ
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    cur.execute("SELECT kbps FROM rate_limit_active WHERE src_ip = %s", (ip,))
                    row = cur.fetchone()
                    current_kbps = row[0] if row else 1024
            except Exception as e:
                ctrl.logger.error(f"âš ï¸ è·å–å½“å‰é€Ÿç‡å¤±è´¥: {e}")
            finally:
                if conn:
                    conn.close()
            
            # 6. æ ¹æ®å½“å‰é€Ÿç‡é€‰æ‹©æ­£ç¡®çš„QoSé˜Ÿåˆ—ï¼ˆå›ºå®šä¸‰æ¡£ï¼‰
            if current_kbps <= 256:
                q = 1  # ä½é€Ÿé˜Ÿåˆ— 256Kbps
            elif current_kbps <= 1024:
                q = 2  # ä¸­é€Ÿé˜Ÿåˆ— 1024Kbps
            else:
                q = 3  # é«˜é€Ÿé˜Ÿåˆ— 2048Kbps
            
            # 7. ä¸‹å‘OpenFlowæµè¡¨åˆ°æ‰€æœ‰äº¤æ¢æœº
            new_hard = int(max(0, new_expire - time.time()))
            flow_success = False
            for dp in ctrl.datapaths.values():
                ofp, ps = dp.ofproto, dp.ofproto_parser
                match = ps.OFPMatch(eth_type=ether_types.ETH_TYPE_IP, ipv4_src=ip)
                acts = [ps.OFPActionSetQueue(queue_id=q), ps.OFPActionOutput(ofp.OFPP_NORMAL)]
                # âœ… ä¿®å¤ï¼šæ·»åŠ idle=0ï¼Œé˜²æ­¢æµè¡¨å› ç©ºé—²è€Œè¢«åˆ é™¤
                ctrl._add_flow(dp, 50, match, acts, idle=0, hard=new_hard)
                flow_success = True
                ctrl.logger.info(f"âœ… æµè¡¨å·²æ›´æ–°: {ip} æ—¶é•¿è°ƒæ•´, é˜Ÿåˆ—={q}(kbps={current_kbps}), å‰©ä½™={new_hard}ç§’")

            if not flow_success:
                ctrl.logger.error(f"âŒ æµè¡¨ä¸‹å‘å¤±è´¥: {ip} - æ²¡æœ‰å¯ç”¨çš„äº¤æ¢æœº")
                return self._json_resp({'success': False, 'message': 'æµè¡¨ä¸‹å‘å¤±è´¥'}, 500)

            # 8. æµè¡¨ä¸‹å‘æˆåŠŸåï¼Œæ›´æ–°æ•°æ®åº“
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    # âœ… åªæ›´æ–°è¿‡æœŸæ—¶é—´ï¼Œä¸ä¿®æ”¹é™é€ŸåŸå› 
                    cur.execute("""
                        UPDATE rate_limit_active
                        SET expire_at = FROM_UNIXTIME(%s)
                        WHERE src_ip = %s
                    """, (new_expire, ip))
                    
                    # ç”Ÿæˆç®€çŸ­çš„ä¸­æ–‡æè¿°
                    if extra_sec > 0:
                        minutes = extra_sec // 60
                        action_desc = f"å»¶é•¿{minutes}åˆ†"  # âœ… ç®€åŒ–
                    elif extra_sec < 0:
                        minutes = abs(extra_sec) // 60
                        action_desc = f"ç¼©çŸ­{minutes}åˆ†"  # âœ… ç®€åŒ–
                    else:
                        action_desc = "ä¿æŒæ—¶é•¿"
                    
                    # åœ¨logè¡¨ä¸­è®°å½•æ“ä½œï¼ˆactionä½¿ç”¨ä¸­æ–‡æè¿°ï¼‰
                    cur.execute("""
                        INSERT INTO rate_limit_log(src_ip, operator, action, reason)
                        VALUES (%s, %s, %s, %s)
                    """, (ip, 'admin', action_desc, reason))
                    conn.commit()
                    ctrl.logger.info(f"ğŸ“¥ æ•°æ®åº“å·²æ›´æ–°: {ip} æ—¶é•¿å‰©ä½™={new_hard}ç§’")
            except Exception as e:
                ctrl.logger.error(f"âš ï¸ æ•°æ®åº“æ›´æ–°å¤±è´¥: {e}")
                if conn:
                    conn.rollback()
                # æµè¡¨å·²ç”Ÿæ•ˆï¼Œæ•°æ®åº“å¤±è´¥ä¸å½±å“è¿”å›ç»“æœ
            finally:
                if conn:
                    conn.close()

            return self._json_resp({'success': True, 'message': f'{ip} æ—¶é•¿å·²è°ƒæ•´ï¼Œå‰©ä½™ {new_hard} ç§’'})
        except Exception as e:
            ctrl.logger.error(f"âŒ æ—¶é•¿è°ƒæ•´å¼‚å¸¸: {ip} - {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'success': False, 'message': f'æ—¶é•¿è°ƒæ•´å¤±è´¥: {str(e)}'}, 500)


            
    # 10. æŒ‰æ—¥æœŸæŸ¥å†å²é™é€Ÿè®°å½•ï¼ˆå¹´æœˆæ—¥ï¼‰
    @route('rate_history_by_day', '/v1/rate/history/{day}', methods=['GET'])
    def rate_history_by_day(self, req, day, **_):
        """
        è¿”å›æŒ‡å®šæ—¥æœŸçš„ä¸€æ•´é¡µé™é€Ÿè®°å½•
        day: 2025-10-05 æ ¼å¼
        """
        # ç®€å•æ ¼å¼æ ¡éªŒ
        if not re.fullmatch(r'\d{4}-\d{2}-\d{2}', day):
            return self._json_resp({'error': 'day æ ¼å¼åº”ä¸º yyyy-mm-dd'}, 400)

        try:
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                sql = """
                    SELECT src_ip, operator, action, reason, kbps, created_at
                    FROM rate_limit_log
                    WHERE DATE(created_at) = %s
                    ORDER BY created_at DESC
                """
                cur.execute(sql, (day,))
                rows = cur.fetchall()

            data = []
            for r in rows:
                ts = r[5]
                if hasattr(ts, 'strftime'):
                    ts = ts.strftime('%Y-%m-%d %H:%M:%S')
                data.append({
                    'src_ip':   r[0],
                    'operator': r[1],
                    'action':   r[2],
                    'reason':   r[3],
                    'kbps':     int(r[4]) if r[4] else None,
                    'created_at': ts
                })

            return self._json_resp({
                'day': day,
                'count': len(data),
                'data': data
            })
        except Exception as e:
            return self._json_resp({'error': str(e)}, 500)



    # 2. å‰ç«¯è°ƒç”¨ï¼šè§£é™¤é™é€Ÿ  DELETE /v1/limit/ip/{ip}
    @route('unlimit_ip', '/v1/limit/ip/{ip}', methods=['DELETE'])
    def unlimit_ip(self, req, ip, **_):
        """
        å‰ç«¯æ‰‹åŠ¨è§£é™¤é™é€Ÿæ¥å£
        """
        try:
            ok = self.ctrl._release_rate_limit(ip, operator='frontend', reason='å‰ç«¯æ‰‹åŠ¨è§£é™¤')
            if ok:
                return self._json_resp({'success': True, 'message': f'å·²è§£é™¤ {ip} é™é€Ÿ'})
            else:
                return self._json_resp({'success': False, 'message': f'{ip} æš‚æ— é™é€Ÿè®°å½•'}, 404)
        except Exception as e:
            return self._json_resp({'success': False, 'message': str(e)}, 500)


    # é™é€Ÿè¶‹åŠ¿å›¾ï¼š1 å°æ—¶ / 3 å¤© / 7 å¤©
    @route('rate_trend', '/v1/rate-trend', methods=['GET'])
    def rate_trend(self, req, **_):
        """
        è·å–é™é€Ÿè¶‹åŠ¿æ•°æ® - ç»Ÿè®¡é™é€Ÿä¼šè¯æ•°ï¼ˆä¸é¥¼å›¾æ•°æ®å£å¾„ä¸€è‡´ï¼‰
        ä½¿ç”¨limit_sessionsè¡¨ï¼ŒæŒ‰æ—¶é—´ç»Ÿè®¡æ–°å»ºçš„é™é€Ÿä¼šè¯æ•°é‡
        """
        try:
            typ = int(req.params.get('type', 1))          # 1 24h  3 3day  7 7day
            if typ not in (1, 3, 7):
                return self._json_resp({'error': 'type only 1/3/7'}, 400)

            self.ctrl.logger.info(f"[rate_trend] æŸ¥è¯¢é™é€Ÿè¶‹åŠ¿ï¼Œç±»å‹: {typ} ({'24å°æ—¶' if typ == 1 else f'{typ}å¤©'})")

            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                if typ == 1:          # æœ€è¿‘ 1 å¤© â†’ æŒ‰å°æ—¶ç»Ÿè®¡å½“å¤©çš„é™é€Ÿä¼šè¯æ•°
                    sql = """
                        SELECT DATE_FORMAT(start_time, '%Y-%m-%d %H:00') AS tm,
                            COUNT(*) AS cnt
                        FROM limit_sessions
                        WHERE DATE(start_time) = CURDATE()
                        GROUP BY DATE_FORMAT(start_time, '%Y-%m-%d %H:00')
                        ORDER BY tm
                    """
                    self.ctrl.logger.info(f"[rate_trend] ç±»å‹1: æŸ¥è¯¢ä»Šå¤©çš„æ•°æ®")
                else:                 # 3 æˆ– 7 å¤© â†’ æŒ‰å¤©ç»Ÿè®¡é™é€Ÿä¼šè¯æ•°
                    sql = """
                        SELECT DATE_FORMAT(start_time, '%Y-%m-%d') AS tm,
                            COUNT(*) AS cnt
                        FROM limit_sessions
                        WHERE start_time >= DATE_SUB(CURDATE(), INTERVAL {} DAY)
                        GROUP BY DATE_FORMAT(start_time, '%Y-%m-%d')
                        ORDER BY tm
                    """.format(typ)
                    self.ctrl.logger.info(f"[rate_trend] ç±»å‹{typ}: æŸ¥è¯¢æœ€è¿‘{typ}å¤©çš„æ•°æ®")

                self.ctrl.logger.debug(f"[rate_trend] æ‰§è¡ŒSQL: {sql}")
                cur.execute(sql)
                rows = cur.fetchall()
                
                self.ctrl.logger.info(f"[rate_trend] âœ… æŸ¥è¯¢åˆ° {len(rows)} ä¸ªæ—¶é—´ç‚¹çš„æ•°æ®")
                for i, row in enumerate(rows[:10]):  # åªæ‰“å°å‰10æ¡
                    self.ctrl.logger.info(f"  [{i+1}] {row[0]}: {row[1]} æ¬¡")
                if len(rows) > 10:
                    self.ctrl.logger.info(f"  ... è¿˜æœ‰ {len(rows)-10} æ¡æ•°æ®")

            data = [{'time': str(r[0]), 'count': int(r[1])} for r in rows]
            
            # è¯¦ç»†æ—¥å¿—
            if data:
                self.ctrl.logger.info(f"[rate_trend] è¶‹åŠ¿æ•°æ®é¢„è§ˆ:")
                for item in data[:5]:  # åªæ˜¾ç¤ºå‰5æ¡
                    self.ctrl.logger.info(f"  - {item['time']}: {item['count']} æ¬¡é™é€Ÿä¼šè¯")
                if len(data) > 5:
                    self.ctrl.logger.info(f"  ... è¿˜æœ‰ {len(data) - 5} æ¡æ•°æ®")
            else:
                self.ctrl.logger.warning(f"[rate_trend] æœ€è¿‘{typ if typ > 1 else 24}{'å¤©' if typ > 1 else 'å°æ—¶'}æ— é™é€Ÿä¼šè¯è®°å½•")
            
            return self._json_resp(data)
        except Exception as e:
            self.ctrl.logger.error(f"[rate_trend] æŸ¥è¯¢å¤±è´¥: {e}")
            import traceback
            self.ctrl.logger.error(traceback.format_exc())
            return self._json_resp({'error': str(e)}, 500)

    # é™é€ŸåŸå› ç»Ÿè®¡æ¥å£
    @route('rate_reason_stats', '/v1/rate-reason-stats', methods=['GET'])
    def rate_reason_stats(self, req, **_):
        """
        è·å–æŒ‡å®šæ—¶é—´èŒƒå›´çš„é™é€ŸåŸå› åˆ†å¸ƒç»Ÿè®¡
        hours=24: ä»Šå¤©çš„æ•°æ®
        hours=72: æœ€è¿‘3å¤©çš„æ•°æ®
        hours=168: æœ€è¿‘7å¤©çš„æ•°æ®
        è¿”å›æ ¼å¼ï¼š[{reason: "SYN Flood", count: 10}, ...]
        """
        try:
            hours = int(req.params.get('hours', 24))  # é»˜è®¤24å°æ—¶
            self.ctrl.logger.info(f"[rate_reason_stats] æŸ¥è¯¢æ—¶é—´èŒƒå›´: {hours}å°æ—¶")
            
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # æ ¹æ®hourså‚æ•°å†³å®šæŸ¥è¯¢é€»è¾‘
                if hours == 24:
                    # 24å°æ—¶ = ä»Šå¤©
                    sql = """
                        SELECT reason, COUNT(*) AS cnt
                        FROM limit_sessions
                        WHERE DATE(start_time) = CURDATE()
                        GROUP BY reason
                        ORDER BY cnt DESC
                    """
                    self.ctrl.logger.debug(f"[rate_reason_stats] æŸ¥è¯¢ä»Šå¤©çš„æ•°æ®: {sql}")
                    cur.execute(sql)
                elif hours == 72:
                    # 72å°æ—¶ = æœ€è¿‘3å¤©
                    sql = """
                        SELECT reason, COUNT(*) AS cnt
                        FROM limit_sessions
                        WHERE start_time >= DATE_SUB(CURDATE(), INTERVAL 3 DAY)
                        GROUP BY reason
                        ORDER BY cnt DESC
                    """
                    self.ctrl.logger.debug(f"[rate_reason_stats] æŸ¥è¯¢æœ€è¿‘3å¤©çš„æ•°æ®: {sql}")
                    cur.execute(sql)
                elif hours == 168:
                    # 168å°æ—¶ = æœ€è¿‘7å¤©
                    sql = """
                        SELECT reason, COUNT(*) AS cnt
                        FROM limit_sessions
                        WHERE start_time >= DATE_SUB(CURDATE(), INTERVAL 7 DAY)
                        GROUP BY reason
                        ORDER BY cnt DESC
                    """
                    self.ctrl.logger.debug(f"[rate_reason_stats] æŸ¥è¯¢æœ€è¿‘7å¤©çš„æ•°æ®: {sql}")
                    cur.execute(sql)
                else:
                    # å…¶ä»–æƒ…å†µï¼Œä½¿ç”¨å°æ—¶æ•°æŸ¥è¯¢
                    sql = """
                        SELECT reason, COUNT(*) AS cnt
                        FROM limit_sessions
                        WHERE start_time >= DATE_SUB(NOW(), INTERVAL %s HOUR)
                        GROUP BY reason
                        ORDER BY cnt DESC
                    """
                    self.ctrl.logger.debug(f"[rate_reason_stats] æŸ¥è¯¢æœ€è¿‘{hours}å°æ—¶çš„æ•°æ®: {sql}")
                    cur.execute(sql, (hours,))
                
                rows = cur.fetchall()
                self.ctrl.logger.info(f"[rate_reason_stats] æŸ¥è¯¢åˆ° {len(rows)} ç§ä¸åŒçš„é™é€ŸåŸå› ")

            data = [{'reason': r[0], 'count': int(r[1])} for r in rows]
            
            # è¯¦ç»†æ—¥å¿—
            if not data:
                self.ctrl.logger.warning(f"[rate_reason_stats] âŒ æœ€è¿‘{hours}å°æ—¶æ— é™é€Ÿè®°å½•")
            else:
                self.ctrl.logger.info(f"[rate_reason_stats] âœ… è¿”å›æ•°æ®:")
                for item in data:
                    self.ctrl.logger.info(f"  - {item['reason']}: {item['count']} æ¬¡")
            
            return self._json_resp(data)
        except Exception as e:
            self.ctrl.logger.error(f"âŒ rate_reason_stats error: {e}")
            import traceback
            self.ctrl.logger.error(traceback.format_exc())
            return self._json_resp({'error': str(e)}, 500)


        
    

    # ---------------- WebSocket é•¿è¿æ¥ï¼ˆå‰ç«¯ 8080ï¼‰ ----------------
    @route('chat_ws', '/ws/chat', methods=['GET'])
    def chat_ws(self, ws, req, **_):
        user_id = req.params.get('user_id') or req.headers.get('X-User-Id') or 'anonymous'
        role = self._get_user_role(user_id)
        self.ctrl.logger.info(f"[WS] {user_id}({role}) connected")
        try:
            while True:
                msg = ws.receive()
                if not msg:
                    break
                reply = self._process_one_shot(user_id, msg.strip())
                ws.send(reply)
        finally:
            ws.close()

    # RYUæ§åˆ¶å™¨å¼‚å¸¸æ•°æ®APIä¼˜åŒ–ç‰ˆæœ¬
# éœ€è¦åœ¨ sdn_smart.py ä¸­æ›¿æ¢åŸæœ‰çš„ get_anomalies æ–¹æ³•

    @route('anomalies', '/v1/anomalies', methods=['GET'])
    def get_anomalies(self, req, **_):
        """
        ä¼˜åŒ–ç‰ˆå¼‚å¸¸æ•°æ®æŸ¥è¯¢æ¥å£
        æ”¯æŒæ—¶é—´èŒƒå›´è¿‡æ»¤å’Œå¯é€‰çš„æ•°é‡é™åˆ¶
        ç‰¹æ®Šå¤„ç†ï¼šå½“hours=24æ—¶ï¼ŒæŸ¥è¯¢ä»Šæ—¥ï¼ˆä»0ç‚¹åˆ°ç°åœ¨ï¼‰è€Œéæœ€è¿‘24å°æ—¶ï¼Œä¸Dashboardä¿æŒä¸€è‡´
        """
        try:
            # è·å–æŸ¥è¯¢å‚æ•°
            hours = int(req.params.get('hours', 12))  # é»˜è®¤12å°æ—¶
            limit = req.params.get('limit')  # å¯é€‰çš„æ•°é‡é™åˆ¶
            
            # éªŒè¯å‚æ•°èŒƒå›´
            hours = max(1, min(hours, 168))  # 1å°æ—¶åˆ°7å¤©
            
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # âœ… ç‰¹æ®Šå¤„ç†ï¼šå½“hours=24æ—¶ï¼ŒæŸ¥è¯¢ä»Šæ—¥æ•°æ®ï¼ˆä»0ç‚¹åˆ°ç°åœ¨ï¼Œä¸Dashboardä¸€è‡´ï¼‰
                if hours == 24:
                    base_sql = """
                        SELECT detect_time, src_ip, dst_ip, anomaly_type, details 
                        FROM anomaly_log 
                        WHERE DATE(detect_time) = CURDATE()
                        ORDER BY detect_time DESC
                    """
                    params = []
                    time_desc = "ä»Šæ—¥"
                else:
                    # å…¶ä»–æ—¶é—´æ®µä½¿ç”¨INTERVALæŸ¥è¯¢
                    base_sql = """
                        SELECT detect_time, src_ip, dst_ip, anomaly_type, details 
                        FROM anomaly_log 
                        WHERE detect_time >= DATE_SUB(NOW(), INTERVAL %s HOUR)
                        ORDER BY detect_time DESC
                    """
                    params = [hours]
                    time_desc = f"æœ€è¿‘{hours}å°æ—¶"
                
                # å¦‚æœæŒ‡å®šäº†limitï¼Œæ·»åŠ åˆ°SQLä¸­
                if limit is not None:
                    try:
                        limit = int(limit)
                        if limit > 0:
                            base_sql += " LIMIT %s"
                            params.append(limit)
                    except (ValueError, TypeError):
                        pass  # å¿½ç•¥æ— æ•ˆçš„limitå‚æ•°
                
                print(f"[DEBUG] æ‰§è¡Œå¼‚å¸¸æŸ¥è¯¢: {time_desc}, limit={limit}")
                cur.execute(base_sql, params)
                rows = cur.fetchall()
                
            data = []
            for r in rows:
                # æ£€æŸ¥è¡Œæ•°æ®çš„å®Œæ•´æ€§ï¼Œé˜²æ­¢tuple index out of range
                if len(r) < 5:
                    continue  # è·³è¿‡ä¸å®Œæ•´çš„è¡Œ
                
                # å¤„ç†datetimeå’Œå…¶ä»–å¯èƒ½çš„éJSONåºåˆ—åŒ–ç±»å‹
                detect_time = r[0]
                if hasattr(detect_time, 'strftime'):
                    detect_time = detect_time.strftime('%Y-%m-%d %H:%M:%S')
                else:
                    detect_time = str(detect_time)
                
                data.append({
                    'detect_time': detect_time,
                    'src_ip': r[1] if r[1] is not None else '',
                    'dst_ip': r[2] if r[2] is not None else '',
                    'anomaly_type': r[3] if r[3] is not None else '',
                    'details': r[4] if r[4] is not None else ''
                })
            
            self.ctrl.logger.info(f"âœ… [anomalies API] {time_desc}æŸ¥è¯¢åˆ° {len(data)} æ¡å¼‚å¸¸æ•°æ®")
            return self._json_resp(data)
            
        except Exception as e:
            self.ctrl.logger.error("get_anomalies error: %s", e)
            return self._json_resp({'error': str(e)}, 500)


    # é¢å¤–ä¼˜åŒ–ï¼šæ·»åŠ æ•°æ®åº“ç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
    def optimize_database_indexes(self):
        """
        ä¸ºå¼‚å¸¸æ—¥å¿—è¡¨æ·»åŠ ç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
        å»ºè®®åœ¨RYUæ§åˆ¶å™¨å¯åŠ¨æ—¶è°ƒç”¨ä¸€æ¬¡
        """
        try:
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # ä¸ºdetect_timeå­—æ®µæ·»åŠ ç´¢å¼•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                cur.execute("""
                    CREATE INDEX IF NOT EXISTS idx_anomaly_log_detect_time 
                    ON anomaly_log(detect_time)
                """)
                
                # ä¸ºsrc_ipå­—æ®µæ·»åŠ ç´¢å¼•ï¼ˆç”¨äºæŒ‰IPæŸ¥è¯¢ï¼‰
                cur.execute("""
                    CREATE INDEX IF NOT EXISTS idx_anomaly_log_src_ip 
                    ON anomaly_log(src_ip)
                """)
                
                # å¤åˆç´¢å¼•ï¼šæ—¶é—´+IPï¼ˆæœ€å¸¸ç”¨çš„æŸ¥è¯¢ç»„åˆï¼‰
                cur.execute("""
                    CREATE INDEX IF NOT EXISTS idx_anomaly_log_time_ip 
                    ON anomaly_log(detect_time, src_ip)
                """)
                
                conn.commit()
                print("[DEBUG] æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–å®Œæˆ")
                
        except Exception as e:
            print(f"[ERROR] æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–å¤±è´¥: {e}")


    # æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–ï¼šå‡å°‘æ•°æ®åº“è¿æ¥å¼€é”€
    def get_anomalies_batch_optimized(self, req, **_):
        """
        æ‰¹é‡ä¼˜åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨è¿æ¥æ± å’ŒæŸ¥è¯¢ç¼“å­˜
        """
        try:
            hours = int(req.params.get('hours', 12))
            limit = req.params.get('limit')
            
            # ç¼“å­˜é”®
            cache_key = f"anomalies_{hours}_{limit or 'all'}"
            
            # æ£€æŸ¥ç¼“å­˜ï¼ˆå¯é€‰ï¼Œå¦‚æœéœ€è¦å®æ—¶æ€§å¯ä»¥è·³è¿‡ï¼‰
            # cached_result = self.get_cache(cache_key)
            # if cached_result:
            #     return self._json_resp(cached_result)
            
            # ä½¿ç”¨è¿æ¥æ± ä¼˜åŒ–
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG, autocommit=True)
                with conn.cursor(pymysql.cursors.DictCursor) as cur:  # ä½¿ç”¨å­—å…¸æ¸¸æ ‡
                    sql = """
                        SELECT detect_time, src_ip, dst_ip, anomaly_type, details 
                        FROM anomaly_log 
                        WHERE detect_time >= DATE_SUB(NOW(), INTERVAL %s HOUR)
                        ORDER BY detect_time DESC
                    """
                    params = [hours]
                    
                    if limit:
                        sql += " LIMIT %s"
                        params.append(int(limit))
                    
                    cur.execute(sql, params)
                    rows = cur.fetchall()
                    
                    # ç›´æ¥ä½¿ç”¨å­—å…¸æ ¼å¼ï¼Œå‡å°‘æ•°æ®è½¬æ¢
                    data = []
                    for row in rows:
                        if row['detect_time']:
                            row['detect_time'] = row['detect_time'].strftime('%Y-%m-%d %H:%M:%S')
                        data.append(row)
                    
                    # è®¾ç½®ç¼“å­˜ï¼ˆå¯é€‰ï¼‰
                    # self.set_cache(cache_key, data, expire=30)  # 30ç§’ç¼“å­˜
                    
                    return self._json_resp(data)
                    
            finally:
                if conn:
                    conn.close()
                    
        except Exception as e:
            return self._json_resp({'error': str(e)}, 500)

    
        # æ·»åŠ é»‘åå•
    @route('acl_black_add', '/v1/acl/black', methods=['POST'])
    def acl_black_add(self, req, **_):
        try:
            body = json.loads(req.body.decode('utf-8'))
            ip   = body['ip']
            ttl  = body.get('ttl', -1)
            operator = body.get('operator', 'admin')  # âœ… å‰ç«¯ä¼ é€’operatorï¼Œé»˜è®¤admin
            self.ctrl.acl_add_black(ip, ttl, operator)
            return self._json_resp({'success': True, 'message': f'{ip} å·²åŠ å…¥é»‘åå•'})
        except Exception as e:
            return self._json_resp({'success': False, 'message': str(e)}, 500)

    # åˆ é™¤é»‘åå•
    @route('acl_black_del', '/v1/acl/black/{ip}', methods=['DELETE'])
    def acl_black_del(self, req, ip, **_):
        try:
            success = self.ctrl.acl_del_black(ip)  # âœ… æ£€æŸ¥è¿”å›å€¼
            if success:
                return self._json_resp({'success': True, 'message': f'âœ… {ip} å·²ä»é»‘åå•ç§»é™¤'})
            else:
                return self._json_resp({'success': False, 'message': f'âŒ {ip} åˆ é™¤å¤±è´¥ï¼Œå¯èƒ½ä¸åœ¨æ•°æ®åº“ä¸­'}, 400)
        except Exception as e:
            self.ctrl.logger.error(f"åˆ é™¤é»‘åå•APIé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'success': False, 'message': str(e)}, 500)
    
        # æ·»åŠ ç™½åå•
    @route('acl_white_add', '/v1/acl/white', methods=['POST'])
    def acl_white_add(self, req, **_):
        try:
            body = json.loads(req.body.decode('utf-8'))
            ip   = body['ip']
            ttl  = body.get('ttl', -1)
            self.ctrl.acl_add_white(ip, ttl)
            return self._json_resp({'success': True, 'message': f'{ip} å·²åŠ å…¥ç™½åå•'})
        except Exception as e:
            return self._json_resp({'success': False, 'message': str(e)}, 500)

    # åˆ é™¤ç™½åå•
    @route('acl_white_del', '/v1/acl/white/{ip}', methods=['DELETE'])
    def acl_white_del(self, req, ip, **_):
        try:
            success = self.ctrl.acl_del_white(ip)  # âœ… æ£€æŸ¥è¿”å›å€¼
            if success:
                return self._json_resp({'success': True, 'message': f'âœ… {ip} å·²ä»ç™½åå•ç§»é™¤'})
            else:
                return self._json_resp({'success': False, 'message': f'âŒ {ip} åˆ é™¤å¤±è´¥ï¼Œå¯èƒ½ä¸åœ¨æ•°æ®åº“ä¸­'}, 400)
        except Exception as e:
            self.ctrl.logger.error(f"åˆ é™¤ç™½åå•APIé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'success': False, 'message': str(e)}, 500)



    

    # ---------------- é™é€Ÿåˆ—è¡¨æ¥å£ ----------------
    @route('ratelimit', '/v1/ratelimit', methods=['GET'])
    def get_ratelimit(self, req, **_):
        limit_list = self.ctrl.get_limit_list()
        return self._json_resp({'limit_list': limit_list})

    # ---------------- ACLåˆ—è¡¨æ¥å£ ----------------
    @route('acl', '/v1/acl', methods=['GET'])
    def get_acl(self, req, **_):
        acl_lists = self.ctrl.get_acl_lists()
        return self._json_resp(acl_lists)

    # ---------------- ç³»ç»Ÿæ¦‚è§ˆæ¥å£ ----------------
    @route('summary', '/v1/summary', methods=['GET'])
    def get_summary(self, req, **_):
        try:
            today = time.strftime('%Y-%m-%d')
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG, autocommit=True)
                with conn.cursor() as cur:
                    # ä»Šæ—¥å¼‚å¸¸
                    cur.execute("SELECT COUNT(*) FROM anomaly_log WHERE DATE(detect_time) = %s", (today,))
                    today_anomalies = int(cur.fetchone()[0])

                    # å½“å‰é™é€Ÿ IP æ•°
                    cur.execute("SELECT COUNT(*) FROM rate_limit_active")
                    limit_count = int(cur.fetchone()[0])

                    # é»‘åå•æ•°
                    cur.execute("SELECT COUNT(*) FROM acl_entries WHERE list_type = 'black'")
                    black_count = int(cur.fetchone()[0])

                    # ç™½åå•æ•°
                    cur.execute("SELECT COUNT(*) FROM acl_entries WHERE list_type = 'white'")
                    white_count = int(cur.fetchone()[0])

                    # äº¤æ¢æœºåœ¨çº¿æ•°
                    switch_count = len(self.ctrl.datapaths)
            finally:
                if conn:
                    conn.close()

            return self._json_resp({
                'today_anomalies': today_anomalies,
                'limit_count': limit_count,
                'black_count': black_count,
                'white_count': white_count,
                'switch_count': switch_count
            })
        except Exception as e:
            import traceback
            return self._json_resp({'error': traceback.format_exc()}, 500)

    
    @route('anomalies_week', '/v1/anomalies/week', methods=['GET'])
    def get_anomalies_week(self, req, **_):
        try:
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                cur.execute("SELECT detect_time,src_ip,dst_ip,anomaly_type,details "
                        "FROM anomaly_log WHERE detect_time >= DATE_SUB(NOW(), INTERVAL 7 DAY) "
                        "ORDER BY detect_time DESC")
                rows = cur.fetchall()
            data = [{'detect_time':r[0].strftime('%Y-%m-%d %H:%M:%S'),'src_ip':r[1],'dst_ip':r[2],
                    'anomaly_type':r[3],'details':r[4]} for r in rows]
            return self._json_resp(data)
        except Exception as e:
            return self._json_resp({'error':str(e)},500)

    @route('anomalies_top10', '/v1/anomalies/top10', methods=['GET'])
    def get_anomalies_top10(self, req, **_):
        try:
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                cur.execute("SELECT src_ip,COUNT(*) as cnt FROM anomaly_log "
                        "WHERE detect_time >= DATE_SUB(NOW(), INTERVAL 7 DAY) "
                        "GROUP BY src_ip ORDER BY cnt DESC LIMIT 10")
                rows = cur.fetchall()
            data = [{'src_ip':r[0],'count':r[1]} for r in rows]
            return self._json_resp(data)
        except Exception as e:
            return self._json_resp({'error':str(e)},500)

    @route('device_anomalies', '/v1/device-anomalies', methods=['GET'])
    def get_device_anomalies(self, req, **_):
        """
        è·å–è®¾å¤‡å¼‚å¸¸åˆ—è¡¨ï¼ˆçœŸæ­£çš„è®¾å¤‡é—®é¢˜ï¼šIPé…é”™ã€ç«¯å£å¼‚å¸¸ç­‰ï¼‰
        ä» device_anomalies è¡¨æŸ¥è¯¢
        """
        try:
            hours = int(req.params.get('hours', 24))
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG, autocommit=True)
                with conn.cursor() as cur:
                    cur.execute("""
                        SELECT 
                            id, anomaly_type, device_type, device_id, 
                            description, severity, status, 
                            detected_at, resolved_at, handled_by, handle_action
                        FROM device_anomalies
                        WHERE detected_at >= DATE_SUB(NOW(), INTERVAL %s HOUR)
                          AND status != 'resolved'
                        ORDER BY detected_at DESC
                    """, (hours,))
                    rows = cur.fetchall()
                    
                data = []
                for r in rows:
                    data.append({
                        'id': r[0],
                        'anomaly_type': r[1],
                        'device_type': r[2],
                        'device_id': r[3],
                        'description': r[4],
                        'severity': r[5],
                        'status': r[6],
                        'detected_at': r[7].strftime('%Y-%m-%d %H:%M:%S') if r[7] else None,
                        'resolved_at': r[8].strftime('%Y-%m-%d %H:%M:%S') if r[8] else None,
                        'handled_by': r[9],
                        'handle_action': r[10]
                    })
                
                return self._json_resp({'success': True, 'data': data, 'count': len(data)})
            finally:
                if conn:
                    conn.close()
        except Exception as e:
            import traceback
            self.ctrl.logger.error(f"è·å–è®¾å¤‡å¼‚å¸¸å¤±è´¥: {e}")
            return self._json_resp({'success': False, 'error': str(e)}, 500)
    
    @route('update_device_anomaly', '/v1/device-anomalies/<anomaly_id>', methods=['PUT'])
    def update_device_anomaly_status(self, req, anomaly_id, **_):
        """
        æ›´æ–°è®¾å¤‡å¼‚å¸¸çŠ¶æ€ä¸ºå·²å¤„ç†
        å½“ç®¡ç†å‘˜ç‚¹å‡»"å·²å¤„ç†"æŒ‰é’®æ—¶è°ƒç”¨æ­¤API
        """
        try:
            anomaly_id = int(anomaly_id)
            
            # è§£æè¯·æ±‚ä½“
            body = json.loads(req.body.decode('utf-8'))
            status = body.get('status', 'resolved')
            
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG, autocommit=True)
                with conn.cursor() as cur:
                    # æ›´æ–°å¼‚å¸¸çŠ¶æ€ä¸ºå·²å¤„ç†
                    cur.execute("""
                        UPDATE device_anomalies
                        SET status = %s,
                            resolved_at = NOW(),
                            handled_by = 'admin',
                            handle_action = 'marked_resolved'
                        WHERE id = %s
                    """, (status, anomaly_id))
                    
                    affected_rows = cur.rowcount
                    
                    if affected_rows > 0:
                        self.ctrl.logger.info(f"âœ… å¼‚å¸¸#{anomaly_id}å·²æ ‡è®°ä¸º{status}")
                        return self._json_resp({
                            'success': True,
                            'message': f'å¼‚å¸¸å·²æ ‡è®°ä¸º{status}',
                            'affected_rows': affected_rows
                        })
                    else:
                        return self._json_resp({
                            'success': False,
                            'message': f'å¼‚å¸¸#{anomaly_id}ä¸å­˜åœ¨'
                        }, 404)
                        
            finally:
                if conn:
                    conn.close()
                    
        except Exception as e:
            import traceback
            self.ctrl.logger.error(f"æ›´æ–°å¼‚å¸¸çŠ¶æ€å¤±è´¥: {e}")
            traceback.print_exc()
            return self._json_resp({'success': False, 'error': str(e)}, 500)
    
    @route('flowstats_top10', '/v1/flowstats/top10', methods=['GET'])
    def get_flowstats_top10(self, req, **_):
        try:
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                cur.execute("SELECT src_ip,SUM(byte_count) as bytes,SUM(packet_count) as packets "
                        "FROM flow_stats WHERE timestamp >= DATE_SUB(NOW(), INTERVAL 24 HOUR) "
                        "GROUP BY src_ip ORDER BY bytes DESC LIMIT 10")
                rows = cur.fetchall()
            data = [{'src_ip':r[0],'bytes':r[1],'packets':r[2]} for r in rows]
            return self._json_resp(data)
        except Exception as e:
            return self._json_resp({'error':str(e)},500)


    @route('switch_info', '/v1/switch/info', methods=['GET'])
    def get_switch_info(self, req, **_):
        switches = []
        for dp in self.ctrl.datapaths.values():
            switches.append({
                'datapath_id': f"{dp.id:016d}",
                'ip': dp.address[0],   # æ§åˆ¶å™¨çœ‹åˆ°çš„äº¤æ¢æœº IP
                'port': dp.address[1],
                'online': True
            })
        return self._json_resp({'switches': switches})

    # ========== æµè¡¨ç®¡ç†API ==========
    @route('switches_list', '/v1/switches', methods=['GET'])
    def get_switches_list(self, req, **_):
        """è·å–æ‰€æœ‰äº¤æ¢æœºçš„DPIDåˆ—è¡¨"""
        try:
            dpids = [dp.id for dp in self.ctrl.datapaths.values()]
            return self._json_resp(dpids)
        except Exception as e:
            self.ctrl.logger.error(f"è·å–äº¤æ¢æœºåˆ—è¡¨å¤±è´¥: {e}")
            return self._json_resp({'error': str(e)}, 500)

    @route('switch_flows', '/v1/switches/{dpid}/flows', methods=['GET'])
    def get_switch_flows(self, req, dpid, **_):
        """è·å–æŒ‡å®šäº¤æ¢æœºçš„æµè¡¨"""
        try:
            dpid_int = int(dpid)
            if dpid_int not in self.ctrl.datapaths:
                return self._json_resp({'error': 'äº¤æ¢æœºä¸å­˜åœ¨'}, 404)
            
            # ä»ç¼“å­˜ä¸­è·å–æµè¡¨æ•°æ®
            flows = self.ctrl.switch_flow_stats.get(dpid_int, [])
            return self._json_resp({str(dpid_int): flows})
        except Exception as e:
            self.ctrl.logger.error(f"è·å–æµè¡¨å¤±è´¥: {e}")
            return self._json_resp({'error': str(e)}, 500)

    @route('add_flow', '/v1/switches/{dpid}/flows', methods=['POST'])
    def add_flow_entry(self, req, dpid, **_):
        """æ·»åŠ æµè¡¨é¡¹"""
        try:
            dpid_int = int(dpid)
            if dpid_int not in self.ctrl.datapaths:
                return self._json_resp({'error': 'äº¤æ¢æœºä¸å­˜åœ¨'}, 404)
            
            # è§£æè¯·æ±‚body
            body = req.body
            if isinstance(body, bytes):
                body = body.decode('utf-8')
            flow_data = json.loads(body)
            
            dp = self.ctrl.datapaths[dpid_int]
            ofp = dp.ofproto
            ofp_parser = dp.ofproto_parser
            
            # æ„å»ºmatch
            match_dict = flow_data.get('match', {})
            match = ofp_parser.OFPMatch(**match_dict)
            
            # âœ… è¯¦ç»†æ—¥å¿—ï¼šæ‰“å°æ”¶åˆ°çš„flow_data
            self.ctrl.logger.info(f"[add_flow] æ”¶åˆ°çš„flow_data: {json.dumps(flow_data, ensure_ascii=False, indent=2)}")
            
            # æ„å»ºactions
            actions = []
            for action in flow_data.get('actions', []):
                self.ctrl.logger.info(f"[add_flow] å¤„ç†action: {action}")
                if action.get('type') == 'OUTPUT':
                    port = action.get('port')
                    queue_id = action.get('queue_id')
                    self.ctrl.logger.info(f"[add_flow] OUTPUTåŠ¨ä½œ - port={port}, queue_id={queue_id}")
                    
                    # âœ… å°ç¦åœºæ™¯ï¼športä¸ºNoneï¼Œä½¿ç”¨DROPåŠ¨ä½œ
                    if port is None:
                        self.ctrl.logger.info("[add_flow] å°ç¦åœºæ™¯ï¼šä¸æ·»åŠ OUTPUTåŠ¨ä½œï¼ˆDROPï¼‰")
                        # ä¸æ·»åŠ ä»»ä½•action = DROP
                        continue
                    
                    # âœ… ç¡®ä¿portæ˜¯æ•´æ•°
                    try:
                        port = int(port)
                        self.ctrl.logger.info(f"[add_flow] ç«¯å£å·è½¬æ¢ä¸ºæ•´æ•°: {port}")
                    except (ValueError, TypeError):
                        self.ctrl.logger.error(f"[add_flow] æ— æ•ˆçš„ç«¯å£å·: {port}")
                        return self._json_resp({'success': False, 'error': f'æ— æ•ˆçš„ç«¯å£å·: {port}'}, 400)
                    
                    # å¦‚æœæœ‰queue_idï¼Œä½¿ç”¨OFPActionSetQueue + OFPActionOutput
                    if queue_id is not None:
                        try:
                            queue_id = int(queue_id)
                            actions.append(ofp_parser.OFPActionSetQueue(queue_id))
                            actions.append(ofp_parser.OFPActionOutput(port))
                            self.ctrl.logger.info(f"[add_flow] æ·»åŠ é™é€ŸåŠ¨ä½œ: queue={queue_id}, port={port}")
                        except (ValueError, TypeError):
                            self.ctrl.logger.error(f"[add_flow] æ— æ•ˆçš„é˜Ÿåˆ—ID: {queue_id}")
                            return self._json_resp({'success': False, 'error': f'æ— æ•ˆçš„é˜Ÿåˆ—ID: {queue_id}'}, 400)
                    else:
                        actions.append(ofp_parser.OFPActionOutput(port))
                        self.ctrl.logger.info(f"[add_flow] æ·»åŠ OUTPUTåŠ¨ä½œ: port={port}")
            
            # æ·»åŠ æµè¡¨
            priority = int(flow_data.get('priority', 100))
            idle_timeout = int(flow_data.get('idle_timeout', 0))
            hard_timeout = int(flow_data.get('hard_timeout', 0))
            
            self.ctrl.logger.info(f"[add_flow] æ·»åŠ æµè¡¨: dpid={dpid_int}, priority={priority}, match={match_dict}, actions_count={len(actions)}, idle={idle_timeout}, hard={hard_timeout}")
            self.ctrl._add_flow(dp, priority, match, actions, idle=idle_timeout, hard=hard_timeout)
            
            return self._json_resp({'success': True, 'message': 'æµè¡¨æ·»åŠ æˆåŠŸ'})
        except Exception as e:
            self.ctrl.logger.error(f"æ·»åŠ æµè¡¨å¤±è´¥: {e}")
            return self._json_resp({'error': str(e)}, 500)

    @route('delete_flow', '/v1/switches/{dpid}/flows', methods=['DELETE'])
    def delete_flow_entry(self, req, dpid, **_):
        """åˆ é™¤æµè¡¨é¡¹"""
        try:
            dpid_int = int(dpid)
            if dpid_int not in self.ctrl.datapaths:
                return self._json_resp({'success': False, 'error': 'äº¤æ¢æœºä¸å­˜åœ¨'}, 404)
            
            # è§£æè¯·æ±‚body
            body = req.body
            if isinstance(body, bytes):
                body = body.decode('utf-8')
            flow_data = json.loads(body)
            
            self.ctrl.logger.info(f"[delete_flow] åˆ é™¤æµè¡¨: dpid={dpid_int}, flow_data={flow_data}")
            
            dp = self.ctrl.datapaths[dpid_int]
            ofp = dp.ofproto
            ofp_parser = dp.ofproto_parser
            
            # æ„å»ºmatch - è½¬æ¢å­—ç¬¦ä¸²ç±»å‹çš„eth_typeä¸ºæ•´æ•°
            match_dict = flow_data.get('match', {})
            if 'eth_type' in match_dict and isinstance(match_dict['eth_type'], str):
                try:
                    match_dict['eth_type'] = int(match_dict['eth_type'])
                except:
                    pass
            
            self.ctrl.logger.info(f"[delete_flow] å¤„ç†åçš„match_dict: {match_dict}")
            
            match = ofp_parser.OFPMatch(**match_dict)
            
            # å‘é€åˆ é™¤æµè¡¨å‘½ä»¤
            priority = flow_data.get('priority', 0)
            mod = ofp_parser.OFPFlowMod(
                datapath=dp,
                priority=priority,
                match=match,
                command=ofp.OFPFC_DELETE,
                out_group=ofp.OFPG_ANY,
                out_port=ofp.OFPP_ANY
            )
            dp.send_msg(mod)
            
            self.ctrl.logger.info(f"[delete_flow] æµè¡¨åˆ é™¤å‘½ä»¤å·²å‘é€")
            return self._json_resp({'success': True, 'message': 'æµè¡¨åˆ é™¤æˆåŠŸ'})
        except Exception as e:
            self.ctrl.logger.error(f"åˆ é™¤æµè¡¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'success': False, 'error': str(e)}, 500)

    @route('delete_all_flows', '/v1/switches/{dpid}/flows/all', methods=['DELETE'])
    def delete_all_flows(self, req, dpid, **_):
        """åˆ é™¤æŒ‡å®šäº¤æ¢æœºçš„æ‰€æœ‰æµè¡¨"""
        try:
            dpid_int = int(dpid)
            if dpid_int not in self.ctrl.datapaths:
                return self._json_resp({'error': 'äº¤æ¢æœºä¸å­˜åœ¨'}, 404)
            
            dp = self.ctrl.datapaths[dpid_int]
            ofp = dp.ofproto
            ofp_parser = dp.ofproto_parser
            
            # åˆ é™¤æ‰€æœ‰æµè¡¨
            match = ofp_parser.OFPMatch()
            mod = ofp_parser.OFPFlowMod(
                datapath=dp,
                command=ofp.OFPFC_DELETE,
                out_group=ofp.OFPG_ANY,
                out_port=ofp.OFPP_ANY,
                match=match
            )
            dp.send_msg(mod)
            
            return self._json_resp({'success': True, 'message': 'æ‰€æœ‰æµè¡¨å·²åˆ é™¤'})
        except Exception as e:
            self.ctrl.logger.error(f"åˆ é™¤æ‰€æœ‰æµè¡¨å¤±è´¥: {e}")
            return self._json_resp({'error': str(e)}, 500)

    
    @route('report_weekly', '/v1/report/weekly', methods=['GET'])
    def get_report_weekly(self, req, **_):
        try:
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # æ”»å‡»ç»Ÿè®¡
                cur.execute("SELECT anomaly_type,COUNT(*) FROM anomaly_log WHERE detect_time >= DATE_SUB(NOW(), INTERVAL 7 DAY) GROUP BY anomaly_type")
                attack_stats = {r[0]: r[1] for r in cur.fetchall()}
                # TOP æ”»å‡»è€…
                cur.execute("SELECT src_ip,COUNT(*) as c FROM anomaly_log WHERE detect_time >= DATE_SUB(NOW(), INTERVAL 7 DAY) GROUP BY src_ip ORDER BY c DESC LIMIT 5")
                top_attackers = [{'ip': r[0], 'count': r[1]} for r in cur.fetchall()]
                # æ€»æµé‡
                cur.execute("SELECT SUM(byte_count),SUM(packet_count) FROM flow_stats WHERE timestamp >= DATE_SUB(NOW(), INTERVAL 7 DAY)")
                total = [float(x) if x is not None else 0 for x in cur.fetchone()]
            report = {
                'period': 'è¿‘ 7 å¤©',
                'total_attacks': sum(attack_stats.values()),
                'attack_breakdown': attack_stats,
                'top_attackers': top_attackers,
                'total_bytes': total[0] or 0,
                'total_packets': total[1] or 0,
                'generated_at': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            return self._json_resp(report)
        except Exception as e:
            return self._json_resp({'error': str(e)}, 500)



    @route('export_pdf', '/v1/export/pdf', methods=['GET'])
    def export_pdf(self, req, **_):
        try:
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # 1. 7 å¤©è¶‹åŠ¿
                cur.execute(
                    "SELECT DATE(detect_time) as d,COUNT(*) FROM anomaly_log "
                    "WHERE detect_time >= DATE_SUB(NOW(), INTERVAL 7 DAY) GROUP BY d ORDER BY d"
                )
                days, counts = zip(*cur.fetchall()) if cur.rowcount else ([], [])
                plt.figure()
                plt.bar(days, counts, color='#0072ff')
                plt.title('7-Day Attack Trend')
                plt.xticks(rotation=45)
                buf = BytesIO()
                plt.savefig(buf, format='png', bbox_inches='tight')
                plt.close()
                chart_b64 = base64.b64encode(buf.getvalue()).decode()

                # 2. TOP5 æ”»å‡»è€…
                cur.execute(
                    "SELECT src_ip,COUNT(*) FROM anomaly_log "
                    "WHERE detect_time >= DATE_SUB(NOW(), INTERVAL 7 DAY) "
                    "GROUP BY src_ip ORDER BY COUNT(*) DESC LIMIT 5"
                )
                top5 = cur.fetchall()

            html = f"""
            <html><head><meta charset="utf-8"><title>SDN Guardian å‘¨æŠ¥</title></head>
            <body>
            <h1>SDN Guardian - è¿‘ 7 å¤©å®‰å…¨å‘¨æŠ¥</h1>
            <p>ç”Ÿæˆæ—¶é—´ï¼š{time.strftime('%Y-%m-%d %H:%M:%S')}</p>
            <img src="data:image/png;base64,{chart_b64}" width="600"/>
            <table border="1" cellpadding="6">
                <tr><th>IP</th><th>æ”»å‡»æ¬¡æ•°</th></tr>
                {''.join(f'<tr><td>{ip}</td><td>{cnt}</td></tr>' for ip, cnt in top5)}
            </table>
            </body></html>
            """

            # ç”¨ weasyprint çœŸè½¬ pdf
            pdf_bytes = HTML(string=html).write_pdf()
            return Response(
                content_type='application/pdf',
                headers={'Content-Disposition': 'attachment; filename="weekly.pdf"'},
                body=pdf_bytes
            )
        except Exception as e:
            return self._json_resp({'error': str(e)}, 500)

    @route('export_weekly_pdf', '/v1/export/weekly-pdf', methods=['GET'])
    def export_weekly_pdf(self, req, **_):
        """ç”Ÿæˆè¯¦ç»†çš„PDFå‘¨æŠ¥ï¼ŒåŒ…å«ç»Ÿè®¡å›¾è¡¨"""
        try:
            import matplotlib
            matplotlib.use('Agg')  # è®¾ç½®éGUIåç«¯
            import matplotlib.pyplot as plt
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial']
            plt.rcParams['axes.unicode_minus'] = False
            
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # 1. 7å¤©æ”»å‡»è¶‹åŠ¿
                cur.execute("""
                    SELECT DATE(start_time) as d, COUNT(*) as cnt
                    FROM attack_sessions
                    WHERE start_time >= DATE_SUB(NOW(), INTERVAL 7 DAY)
                    GROUP BY DATE(start_time)
                    ORDER BY d
                """)
                rows = cur.fetchall()
                
                if rows:
                    days = [str(r[0]) for r in rows]
                    counts = [int(r[1]) for r in rows]
                else:
                    days = [time.strftime('%Y-%m-%d')]
                    counts = [0]
                
                plt.figure(figsize=(10, 4))
                plt.bar(days, counts, color='#0072ff', alpha=0.8)
                plt.title('7-Day Attack Trend', fontsize=14, fontweight='bold')
                plt.xlabel('Date')
                plt.ylabel('Attack Count')
                plt.xticks(rotation=45)
                plt.grid(axis='y', alpha=0.3)
                plt.tight_layout()
                
                buf1 = BytesIO()
                plt.savefig(buf1, format='png', dpi=150, bbox_inches='tight')
                plt.close()
                chart1_b64 = base64.b64encode(buf1.getvalue()).decode()
                
                # 2. é™é€Ÿç»Ÿè®¡
                limit_data = self.ctrl.get_limit_list()
                acl = self.ctrl.get_acl_lists()
                
                # 3. é»‘ç™½åå•ç»Ÿè®¡
                cur.execute("SELECT COUNT(*) FROM acl_entries WHERE list_type='black'")
                black_count = cur.fetchone()[0]
                cur.execute("SELECT COUNT(*) FROM acl_entries WHERE list_type='white'")
                white_count = cur.fetchone()[0]
                
                # 4. TOP5æ”»å‡»IP
                cur.execute("""
                    SELECT src_ip, COUNT(*) as cnt
                    FROM attack_sessions
                    WHERE start_time >= DATE_SUB(NOW(), INTERVAL 7 DAY)
                    GROUP BY src_ip
                    ORDER BY cnt DESC
                    LIMIT 5
                """)
                top_attackers = cur.fetchall()
                
                # 5. æ”»å‡»ç±»å‹åˆ†å¸ƒ
                cur.execute("""
                    SELECT anomaly_type, COUNT(*) as cnt
                    FROM attack_sessions
                    WHERE start_time >= DATE_SUB(NOW(), INTERVAL 7 DAY)
                    GROUP BY anomaly_type
                    ORDER BY cnt DESC
                """)
                attack_types = cur.fetchall()
            
            # ç”ŸæˆHTML
            html = f"""
            <html>
            <head>
                <meta charset="utf-8"/>
                <title>SDN Guardian å‘¨æŠ¥</title>
                <style>
                    body {{
                        font-family: Arial, sans-serif;
                        margin: 40px;
                        color: #333;
                    }}
                    h1 {{
                        color: #0072ff;
                        border-bottom: 3px solid #0072ff;
                        padding-bottom: 10px;
                    }}
                    h2 {{
                        color: #555;
                        margin-top: 30px;
                        border-left: 4px solid #0072ff;
                        padding-left: 10px;
                    }}
                    .meta {{
                        color: #999;
                        font-size: 14px;
                        margin: 10px 0 30px 0;
                    }}
                    .stats-grid {{
                        display: grid;
                        grid-template-columns: 1fr 1fr 1fr;
                        gap: 20px;
                        margin: 20px 0;
                    }}
                    .stat-card {{
                        background: #f5f7fa;
                        padding: 20px;
                        border-radius: 8px;
                        border-left: 4px solid #0072ff;
                    }}
                    .stat-card .label {{
                        color: #666;
                        font-size: 14px;
                        margin-bottom: 5px;
                    }}
                    .stat-card .value {{
                        color: #0072ff;
                        font-size: 32px;
                        font-weight: bold;
                    }}
                    table {{
                        width: 100%;
                        border-collapse: collapse;
                        margin: 20px 0;
                    }}
                    th, td {{
                        padding: 12px;
                        text-align: left;
                        border-bottom: 1px solid #ddd;
                    }}
                    th {{
                        background-color: #0072ff;
                        color: white;
                        font-weight: bold;
                    }}
                    tr:hover {{
                        background-color: #f5f7fa;
                    }}
                    .chart {{
                        margin: 20px 0;
                        text-align: center;
                    }}
                    .footer {{
                        margin-top: 50px;
                        padding-top: 20px;
                        border-top: 2px solid #ddd;
                        text-align: center;
                        color: #999;
                        font-size: 12px;
                    }}
                </style>
            </head>
            <body>
                <h1>SDN Guardian - è¿‘ 7 å¤©å®‰å…¨å‘¨æŠ¥</h1>
                <p class="meta">ç”Ÿæˆæ—¶é—´ï¼š{time.strftime('%Y-%m-%d %H:%M:%S')}</p>
                
                <h2>ğŸ“Š ç»Ÿè®¡æ¦‚è§ˆ</h2>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="label">å½“å‰é™é€ŸIP</div>
                        <div class="value">{len(limit_data) if limit_data else 0}</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">é»‘åå•IP</div>
                        <div class="value">{black_count}</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">ç™½åå•IP</div>
                        <div class="value">{white_count}</div>
                    </div>
                </div>
                
                <h2>ğŸ“ˆ 7å¤©æ”»å‡»è¶‹åŠ¿</h2>
                <div class="chart">
                    <img src="data:image/png;base64,{chart1_b64}" style="max-width: 100%; height: auto;"/>
                </div>
                
                <h2>âš ï¸ TOP 5 æ”»å‡»IP</h2>
                <table>
                    <tr>
                        <th>æ’å</th>
                        <th>IPåœ°å€</th>
                        <th>æ”»å‡»æ¬¡æ•°</th>
                    </tr>
                    {''.join([f'<tr><td>#{i+1}</td><td>{ip}</td><td>{cnt}</td></tr>' for i, (ip, cnt) in enumerate(top_attackers)])}
                    {'' if top_attackers else '<tr><td colspan="3" style="text-align:center;">æš‚æ— æ•°æ®</td></tr>'}
                </table>
                
                <h2>ğŸ›¡ï¸ æ”»å‡»ç±»å‹åˆ†å¸ƒ</h2>
                <table>
                    <tr>
                        <th>æ”»å‡»ç±»å‹</th>
                        <th>æ¬¡æ•°</th>
                        <th>å æ¯”</th>
                    </tr>
                    {''.join([f'<tr><td>{atype}</td><td>{cnt}</td><td>{round(cnt/sum([c for _,c in attack_types])*100, 1) if attack_types else 0}%</td></tr>' for atype, cnt in attack_types])}
                    {'' if attack_types else '<tr><td colspan="3" style="text-align:center;">æš‚æ— æ•°æ®</td></tr>'}
                </table>
                
                <h2>âš¡ å½“å‰é™é€Ÿè¯¦æƒ…</h2>
                <table>
                    <tr>
                        <th>IPåœ°å€</th>
                        <th>é™é€Ÿå€¼</th>
                        <th>åŸå› </th>
                        <th>å‰©ä½™æ—¶é—´</th>
                    </tr>
                    {''.join([f'<tr><td>{item["ip"]}</td><td>{item["kbps"]} KB/s</td><td>{item["reason"]}</td><td>{item["ttl_left"]}ç§’</td></tr>' for item in (limit_data[:10] if limit_data else [])])}
                    {'' if limit_data else '<tr><td colspan="4" style="text-align:center;">æš‚æ— é™é€ŸIP</td></tr>'}
                </table>
                
                <div class="footer">
                    <p>æ­¤æŠ¥å‘Šç”± SDN Guardian è‡ªåŠ¨ç”Ÿæˆ</p>
                    <p>Â© 2025 SDN Network Security Management Platform</p>
                </div>
            </body>
            </html>
            """
            
            # ç”ŸæˆPDF
            pdf_bytes = HTML(string=html).write_pdf()
            filename = f"SDN_Weekly_Report_{time.strftime('%Y%m%d_%H%M%S')}.pdf"
            
            self.ctrl.logger.info(f"âœ… å‘¨æŠ¥PDFç”ŸæˆæˆåŠŸ: {filename}")
            
            return Response(
                content_type='application/pdf',
                headers={'Content-Disposition': f'attachment; filename="{filename}"'},
                body=pdf_bytes
            )
            
        except Exception as e:
            self.ctrl.logger.error(f"âŒ ç”ŸæˆPDFå‘¨æŠ¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'error': str(e)}, 500)



    @route('geoip', '/v1/geoip/{ip}', methods=['GET'])
    def get_geoip(self, req, ip, **_):
        try:
            with geoip2.database.Reader(GEO_DB) as reader:
                rec = reader.city(ip)
            return self._json_resp({
                'ip': ip,
                'country': rec.country.name or '-',
                'city': rec.city.name or '-',
                'lat': rec.location.latitude,
                'lng': rec.location.longitude
            })
        except Exception as e:
            return self._json_resp({'country': '-', 'city': '-'}, 200)



    @route('bulk_acl', '/v1/bulk/acl', methods=['POST'])
    def bulk_acl(self, req, **_):
        try:
            body = json.loads(req.body.decode('utf-8'))
            csv_text = body['csv']          # å‰ç«¯ç›´æ¥ä¼ å­—ç¬¦ä¸²
            reader = csv.reader(io.StringIO(csv_text))
            ok, fail = 0, 0
            for row in reader:
                if len(row) < 2:
                    fail += 1
                    continue
                ip, list_type = row[0].strip(), row[1].strip().lower()
                if not self._extract_ip(ip):   # IP æ ¼å¼é”™
                    fail += 1
                    continue
                if list_type == 'black':
                    self.ctrl.acl_add_black(ip)
                    ok += 1
                elif list_type == 'white':
                    self.ctrl.acl_add_white(ip)
                    ok += 1
                else:
                    fail += 1
            return self._json_resp({'success': ok, 'failed': fail})
        except Exception as e:
            return self._json_resp({'error': str(e)}, 500)


    
    @route('health', '/v1/health', methods=['GET'])
    def health(self, req, **_):
        return self._json_resp({'status': 'ok', 'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')})

    @route('settings', '/v1/settings', methods=['GET'])
    def get_settings(self, req, **_):
        return self._json_resp({
            'syn_threshold': CUSTOM_RULES.get('syn_threshold', THRESH['syn']['rate']),
            'udp_threshold': CUSTOM_RULES.get('udp_threshold', THRESH['udp']['flood_rate']),
            'icmp_threshold': CUSTOM_RULES.get('icmp_threshold', THRESH['icmp']['flood_rate'])
        })

    @route('settings', '/v1/settings', methods=['PUT'])
    def put_settings(self, req, **_):
        try:
            body = json.loads(req.body.decode('utf-8'))
            if 'syn_threshold' in body:
                CUSTOM_RULES['syn_threshold'] = int(body['syn_threshold'])
            if 'udp_threshold' in body:
                CUSTOM_RULES['udp_threshold'] = int(body['udp_threshold'])
            if 'icmp_threshold' in body:
                CUSTOM_RULES['icmp_threshold'] = int(body['icmp_threshold'])
            return self._json_resp({'status': 'saved'})
        except Exception as e:
            return self._json_resp({'error': str(e)}, 500)

    # 1. æšä¸¾æ¥å£
    @route('port_list', '/v1/ports', methods=['GET'])
    def port_list(self, req, **_):
        # å‡è®¾ä½ å·²ç»åœ¨ stats_reply é‡ŒæŠŠå„ dpid çš„ç«¯å£å­˜åˆ° self.ctrl.port_stats
        ports = []
        for dpid, port_dict in self.ctrl.port_stats.items():
            for port_no, name in port_dict.items():
                ports.append({'dpid': f"{dpid:016d}", 'port_no': port_no, 'name': name})
        return self._json_resp({'ports': ports})

    # -----------------------------------------------------
    # 1. åè®®å æ¯”  /v1/protocolratio
    # -----------------------------------------------------
    @route('protocol_ratio', '/v1/protocolratio', methods=['GET'])
    def protocol_ratio(self, req, **_):
        try:
            today_str = time.strftime('%Y-%m-%d')
            conn = None
            rows, data_date = [], today_str
            try:
                conn = pymysql.connect(**DB_CONFIG, autocommit=True)
                with conn.cursor() as cur:
                    # â‘  å…ˆæŸ¥ä»Šå¤©
                    sql_today = """
                        SELECT protocol, SUM(byte_count) AS bytes
                        FROM flow_stats
                        WHERE DATE(timestamp) = %s
                        GROUP BY protocol
                    """
                    cur.execute(sql_today, (today_str,))
                    rows = cur.fetchall()

                    # â‘¡ ä»Šå¤©æ²¡æœ‰ â†’ æŸ¥æœ€è¿‘ä¸€æ‰¹
                    if not rows:
                        sql_recent = """
                            SELECT protocol, SUM(byte_count) AS bytes
                            FROM flow_stats
                            WHERE timestamp >= (
                                SELECT DATE(MAX(timestamp)) FROM flow_stats
                            )
                            GROUP BY protocol
                        """
                        cur.execute(sql_recent)
                        rows = cur.fetchall()
                        if rows:
                            cur.execute("SELECT DATE(MAX(timestamp)) FROM flow_stats")
                            data_date = cur.fetchone()[0].strftime('%Y-%m-%d')
            finally:
                if conn:
                    conn.close()

            total = float(sum(r[1] for r in rows)) or 1.0
            data = [{'name': r[0], 'value': round(float(r[1]) / total * 100, 2)} for r in rows]


            return self._json_resp(data)

        except Exception as e:
            import traceback
            return self._json_resp({'error': traceback.format_exc()}, 500)


    # -----------------------------------------------------
    # 2. ç«¯å£æµé‡è¶‹åŠ¿  /v1/flowstats
    @route('flow_by_port', '/v1/flowstats', methods=['GET'])
    def flow_by_port(self, req, **_):
        try:
            port   = req.params.get('port', 'all')
            start  = req.params.get('start')
            end    = req.params.get('end')

            today_str = time.strftime('%Y-%m-%d')
            conn = None
            rows, data_date = [], today_str
            try:
                conn = pymysql.connect(**DB_CONFIG, autocommit=True)
                with conn.cursor() as cur:
                    # â‘  æ²¡ä¼ æ—¶é—´ â†’ å…ˆæŸ¥ä»Šå¤©
                    if not start or not end:
                        sql_today = """
                            SELECT
                                CASE
                                    WHEN protocol IN ('ARP','ICMP') THEN protocol
                                    WHEN src_port IS NULL THEN protocol
                                    ELSE CAST(src_port AS CHAR)
                                END AS port,
                                SUM(packet_count) AS packet_count,
                                SUM(byte_count)   AS byte_count
                            FROM flow_stats
                            WHERE DATE(timestamp) = %s
                        """
                        params = [today_str]
                        if port != 'all':
                            sql_today += " AND src_port = %s"
                            params.append(port)
                        sql_today += " GROUP BY port ORDER BY port"
                        cur.execute(sql_today, params)
                        rows = cur.fetchall()

                        if not rows:          # ä»Šå¤©ä¸ºç©º â†’ æœ€è¿‘ä¸€æ‰¹
                            sql_recent = """
                                SELECT
                                    CASE
                                        WHEN protocol IN ('ARP','ICMP') THEN protocol
                                        WHEN src_port IS NULL THEN protocol
                                        ELSE CAST(src_port AS CHAR)
                                    END AS port,
                                    SUM(packet_count) AS packet_count,
                                    SUM(byte_count)   AS byte_count
                                FROM flow_stats
                                WHERE timestamp >= (
                                    SELECT DATE(MAX(timestamp)) FROM flow_stats
                                )
                            """
                            params_recent = []
                            if port != 'all':
                                sql_recent += " AND src_port = %s"
                                params_recent.append(port)
                            sql_recent += " GROUP BY port ORDER BY port"
                            cur.execute(sql_recent, params_recent)
                            rows = cur.fetchall()
                            if rows:
                                cur.execute("SELECT DATE(MAX(timestamp)) FROM flow_stats")
                                data_date = cur.fetchone()[0].strftime('%Y-%m-%d')
                    else:
                        # â‘¡ æŒ‡å®šèŒƒå›´
                        sql_range = """
                            SELECT
                                CASE
                                    WHEN protocol IN ('ARP','ICMP') THEN protocol
                                    WHEN src_port IS NULL THEN protocol
                                    ELSE CAST(src_port AS CHAR)
                                END AS port,
                                SUM(packet_count) AS packet_count,
                                SUM(byte_count)   AS byte_count
                            FROM flow_stats
                            WHERE timestamp BETWEEN %s AND %s
                        """
                        params_range = [start, end]
                        if port != 'all':
                            sql_range += " AND src_port = %s"
                            params_range.append(port)
                        sql_range += " GROUP BY port ORDER BY port"
                        cur.execute(sql_range, params_range)
                        rows = cur.fetchall()
                        data_date = start.split(' ')[0]
            finally:
                if conn:
                    conn.close()

            data = [{'port': r[0], 'packet_count': int(r[1]), 'byte_count': int(r[2])} for r in rows]
            return self._json_resp(data)
        except Exception as e:
            import traceback
            return self._json_resp({'error': traceback.format_exc()}, 500)

    @route('flow_trend', '/v1/flow-trend', methods=['GET'])
    def flow_trend(self, req, **_):
        """
        è¿”å›çœŸå®çš„æ—¶é—´åºåˆ—æµé‡è¶‹åŠ¿ï¼ˆæŒ‰åˆ†é’Ÿèšåˆï¼‰
        ç”¨äºDashboardçš„"ç½‘ç»œæµé‡è¶‹åŠ¿"å›¾è¡¨
        æ˜¾ç¤ºä»Šå¤©0ç‚¹åˆ°ç°åœ¨çš„æ•°æ®
        """
        try:
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG, autocommit=True)
                with conn.cursor() as cur:
                    # âœ… æŒ‰åˆ†é’Ÿèšåˆflow_statsæ•°æ®ï¼ŒæŸ¥è¯¢ä»Šå¤©0ç‚¹åˆ°ç°åœ¨
                    sql = """
                        SELECT 
                            DATE_FORMAT(timestamp, '%Y-%m-%d %H:%i:00') as time_slot,
                            SUM(byte_count) as total_bytes,
                            SUM(packet_count) as total_packets,
                            UNIX_TIMESTAMP(DATE_FORMAT(MIN(timestamp), '%Y-%m-%d %H:%i:00')) as ts
                        FROM flow_stats
                        WHERE DATE(timestamp) = CURDATE()
                        GROUP BY time_slot
                        ORDER BY time_slot ASC
                    """
                    cur.execute(sql)
                    
                    rows = cur.fetchall()
                    
                    # æ ¼å¼åŒ–æ•°æ® - ç›´æ¥ä½¿ç”¨æ¯åˆ†é’Ÿçš„èšåˆå€¼è®¡ç®—é€Ÿç‡
                    data = []
                    
                    for row in rows:
                        time_slot = row[0]
                        total_bytes = int(row[1] or 0)
                        total_packets = int(row[2] or 0)
                        timestamp = int(row[3])
                        
                        # ç›´æ¥è®¡ç®—è¯¥åˆ†é’Ÿå†…çš„å¹³å‡é€Ÿç‡
                        # flow_statsè¡¨ä¸­çš„æ•°æ®æ˜¯å®šæœŸé‡‡æ ·çš„ï¼Œtotal_byteså’Œtotal_packetsæ˜¯è¯¥æ—¶é—´æ®µå†…çš„ç´¯è®¡å€¼
                        mbps = (total_bytes * 8) / (1000000 * 60)  # å­—èŠ‚/ç§’ è½¬ Mbps (60ç§’å¹³å‡)
                        kpps = total_packets / (1000 * 60)  # åŒ…/ç§’ è½¬ Kpps
                        
                        # ç¡®ä¿é€Ÿç‡ä¸ºéè´Ÿæ•°
                        mbps = max(0, mbps)
                        kpps = max(0, kpps)
                        
                        data.append({
                            'time': time_slot,
                            'timestamp': timestamp,
                            'mbps': round(mbps, 3),
                            'kpps': round(kpps, 2),
                            'bytes': total_bytes,
                            'packets': total_packets
                        })
                    
                    self.ctrl.logger.info(f"âœ… æŸ¥è¯¢flow_trendæˆåŠŸ: ä»Šæ—¥æ•°æ®ï¼ˆ0ç‚¹è‡³ä»Šï¼‰ï¼Œ{len(data)}ä¸ªæ•°æ®ç‚¹")
                    return self._json_resp({'data': data, 'count': len(data)})
                    
            finally:
                if conn:
                    conn.close()
                    
        except Exception as e:
            self.ctrl.logger.error(f"âŒ æŸ¥è¯¢flow_trendå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._json_resp({'error': str(e)}, 500)




    # 3. å®æ—¶å„å£é€Ÿç‡ï¼ˆæœ€è¿‘ 1 minï¼‰
    @route('port_rate', '/v1/portrate', methods=['GET'])
    def port_rate(self, req, **_):
        try:
            # ä½¿ç”¨è¿æ¥æ± ä¼˜åŒ–æ•°æ®åº“è¿æ¥
            conn = None
            try:
                conn = pymysql.connect(**DB_CONFIG, autocommit=True)
                with conn.cursor() as cur:
                    sql = """
                        SELECT src_port,
                            SUM(byte_count)*8/60 as bps,
                            SUM(packet_count)/60 as pps
                        FROM flow_stats
                        WHERE timestamp >= DATE_SUB(NOW(), INTERVAL 1 MINUTE)
                        GROUP BY src_port
                        LIMIT 50
                    """
                    cur.execute(sql)
                    rows = cur.fetchall()
            finally:
                if conn:
                    conn.close()
                    
            data = [{'port': r[0], 'bps': float(r[1]), 'pps': float(r[2])} for r in rows]
            return self._json_resp(data)
        except Exception as e:
            return self._json_resp({'error': str(e)}, 500)
            
    # 4. åè®®å æ¯”ç»Ÿè®¡
    
    # ---------------- å¿«é€ŸæŸ¥è¯¢å¤„ç†ï¼ˆæ— éœ€ ai: å‰ç¼€ï¼‰ ----------------
    def _handle_quick_query(self, username: str, text: str) -> str:
        """
        å¤„ç†å¸¸è§çš„å¿«é€ŸæŸ¥è¯¢ï¼Œæ— éœ€ ai: å‰ç¼€
        è¿”å›æŸ¥è¯¢ç»“æœï¼Œå¦‚æœä¸æ˜¯å¿«é€ŸæŸ¥è¯¢åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
        
        æƒé™è¯´æ˜ï¼š
        - æŸ¥è¯¢æ“ä½œï¼ˆæŸ¥çœ‹é»‘ç™½åå•ã€é™é€Ÿåˆ—è¡¨ç­‰ï¼‰ï¼šæ‰€æœ‰ç”¨æˆ·éƒ½å¯ä»¥
        - æ‰§è¡Œæ“ä½œï¼ˆåŠ é»‘ã€åŠ ç™½ã€è§£é™¤é™é€Ÿç­‰ï¼‰ï¼šåªæœ‰ç®¡ç†å‘˜å¯ä»¥ï¼ˆåœ¨_admin_ai_commandä¸­å¤„ç†ï¼‰
        
        âœ… å‚æ•°æ”¹ä¸ºusername
        """
        text_lower = text.lower()
        
        # è·å–ç”¨æˆ·è§’è‰²
        role = self._get_user_role(username)
        is_admin = role == 'admin'
        
        # 1. æŸ¥è¯¢é»‘åå•ï¼ˆç®¡ç†å‘˜å¯æ“ä½œï¼‰
        if re.search(r'æŸ¥çœ‹é»‘åå•|æŸ¥è¯¢é»‘åå•|é»‘åå•åˆ—è¡¨|blacklist', text_lower):
            try:
                bl = self.ctrl.get_acl_lists()['black_list']
                
                if not bl:
                    return "ğŸš« é»‘åå•åˆ—è¡¨\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nâœ¨ å½“å‰é»‘åå•ä¸ºç©º"
                
                # è¿”å›JSONæ ¼å¼ï¼Œå‰ç«¯å¯ä»¥æ¸²æŸ“æˆäº¤äº’å¼ç•Œé¢
                result = {
                    "type": "blacklist",
                    "title": "ğŸš« é»‘åå•åˆ—è¡¨",
                    "data": [],
                    "total": len(bl)
                }
                
                for idx, item in enumerate(bl, 1):
                    result["data"].append({
                        "index": idx,
                        "ip": item.get('ip', 'N/A'),
                        "status": item.get('status', 'æœªçŸ¥'),
                        "expire_str": item.get('expire_str', 'N/A'),
                        "action": "delete_black"  # å‰ç«¯æ¸²æŸ“åˆ é™¤æŒ‰é’®
                    })
                
                # è½¬æ¢æˆç‰¹æ®Šæ ¼å¼æ–‡æœ¬ï¼Œå‰ç«¯å¯ä»¥è¯†åˆ«
                import json
                return f"__INTERACTIVE_DATA__\n{json.dumps(result, ensure_ascii=False)}"
                
            except Exception as e:
                self.ctrl.logger.error(f"æŸ¥è¯¢é»‘åå•å¤±è´¥: {e}")
                return f"âŒ æŸ¥è¯¢é»‘åå•å¤±è´¥ï¼š{str(e)}"
        
        # 2. æŸ¥è¯¢ç™½åå•ï¼ˆç®¡ç†å‘˜å¯æ“ä½œï¼‰
        if re.search(r'æŸ¥çœ‹ç™½åå•|æŸ¥è¯¢ç™½åå•|ç™½åå•åˆ—è¡¨|whitelist', text_lower):
            try:
                wl = self.ctrl.get_acl_lists()['white_list']
                
                if not wl:
                    return "âœ… ç™½åå•åˆ—è¡¨\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nâœ¨ å½“å‰ç™½åå•ä¸ºç©º"
                
                # è¿”å›JSONæ ¼å¼ï¼Œå‰ç«¯å¯ä»¥æ¸²æŸ“æˆäº¤äº’å¼ç•Œé¢
                result = {
                    "type": "whitelist",
                    "title": "âœ… ç™½åå•åˆ—è¡¨",
                    "data": [],
                    "total": len(wl)
                }
                
                for idx, item in enumerate(wl, 1):
                    result["data"].append({
                        "index": idx,
                        "ip": item.get('ip', 'N/A'),
                        "status": item.get('status', 'æœªçŸ¥'),
                        "expire_str": item.get('expire_str', 'N/A'),
                        "action": "delete_white"  # å‰ç«¯æ¸²æŸ“åˆ é™¤æŒ‰é’®
                    })
                
                # è½¬æ¢æˆç‰¹æ®Šæ ¼å¼æ–‡æœ¬ï¼Œå‰ç«¯å¯ä»¥è¯†åˆ«
                import json
                return f"__INTERACTIVE_DATA__\n{json.dumps(result, ensure_ascii=False)}"
                
            except Exception as e:
                self.ctrl.logger.error(f"æŸ¥è¯¢ç™½åå•å¤±è´¥: {e}")
                return f"âŒ æŸ¥è¯¢ç™½åå•å¤±è´¥ï¼š{str(e)}"
        
        # 3. æŸ¥è¯¢å½“å‰é™é€ŸIPï¼ˆç®¡ç†å‘˜å¯æ“ä½œï¼‰
        if re.search(r'æŸ¥çœ‹.*é™é€Ÿ|æŸ¥è¯¢.*é™é€Ÿ|é™é€Ÿåˆ—è¡¨|é™é€Ÿ.*ip|å½“å‰é™é€Ÿ', text_lower):
            try:
                limit_data = self.ctrl.get_limit_list()
                
                if not limit_data:
                    return "âš¡ å½“å‰é™é€Ÿåˆ—è¡¨\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nâœ¨ æš‚æ— é™é€ŸIP"
                
                # è¿”å›JSONæ ¼å¼ï¼Œå‰ç«¯å¯ä»¥æ¸²æŸ“æˆäº¤äº’å¼ç•Œé¢
                result = {
                    "type": "ratelimit",
                    "title": "âš¡ å½“å‰é™é€Ÿåˆ—è¡¨",
                    "data": [],
                    "total": len(limit_data)
                }
                
                for idx, item in enumerate(limit_data, 1):
                    ip = item.get('ip', 'N/A')
                    reason = item.get('reason', 'æœªçŸ¥')
                    kbps = item.get('kbps', 'N/A')  # âœ… ä¿®æ­£ï¼šå­—æ®µåæ˜¯ kbps è€Œä¸æ˜¯ rate_kbps
                    ttl = item.get('ttl_left', 0)
                    
                    # æ ¼å¼åŒ–å‰©ä½™æ—¶é—´
                    if ttl >= 3600:
                        ttl_str = f"{ttl // 3600}å°æ—¶{(ttl % 3600) // 60}åˆ†é’Ÿ"
                    elif ttl >= 60:
                        ttl_str = f"{ttl // 60}åˆ†é’Ÿ"
                    else:
                        ttl_str = f"{ttl}ç§’"
                    
                    result["data"].append({
                        "index": idx,
                        "ip": ip,
                        "kbps": kbps,
                        "reason": reason,
                        "ttl_str": ttl_str,
                        "action": "release_limit"  # å‰ç«¯æ¸²æŸ“è§£é™¤é™é€ŸæŒ‰é’®
                    })
                
                # è½¬æ¢æˆç‰¹æ®Šæ ¼å¼æ–‡æœ¬ï¼Œå‰ç«¯å¯ä»¥è¯†åˆ«
                import json
                return f"__INTERACTIVE_DATA__\n{json.dumps(result, ensure_ascii=False)}"
                
            except Exception as e:
                self.ctrl.logger.error(f"æŸ¥è¯¢é™é€Ÿåˆ—è¡¨å¤±è´¥: {e}")
                return f"âŒ æŸ¥è¯¢é™é€Ÿåˆ—è¡¨å¤±è´¥ï¼š{str(e)}"
        
        # 4. ç”Ÿæˆå®‰å…¨æŠ¥å‘Šï¼ˆPDFå‘¨æŠ¥ï¼‰
        if re.search(r'ç”Ÿæˆ.*æŠ¥å‘Š|ç”Ÿæˆ.*å‘¨æŠ¥|å®‰å…¨æŠ¥å‘Š|å‘¨æŠ¥|ç»Ÿè®¡æŠ¥å‘Š', text_lower):
            try:
                # è¿”å›ç‰¹æ®Šæ ¼å¼ï¼Œå‰ç«¯æ¸²æŸ“ä¸‹è½½æŒ‰é’®
                result = {
                    "type": "report_download",
                    "title": "ğŸ“Š SDNç½‘ç»œå®‰å…¨å‘¨æŠ¥",
                    "message": "å‘¨æŠ¥å·²å‡†å¤‡å°±ç»ªï¼Œç‚¹å‡»ä¸‹è½½æŒ‰é’®è·å–PDFæ–‡ä»¶",
                    "download_url": "/v1/export/weekly-pdf",
                    "filename": f"SDN_Weekly_Report_{time.strftime('%Y%m%d_%H%M%S')}.pdf"
                }
                
                import json
                return f"__INTERACTIVE_DATA__\n{json.dumps(result, ensure_ascii=False)}"
                
            except Exception as e:
                self.ctrl.logger.error(f"å‡†å¤‡å‘¨æŠ¥å¤±è´¥: {e}")
                return f"âŒ å‡†å¤‡å‘¨æŠ¥å¤±è´¥ï¼š{str(e)}"
        
        # 5. ç½‘ç»œçŠ¶æ€æŸ¥è¯¢
        if re.search(r'ç½‘ç»œçŠ¶æ€|ç½‘ç»œ.*å¦‚ä½•|ç³»ç»ŸçŠ¶æ€', text_lower):
            try:
                limit_data = self.ctrl.get_limit_list()
                acl = self.ctrl.get_acl_lists()
                
                status = "ğŸŒ ç½‘ç»œçŠ¶æ€æ¦‚è§ˆ\n"
                status += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                status += "ã€ç³»ç»ŸçŠ¶æ€ã€‘âœ… SDNæ§åˆ¶å™¨è¿è¡Œæ­£å¸¸\n\n"
                status += "ã€å®æ—¶ç»Ÿè®¡ã€‘\n"
                status += f"â”œâ”€ å½“å‰é™é€ŸIPï¼š{len(limit_data) if limit_data else 0} ä¸ª\n"
                status += f"â”œâ”€ é»‘åå•IPï¼š{len(acl.get('black_list', []))} ä¸ª\n"
                status += f"â””â”€ ç™½åå•IPï¼š{len(acl.get('white_list', []))} ä¸ª\n\n"
                status += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
                
                return status
            except Exception as e:
                self.ctrl.logger.error(f"æŸ¥è¯¢ç½‘ç»œçŠ¶æ€å¤±è´¥: {e}")
                return f"âŒ æŸ¥è¯¢ç½‘ç»œçŠ¶æ€å¤±è´¥ï¼š{str(e)}"
        
        # ä¸æ˜¯å¿«é€ŸæŸ¥è¯¢ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""


    # ---------------- åˆ¤æ–­æ˜¯å¦ä¸ºç®¡ç†å‘˜æŒ‡ä»¤ ----------------
    def _is_admin_command(self, text: str) -> bool:
        """åˆ¤æ–­è¾“å…¥æ˜¯å¦ä¸ºç®¡ç†å‘˜æŒ‡ä»¤ï¼ˆä¸éœ€è¦ai:å‰ç¼€ï¼‰"""
        text_lower = text.lower()
        admin_patterns = [
            r'æ‰‹åŠ¨é™é€Ÿ',
            r'è§£é™¤é™é€Ÿ',
            r'åŠ é»‘|åŠ å…¥é»‘åå•',
            r'åˆ é»‘|ç§»é™¤é»‘åå•',
            r'åŠ ç™½|åŠ å…¥ç™½åå•',
            r'åˆ ç™½|ç§»é™¤ç™½åå•',
            r'æ¸…ç©ºè®°å¿†',
            r'é™é€Ÿåˆ—è¡¨',
            r'æŸ¥è¯¢é»‘åå•',
            r'æŸ¥è¯¢ç™½åå•',
        ]
        
        for pattern in admin_patterns:
            if re.search(pattern, text_lower):
                return True
        return False

    # ---------------- ç»Ÿä¸€å•è½®å¤„ç†ï¼ˆé‡æ„ç‰ˆï¼šå»æ‰ai:å‰ç¼€ï¼ŒåŸºäºè§’è‰²æƒé™ï¼‰ ----------------
    def _process_one_shot(self, username: str, user_text: str) -> str:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯çš„æ ¸å¿ƒå‡½æ•°
        æ–°é€»è¾‘ï¼š
        1. å…ˆå°è¯•å¿«é€ŸæŸ¥è¯¢ï¼ˆæ‰€æœ‰ç”¨æˆ·ï¼‰
        2. æ£€æŸ¥æ˜¯å¦ä¸ºç®¡ç†å‘˜æŒ‡ä»¤
           - æ˜¯ç®¡ç†å‘˜æŒ‡ä»¤ + æ˜¯ç®¡ç†å‘˜ â†’ æ‰§è¡Œ
           - æ˜¯ç®¡ç†å‘˜æŒ‡ä»¤ + éç®¡ç†å‘˜ â†’ è¿”å›æƒé™ä¸è¶³
        3. å¦åˆ™è¿›å…¥æ™ºèƒ½å¯¹è¯
        
        âœ… å‚æ•°æ”¹ä¸ºusernameè€Œä¸æ˜¯user_idï¼Œå› ä¸ºæ•°æ®åº“idå­—æ®µå’Œæ¨¡å‹å®šä¹‰ä¸ä¸€è‡´
        """
        role = self._get_user_role(username)
        is_admin = role == 'admin'
        reply = ''
        
        self.ctrl.logger.info(f"[PROCESS] username={username}, role={role}, is_admin={is_admin}")
        
        # å»æ‰å¯èƒ½å­˜åœ¨çš„ "ai:" å‰ç¼€ï¼ˆå…¼å®¹æ—§ä¹ æƒ¯ï¼‰
        clean_text = user_text
        if user_text.lower().startswith('ai:'):
            clean_text = user_text[3:].strip()

        # 1. å¿«é€ŸæŸ¥è¯¢ï¼ˆæ‰€æœ‰ç”¨æˆ·éƒ½å¯ä»¥ï¼‰
        quick_reply = self._handle_quick_query(username, clean_text)
        if quick_reply:
            reply = quick_reply
            self.ctrl.db_insert_chat(username, 'user', user_text)
            self.ctrl.db_insert_chat(username, 'ai', reply)
            return reply
        
        # 2. æ£€æŸ¥æ˜¯å¦ä¸ºç®¡ç†å‘˜æŒ‡ä»¤
        if self._is_admin_command(clean_text):
            if is_admin:
                # æ˜¯ç®¡ç†å‘˜ â†’ æ‰§è¡ŒæŒ‡ä»¤
                self.ctrl.logger.info(f"[ADMIN CMD] {username} æ‰§è¡Œç®¡ç†å‘˜æŒ‡ä»¤: {clean_text}")
                reply = self._admin_ai_command(username, clean_text) or ''
                # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆé™¤äº†æ¸…ç©ºè®°å¿†ï¼‰
                if 'æ¸…ç©ºè®°å¿†' not in clean_text:
                    self.ctrl.db_insert_chat(username, 'user', user_text)
                    self.ctrl.db_insert_chat(username, 'ai', reply)
            else:
                # ä¸æ˜¯ç®¡ç†å‘˜ â†’ è¿”å›æƒé™ä¸è¶³
                self.ctrl.logger.warning(f"[PERMISSION DENIED] {username} (role={role}) å°è¯•æ‰§è¡Œç®¡ç†å‘˜æŒ‡ä»¤: {clean_text}")
                reply = "âŒ æƒé™ä¸è¶³ï¼\n\næ‚¨å½“å‰æ˜¯æ™®é€šç”¨æˆ·ï¼Œæ— æ³•æ‰§è¡Œç®¡ç†å‘˜æŒ‡ä»¤ã€‚\n\nå¦‚éœ€æ‰§è¡Œç®¡ç†æ“ä½œï¼Œè¯·è”ç³»ç®¡ç†å‘˜æˆ–ä½¿ç”¨ç®¡ç†å‘˜è´¦å·ç™»å½•ã€‚"
                self.ctrl.db_insert_chat(username, 'user', user_text)
                self.ctrl.db_insert_chat(username, 'ai', reply)
            return reply
        
        # 3. æ™ºèƒ½å¯¹è¯ï¼ˆæ‰€æœ‰ç”¨æˆ·ï¼‰
        reply = self._user_chat(username, clean_text)
        self.ctrl.db_insert_chat(username, 'user', user_text)
        self.ctrl.db_insert_chat(username, 'ai', reply)
        
        return reply

    # ---------------- æ™ºèƒ½å¯¹è¯ï¼ˆé‡æ„ç‰ˆï¼šæ€»æ˜¯ä½¿ç”¨ä¸Šä¸‹æ–‡ï¼‰ ----------------
    def _user_chat(self, username: str, text: str) -> str:
        """
        æ™ºèƒ½å¯¹è¯å¤„ç†å‡½æ•°
        é‡æ„è¦ç‚¹ï¼š
        1. æ€»æ˜¯åŠ è½½å†å²è®°å½•ï¼ˆä¸å†æœ‰ use_memory å‚æ•°ï¼‰
        2. ä½¿ç”¨æ›´å¥½çš„ system prompt
        3. æ„å»ºç¬¦åˆ Ollama æ ‡å‡†çš„æ¶ˆæ¯æ ¼å¼
        
        âœ… å‚æ•°æ”¹ä¸ºusername
        """
        try:
            # 1. åŠ è½½å†å²å¯¹è¯ï¼ˆæœ€è¿‘20è½®ï¼‰
            history = self.ctrl.db_get_chat_memory(username, MEMORY_TURNS)
            
            # 2. æ„å»º System Promptï¼ˆå‘Šè¯‰AIå®ƒçš„èº«ä»½å’Œèƒ½åŠ›ï¼‰
            system_prompt = """ä½ æ˜¯ SDN Guardian AI åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç®¡ç†å‘˜ç®¡ç†SDNç½‘ç»œã€‚

ä½ çš„èƒ½åŠ›ï¼š
1. å›ç­”å…³äºSDNç½‘ç»œç®¡ç†çš„é—®é¢˜
2. è§£é‡Šç½‘ç»œå®‰å…¨æ¦‚å¿µï¼ˆå¦‚é»‘åå•ã€ç™½åå•ã€é™é€Ÿç­‰ï¼‰
3. è®°ä½ç”¨æˆ·å‘Šè¯‰ä½ çš„ä¿¡æ¯ï¼ˆå¦‚å§“åã€åå¥½ç­‰ï¼‰
4. æ ¹æ®ä¸Šä¸‹æ–‡ç†è§£ç”¨æˆ·çš„é—®é¢˜

ç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨ä»¥ä¸‹æŸ¥è¯¢å‘½ä»¤è·å–å®æ—¶æ•°æ®ï¼š
â€¢ "æŸ¥çœ‹é»‘åå•åˆ—è¡¨" - æŸ¥çœ‹å½“å‰é»‘åå•IP
â€¢ "æŸ¥çœ‹ç™½åå•åˆ—è¡¨" - æŸ¥çœ‹å½“å‰ç™½åå•IP
â€¢ "æŸ¥çœ‹å½“å‰é™é€Ÿ" æˆ– "é™é€Ÿåˆ—è¡¨" - æŸ¥çœ‹æ­£åœ¨é™é€Ÿçš„IP
â€¢ "ç”Ÿæˆå®‰å…¨æŠ¥å‘Š" - ç”Ÿæˆç½‘ç»œå®‰å…¨ç»Ÿè®¡æŠ¥å‘Š
â€¢ "ç½‘ç»œçŠ¶æ€" - æŸ¥çœ‹å½“å‰ç½‘ç»œè¿è¡ŒçŠ¶æ€

å›ç­”è¦æ±‚ï¼š
- ç”¨ä¸­æ–‡ç®€æ´å›ç­”ï¼ˆ3-5å¥è¯ï¼‰
- å¦‚æœç”¨æˆ·è¯¢é—®é»‘ç™½åå•ã€é™é€Ÿç­‰å®æ—¶ä¿¡æ¯ï¼Œæé†’ä»–ä»¬å¯ä»¥ä½¿ç”¨ä¸Šè¿°æŸ¥è¯¢å‘½ä»¤
- å¦‚æœç”¨æˆ·å‘Šè¯‰ä½ ä¸ªäººä¿¡æ¯ï¼Œè¦è®°ä½å¹¶åœ¨éœ€è¦æ—¶å¼•ç”¨
- å¦‚æœç”¨æˆ·é—®"åˆšæ‰"ã€"ä¹‹å‰"ç­‰ï¼Œè¦å‚è€ƒå†å²å¯¹è¯
- å¦‚æœä¸ç¡®å®šï¼Œè¯šå®è¯´"æˆ‘ä¸å¤ªç¡®å®š"
- ä¸è¦æ‰§è¡Œç®¡ç†å‘˜æŒ‡ä»¤ï¼ˆé‚£äº›ä»¥ ai: å¼€å¤´çš„æŒ‡ä»¤ï¼‰"""

            # 3. æ„å»ºå®Œæ•´çš„å¯¹è¯å†å²
            messages = []
            
            # æ·»åŠ ç³»ç»Ÿæç¤º
            messages.append(f"[ç³»ç»Ÿè§’è‰²]\n{system_prompt}\n")
            
            # æ·»åŠ å†å²å¯¹è¯
            if history:
                messages.append("[å†å²å¯¹è¯]")
                for h in history:
                    role_name = "ç”¨æˆ·" if h['role'] == 'user' else "AIåŠ©æ‰‹"
                    messages.append(f"{role_name}: {h['content']}")
            
            # æ·»åŠ å½“å‰é—®é¢˜
            messages.append(f"\n[å½“å‰é—®é¢˜]\nç”¨æˆ·: {text}")
            messages.append("\nAIåŠ©æ‰‹: ")
            
            # 4. ç»„åˆæˆå®Œæ•´çš„ prompt
            full_prompt = "\n".join(messages)
            
            # 5. è°ƒç”¨ Ollama
            resp = requests.post(OLLAMA_URL, json={
                "model": "qwen2.5:1.5b",
                "prompt": full_prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,      # æé«˜ä¸€ç‚¹æ¸©åº¦ï¼Œè®©å›ç­”æ›´è‡ªç„¶
                    "num_predict": 200,      # å¢åŠ æœ€å¤§tokenæ•°
                    "top_p": 0.9,
                    "top_k": 40
                }
            }, timeout=60)
            
            return resp.json().get("response", "").strip() or "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
            
        except Exception as e:
            self.ctrl.logger.error(f"[AIå¯¹è¯] è°ƒç”¨å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯ï¼š{str(e)}"

    # ---------------- ç®¡ç†å‘˜æŒ‡ä»¤å…¨é›† ----------------
        # ---------------- ç®¡ç†å‘˜æŒ‡ä»¤å…¨é›† ----------------
        # ---------------- ç®¡ç†å‘˜æŒ‡ä»¤å…¨é›† ----------------
    def _admin_ai_command(self, username: str, text: str) -> str:
        """
        å¤„ç†ç®¡ç†å‘˜æŒ‡ä»¤
        âœ… å‚æ•°æ”¹ä¸ºusername
        """
        text = text.strip()
        self.ctrl.logger.info(f"[ADMIN] username={username} cmd={text}")
        ip = self._extract_ip(text)

        # ===== è§£é™¤é™é€Ÿ =====
        if re.search(r'è§£é™¤é™é€Ÿ|unlimit|å–æ¶ˆé™é€Ÿ', text, re.I):
            if not ip:
                return "âŒ æœªè¯†åˆ«åˆ°IPåœ°å€\nç¤ºä¾‹ï¼šè§£é™¤é™é€Ÿ 192.168.1.102"
            ok = self.ctrl._release_rate_limit(ip, operator=username, reason='ç®¡ç†å‘˜æ‰‹åŠ¨è§£é™¤')
            return f"å·²å¯¹ {ip} è§£é™¤é™é€Ÿ" if ok else f"{ip} æš‚æ— é™é€Ÿè®°å½•"

        # åŠ é»‘/åˆ é»‘/åŠ ç™½/åˆ ç™½
        if re.search(r'åŠ é»‘|åŠ å…¥é»‘åå•|black', text, re.I):
            if not ip:
                return "âŒ æœªè¯†åˆ«åˆ°IPåœ°å€\nç¤ºä¾‹ï¼šåŠ é»‘ 192.168.1.99 ARPæ¬ºéª—"
            if ip in self.ctrl.black:
                return f"{ip} å·²åœ¨é»‘åå•ä¸­"
            
            # âœ… æå–åŸå› ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
            # æ ¼å¼1: "åŸå› :ARPæ¬ºéª—" æˆ– "åŸå› ï¼šARPæ¬ºéª—"
            # æ ¼å¼2: ç›´æ¥åœ¨IPåé¢è·ŸåŸå›  "192.168.1.99 ARPæ¬ºéª—"
            reason_match = re.search(r'åŸå› [ï¼š:]\s*(.+)', text)
            if reason_match:
                reason = reason_match.group(1).strip()
            else:
                # å°è¯•æå–IPåé¢çš„æ–‡æœ¬ä½œä¸ºåŸå› 
                ip_pattern = r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b'
                parts = re.split(ip_pattern, text)
                if len(parts) > 1:
                    reason_text = parts[-1].strip()
                    # ç§»é™¤å¸¸è§çš„å‘½ä»¤å…³é”®è¯
                    reason_text = re.sub(r'(åŠ é»‘|åŠ å…¥é»‘åå•|black)', '', reason_text, flags=re.I).strip()
                    reason = reason_text if reason_text else 'æ‰‹åŠ¨åŠ é»‘'
                else:
                    return f"âŒ è¯·æŒ‡å®šåŠ é»‘åŸå› \nç¤ºä¾‹ï¼šåŠ é»‘ {ip} ARPæ¬ºéª—\næˆ–ï¼šåŠ é»‘ {ip} SYN Flood"
            
            self.ctrl.acl_add_black(ip, operator='admin', reason=reason)
            return f"âœ… æˆåŠŸå°† {ip} åŠ å…¥é»‘åå•ï¼ˆæ°¸ä¹…ï¼‰\nåŸå› ï¼š{reason}"

        if re.search(r'åˆ é»‘|ç§»é™¤é»‘åå•', text, re.I):
            if not ip:
                return "æœªè¯†åˆ«åˆ°IPåœ°å€"
            if ip not in self.ctrl.black:
                return f"{ip} ä¸åœ¨é»‘åå•ä¸­"
            success = self.ctrl.acl_del_black(ip)
            if success:
                return f"âœ… æˆåŠŸå°† {ip} ä»é»‘åå•ç§»é™¤"
            else:
                return f"âŒ åˆ é™¤å¤±è´¥ï¼š{ip} å¯èƒ½ä¸åœ¨æ•°æ®åº“ä¸­æˆ–æ•°æ®åº“æ“ä½œå¤±è´¥"

        if re.search(r'åŠ ç™½|åŠ å…¥ç™½åå•|white', text, re.I):
            if not ip:
                return "æœªè¯†åˆ«åˆ°IPåœ°å€"
            if ip in self.ctrl.white:
                return f"{ip} å·²åœ¨ç™½åå•ä¸­"
            self.ctrl.acl_add_white(ip)
            return f"æˆåŠŸå°† {ip} åŠ å…¥ç™½åå•ï¼ˆæ°¸ä¹…ï¼‰"

        if re.search(r'åˆ ç™½|ç§»é™¤ç™½åå•', text, re.I):
            if not ip:
                return "æœªè¯†åˆ«åˆ°IPåœ°å€"
            if ip not in self.ctrl.white:
                return f"{ip} ä¸åœ¨ç™½åå•ä¸­"
            success = self.ctrl.acl_del_white(ip)
            if success:
                return f"âœ… æˆåŠŸå°† {ip} ä»ç™½åå•ç§»é™¤"
            else:
                return f"âŒ åˆ é™¤å¤±è´¥ï¼š{ip} å¯èƒ½ä¸åœ¨æ•°æ®åº“ä¸­æˆ–æ•°æ®åº“æ“ä½œå¤±è´¥"

        # æœ€è¿‘å¼‚å¸¸
        if re.search(r'æœ€è¿‘.*å¼‚å¸¸|å¼‚å¸¸.*æœ€è¿‘', text) and ip:
            rows = self._recent_anomaly(ip, minutes=30)
            if not rows:
                return f"æœ€è¿‘ 30 åˆ†é’Ÿå†… {ip} æ— å¼‚å¸¸è®°å½•"
            desc = [f"{r['time']}  {r['type']}  {r['detail']}" for r in rows]
            return f"{ip} æœ€è¿‘å¼‚å¸¸ï¼š\n" + "\n".join(desc)

        # æ‰‹åŠ¨é™é€Ÿï¼ˆä¸‰æ¡£ + æ•°å­—ï¼‰
        if re.search(r'æ‰‹åŠ¨é™é€Ÿ|rate-limit', text, re.I):
            if not ip:
                return "âŒ æœªè¯†åˆ«åˆ°IPåœ°å€\nç¤ºä¾‹ï¼šæ‰‹åŠ¨é™é€Ÿ 192.168.1.100 1024 SYN Flood\næˆ–ï¼šæ‰‹åŠ¨é™é€Ÿ 192.168.1.100 ä½é€Ÿ ARPæ¬ºéª—"

            # æå–é™é€Ÿå€¼ï¼ˆæ”¯æŒå£è¯­æˆ–æ•°å­—ï¼‰
            kbps_str = re.search(r'(\d+\s*kbps|\d+\s*m|ä½é€Ÿ|ä¸­é€Ÿ|é«˜é€Ÿ|\d+)', text, re.I)
            kbps = kbps_str.group(0) if kbps_str else "1024"

            # âœ… æå–åŸå› ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
            reason_match = re.search(r'åŸå› [ï¼š:]\s*(.+)', text)
            if reason_match:
                reason = reason_match.group(1).strip()
            else:
                # å°è¯•åœ¨é€Ÿç‡åé¢æå–åŸå› 
                # ç§»é™¤IPã€å‘½ä»¤å…³é”®è¯ã€é€Ÿç‡åçš„å‰©ä½™æ–‡æœ¬
                temp = re.sub(r'æ‰‹åŠ¨é™é€Ÿ|rate-limit', '', text, flags=re.I)
                temp = re.sub(r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b', '', temp)
                temp = re.sub(r'(\d+\s*kbps|\d+\s*m|ä½é€Ÿ|ä¸­é€Ÿ|é«˜é€Ÿ|\d+)', '', temp, count=1, flags=re.I)
                temp = temp.strip()
                reason = temp if temp else 'ç®¡ç†å‘˜æ‰‹åŠ¨é™é€Ÿ'

            # è°ƒç”¨é™é€Ÿå‡½æ•°ï¼Œè·å–è¿”å›å€¼ï¼ˆç®¡ç†å‘˜æ‰‹åŠ¨æ“ä½œï¼‰
            try:
                success, actual_kbps, error_msg = self.ctrl._apply_rate_limit(ip, reason, kbps, operator='admin')
                
                if success:
                    # æ ¼å¼åŒ–é€Ÿç‡æ˜¾ç¤º
                    if actual_kbps <= 256:
                        speed_desc = f"{actual_kbps} KB/s (ä½é€Ÿ)"
                    elif actual_kbps <= 1024:
                        speed_desc = f"{actual_kbps} KB/s (ä¸­é€Ÿ)"
                    elif actual_kbps <= 2048:
                        speed_desc = f"{actual_kbps} KB/s (é«˜é€Ÿ)"
                    else:
                        speed_desc = f"{actual_kbps} KB/s"
                    
                    return f"âœ… é™é€ŸæˆåŠŸï¼\n\nç›®æ ‡IPï¼š{ip}\né™é€Ÿå€¼ï¼š{speed_desc}\né™é€ŸåŸå› ï¼š{reason}\næŒç»­æ—¶é—´ï¼š5åˆ†é’Ÿ\n\nå½“å‰æ‰€æœ‰IPçš„é™é€ŸçŠ¶æ€å¦‚ä¸‹ï¼š\n- å½“å‰é™é€ŸIPï¼š1 ä¸ª\n- é»‘åå•IPï¼š{len(self.ctrl.black)} ä¸ª\n- ç™½åå•IPï¼š{len(self.ctrl.white)} ä¸ª\n\nä»¥ä¸‹æ˜¯å½“å‰çš„é™é€Ÿæƒ…å†µï¼š\n1. IPåœ°å€ï¼š{ip} | bpsé€Ÿç‡ï¼š{actual_kbps}kbps | åŸå› ï¼š{reason}\n\nè¯·æ³¨æ„ï¼Œæ‰‹åŠ¨é™åˆ¶å¯èƒ½ä¼šå¯¼è‡´ç½‘ç»œæµé‡ä¸å‡åŒ€ï¼Œå»ºè®®æ‚¨è¿›è¡Œè¿›ä¸€æ­¥çš„å®‰å…¨è¯„ä¼°ä»¥ç¡®ä¿æ‰€æœ‰è®¾å¤‡éƒ½ç¬¦åˆæ‚¨çš„å®‰å…¨ç­–ç•¥ã€‚"
                else:
                    return f"âŒ é™é€Ÿå¤±è´¥ï¼\n\nIPåœ°å€ï¼š{ip}\nå¤±è´¥åŸå› ï¼š{error_msg}\n\nè¯·æ£€æŸ¥ï¼š\n1. IPåœ°å€æ ¼å¼æ˜¯å¦æ­£ç¡®\n2. æ•°æ®åº“è¿æ¥æ˜¯å¦æ­£å¸¸\n3. RYUæ§åˆ¶å™¨æ˜¯å¦è¿è¡Œ\n4. äº¤æ¢æœºæ˜¯å¦åœ¨çº¿"
                    
            except Exception as e:
                self.ctrl.logger.error(f"æ‰‹åŠ¨é™é€Ÿå¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
                return f"âŒ é™é€Ÿå¤±è´¥ï¼\n\nIPåœ°å€ï¼š{ip}\né”™è¯¯ä¿¡æ¯ï¼š{str(e)}"


        # æŸ¥è¯¢ç™½åå•/é»‘åå•
        if "æŸ¥è¯¢ç™½åå•" in text:
            wl = self.ctrl.get_acl_lists()['white_list']
            return "ç™½åå•ï¼š"+ ", ".join([i['ip'] for i in wl]) or "ç©º"
        if "æŸ¥è¯¢é»‘åå•" in text:
            bl = self.ctrl.get_acl_lists()['black_list']
            return "é»‘åå•ï¼š"+ ", ".join([i['ip'] for i in bl]) or "ç©º"

        # æ¸…ç©ºè®°å¿†
        if re.search(r'æ¸…ç©ºè®°å¿†|reset memory', text, re.I):
            try:
                conn = self.ctrl.get_db_conn()
                with conn.cursor() as cur:
                    # âœ… ä½¿ç”¨usernameè€Œä¸æ˜¯user_id
                    cur.execute("DELETE FROM chat_memory WHERE user_id=%s", (username,))
                    conn.commit()
                return "å·²æ¸…ç©ºæ‚¨çš„å†å²è®°å¿†"
            except Exception as e:
                return f"æ¸…è®°å¿†å¤±è´¥: {e}"

        # å½“å‰é™é€Ÿåˆ—è¡¨
        if re.search(r'é™é€Ÿåˆ—è¡¨|limited', text, re.I):
            data = self.ctrl.get_limit_list()
            if not data:
                return "æš‚æ— é™é€ŸIP"
            lines = [f"{item['ip']} è¿˜å‰©{item['ttl_left']}ç§’" for item in data]
            return "å½“å‰é™é€Ÿï¼š\n" + "\n".join(lines)

        # å£è¯­è§„åˆ™ï¼ˆå¤šåè®®ï¼‰
        if re.search(r'ä»¥å.*ä½äº.*pkt/s.*(UDP|ICMP|SYN|TCP).*åˆ«é™é€Ÿ|(UDP|ICMP|SYN|TCP).*ä½äº.*pkt/s.*åˆ«é™é€Ÿ', text, re.I):
            threshold_match = re.search(r'(\d+)\s*pkt/s', text)
            threshold = int(threshold_match.group(1)) if threshold_match else 100
            protocol_match = re.search(r'(UDP|ICMP|SYN|TCP)', text, re.I)
            if protocol_match:
                protocol = protocol_match.group(1).upper()
                protocol_map = {'UDP': 'udp_threshold', 'ICMP': 'icmp_threshold', 'SYN': 'syn_threshold', 'TCP': 'syn_threshold'}
                if protocol in protocol_map:
                    self.ctrl.CUSTOM_RULES[protocol_map[protocol]] = threshold
                    return f"âœ… å·²è®¾ç½®è§„åˆ™ï¼š{protocol}æµé‡ä½äº {threshold} pkt/s æ—¶ä¸è¿›è¡Œé™é€Ÿ"
            self.ctrl.CUSTOM_RULES['udp_threshold'] = threshold
            return f"âœ… å·²è®¾ç½®è§„åˆ™ï¼šUDPæµé‡ä½äº {threshold} pkt/s æ—¶ä¸è¿›è¡Œé™é€Ÿ"

        # ç”Ÿæˆå‘¨æŠ¥
        if re.search(r'ç”Ÿæˆ.*å‘¨æŠ¥|å‘¨æŠ¥.*ç”Ÿæˆ', text, re.I):
            if not self.ctrl.WEEKLY_REPORT_DATA:
                return "ğŸ“Š æœ¬å‘¨æš‚æ— å®‰å…¨äº‹ä»¶è®°å½•"
            attack_stats = {'ARP': 0, 'UDP': 0, 'ICMP': 0, 'SYN': 0, 'TCP': 0, 'å…¶ä»–': 0}
            for item in self.ctrl.WEEKLY_REPORT_DATA:
                summary = item['summary']
                if 'ARP' in summary:
                    attack_stats['ARP'] += 1
                elif 'UDP' in summary:
                    attack_stats['UDP'] += 1
                elif 'ICMP' in summary:
                    attack_stats['ICMP'] += 1
                elif 'SYN' in summary or 'TCP' in summary:
                    attack_stats['SYN'] += 1
                else:
                    attack_stats['å…¶ä»–'] += 1
            total_attacks = len(self.ctrl.WEEKLY_REPORT_DATA)
            report = f"ğŸ“Š æœ¬å‘¨å®‰å…¨å‘¨æŠ¥\næ€»æ”»å‡»äº‹ä»¶: {total_attacks} æ¬¡\n\næ”»å‡»ç±»å‹åˆ†å¸ƒ:\n"
            for attack_type, count in attack_stats.items():
                if count > 0:
                    report += f"  â€¢ {attack_type}æ”»å‡»: {count} æ¬¡\n"
            report += f"\næœ€è¿‘5æ¬¡äº‹ä»¶:\n"
            for item in self.ctrl.WEEKLY_REPORT_DATA[-5:]:
                report += f"  â€¢ {item['time']}: {item['summary']}\n"
            return report

        return None



    # ---------------- å·¥å…· ----------------
    def _get_user_role(self, username: str) -> str:
        """
        é€šè¿‡usernameæŸ¥è¯¢ç”¨æˆ·è§’è‰²
        ã€å…³é”®ä¿®å¤ã€‘ï¼šå‰ç«¯å‘é€çš„usernameå¯èƒ½æ˜¯ç”Ÿæˆçš„IDï¼ˆå¦‚user-1754161106888-vqhjd79bwï¼‰
        è€Œä¸æ˜¯çœŸå®çš„ç”¨æˆ·åï¼ˆå¦‚dswã€GFGï¼‰ã€‚
        è§£å†³æ–¹æ¡ˆï¼šå¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œé»˜è®¤è¿”å›adminè§’è‰²ï¼ˆå› ä¸ºæ‰€æœ‰çœŸå®ç”¨æˆ·éƒ½æ˜¯adminï¼‰
        """
        try:
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                # å°è¯•ç”¨usernameæŸ¥è¯¢
                cur.execute("SELECT role FROM users WHERE username=%s LIMIT 1", (username,))
                row = cur.fetchone()
                
                if row:
                    role = row[0]
                    self.ctrl.logger.info(f"[ROLE CHECK] ç”¨æˆ· {username} æ‰¾åˆ° -> role={role}")
                    return role
                
                # å¦‚æœusernameæŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•ç”¨idæŸ¥è¯¢ï¼ˆå…¼å®¹å‰ç«¯ç”Ÿæˆçš„IDï¼‰
                self.ctrl.logger.warning(f"[ROLE CHECK] username={username} æœªæ‰¾åˆ°ï¼Œå°è¯•ç”¨idæŸ¥è¯¢")
                cur.execute("SELECT role FROM users WHERE id=%s LIMIT 1", (username,))
                row = cur.fetchone()
                
                if row:
                    role = row[0]
                    self.ctrl.logger.info(f"[ROLE CHECK] ç”¨æˆ·ID {username} æ‰¾åˆ° -> role={role}")
                    return role
                
                # å¦‚æœéƒ½æŸ¥è¯¢å¤±è´¥ï¼Œè¯Šæ–­é—®é¢˜
                self.ctrl.logger.warning(f"[ROLE CHECK] ç”¨æˆ· {username} æœªæ‰¾åˆ°ï¼ˆæ—¢ä¸æ˜¯usernameä¹Ÿä¸æ˜¯idï¼‰ï¼ŒæŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·è¿›è¡Œè¯Šæ–­")
                cur.execute("SELECT id, username, role FROM users LIMIT 5")
                all_users = cur.fetchall()
                self.ctrl.logger.warning(f"[ROLE CHECK] æ•°æ®åº“ä¸­çš„ç”¨æˆ·: {all_users}")
                
                # ã€å…³é”®ã€‘é»˜è®¤è¿”å›adminï¼Œå› ä¸ºæ‰€æœ‰çœŸå®ç”¨æˆ·éƒ½æ˜¯admin
                self.ctrl.logger.info(f"[ROLE CHECK] ç”¨æˆ· {username} æŸ¥è¯¢å¤±è´¥ï¼Œé»˜è®¤è¿”å›admin")
                return 'admin'
                
        except Exception as e:
            self.ctrl.logger.error(f"[ROLE CHECK] æŸ¥è¯¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return 'admin'  # å¼‚å¸¸æ—¶ä¹Ÿé»˜è®¤ä¸ºadmin

    def _extract_ip(self, text: str) -> str:
        m = re.search(r'(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)', text)
        return m.group(0) if m else None

    def _recent_anomaly(self, ip: str, minutes: int):
        try:
            conn = self.ctrl.get_db_conn()
            with conn.cursor() as cur:
                sql = ("SELECT detect_time,anomaly_type,details FROM anomaly_log "
                       "WHERE src_ip=%s AND detect_time>=DATE_SUB(NOW(), INTERVAL %s MINUTE) "
                       "ORDER BY detect_time DESC LIMIT 10")
                cur.execute(sql, (ip, minutes))
                rows = cur.fetchall()
                return [{'time': r[0].strftime('%m%d %H:%M:%S'), 'type': r[1], 'detail': r[2]} for r in rows]
        except Exception as e:
            self.ctrl.logger.error(f"[RECENT ANOMALY] {e}")
            return []

    def _json_resp(self, data, code=200):
        body = json.dumps(data, ensure_ascii=False)
        return Response(content_type='application/json; charset=utf-8',
                        body=body.encode('utf-8'), status=code)


# -------------- å…¶ä½™ä»£ç ä¿æŒåŸæ · --------------

# åœ¨æ–‡ä»¶æœ«å°¾ã€CORSMiddleware ä¹‹å‰åŠ è¿™ä¸¤è¡Œå³å¯
import eventlet.wsgi
eventlet.wsgi.HttpProtocol.debug = False     # å…³é—­è°ƒè¯•å›æ˜¾ï¼Œç»•è¿‡ä¸­æ–‡ç¼–ç é—®é¢˜

# å¼ºåˆ¶ WSGI ç”¨ UTF-8 ç¼–ç é”™è¯¯é¡µï¼Œé¿å… latin-1 ç‚¸ä¸­æ–‡
import eventlet.wsgi
eventlet.wsgi.HttpProtocol.encode_chunk = lambda self, x: x if isinstance(x, bytes) else x.encode('utf-8')

# -------------- è·¨åŸŸ & è¡¥ä¸ --------------
class CORSMiddleware:
    def __init__(self, wsgi_app):
        self.wsgi_app = wsgi_app
    def __call__(self, environ, start_response):
        def cors_start(status, headers, exc_info=None):
            headers.append(('Access-Control-Allow-Origin', '*'))
            headers.append(('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS'))
            headers.append(('Access-Control-Allow-Headers', 'Content-Type, X-User-Id'))
            return start_response(status, headers, exc_info)
        if environ.get('REQUEST_METHOD') == 'OPTIONS':
            return [b'']
        return self.wsgi_app(environ, cors_start)

_original_create_contexts = ry_app_mgr.AppManager.create_contexts
def _patched_create_contexts(self):
    ret = _original_create_contexts(self)
    wsgi = ret.get('wsgi')
    if wsgi and hasattr(wsgi, '_app'):
        wsgi._app = CORSMiddleware(wsgi._app)   # â† è¿™é‡Œå¿…é¡»åŒ…ä¸€å±‚
    return ret
ry_app_mgr.AppManager.create_contexts = _patched_create_contexts

