"""
Security Agent - ç½‘ç»œå®‰å…¨æ™ºèƒ½ä»£ç†
é›†æˆRAGçŸ¥è¯†åº“æ£€ç´¢å’ŒMCPå·¥å…·è°ƒç”¨ï¼Œå®ç°è‡ªä¸»å†³ç­–
"""

import json
import requests
import os
import pymysql
from typing import Dict, List, Any, Optional
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

try:
    from .rag_service import rag_service
    RAG_SERVICE = rag_service
except ImportError:
    try:
        from rag_service import rag_service
        RAG_SERVICE = rag_service
    except ImportError:
        # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨æœ¬åœ°RAG
        try:
            from .rag_system import get_rag_instance
            RAG_SERVICE = None
        except ImportError:
            from rag_system import get_rag_instance
            RAG_SERVICE = None

# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'host': '192.168.44.1',
    'user': 'root',
    'password': 'yyr0218...',
    'db': 'network_management',
    'charset': 'utf8mb4'
}


class SecurityAgent:
    """ç½‘ç»œå®‰å…¨æ™ºèƒ½ä»£ç†"""
    
    def __init__(self, 
                 kimi_api_key: str = None,
                 model: str = "kimi-k2-turbo-preview"):
        """
        åˆå§‹åŒ–Security Agent
        
        Args:
            kimi_api_key: Kimi APIå¯†é’¥
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆkimi-k2-turbo-previewï¼‰
        """
        self.kimi_api_key = kimi_api_key or os.getenv("KIMI_API_KEY", "")
        self.kimi_api_url = "https://api.moonshot.cn/v1/chat/completions"
        self.model = model  # ä½¿ç”¨Kimi k2æ¨¡å‹
        
        # æ··åˆæ–¹æ¡ˆï¼šä¼˜å…ˆä½¿ç”¨é˜¿é‡Œäº‘Embedding + Kimi LLM
        if RAG_SERVICE is not None:
            self.rag = RAG_SERVICE
            self.use_dashscope_embedding = True
            print("âœ… ä½¿ç”¨é˜¿é‡Œäº‘DashScope Embeddingï¼ˆRAGæ£€ç´¢ï¼‰")
            # åˆå§‹åŒ–çŸ¥è¯†åº“
            self._initialize_knowledge_base()
        else:
            self.rag = get_rag_instance()
            self.use_dashscope_embedding = False
            print("âœ… ä½¿ç”¨æœ¬åœ°RAGç³»ç»Ÿï¼ˆEmbeddingï¼‰")
            # æ„å»ºæœ¬åœ°çŸ¥è¯†åº“
            self._build_local_knowledge_base()
        
        # LLMä½¿ç”¨Kimi API
        print("âœ… ä½¿ç”¨Kimi k2 LLMï¼ˆæ¨¡å‹åˆ†æï¼‰")
        
        # MCPå·¥å…·æ³¨å†Œè¡¨
        self.tools = {
            # æŸ¥è¯¢å·¥å…·ï¼ˆä»æ•°æ®åº“è·å–å®æ—¶æ•°æ®ï¼‰
            "search_knowledge": self._tool_search_knowledge,
            "query_acl_status": self._tool_query_acl_status,
            "query_acl_blacklist": self._tool_query_acl_blacklist,
            "query_acl_whitelist": self._tool_query_acl_whitelist,
            "query_rate_limit_history": self._tool_query_rate_limit_history,
            "query_attack_history": self._tool_query_attack_history,
            "query_flow_stats": self._tool_query_flow_stats,
            "get_defense_rules": self._tool_get_defense_rules,
            "query_network_topology": self._tool_query_network_topology,
            "get_current_status": self._tool_get_current_status,
            "query_device_anomalies": self._tool_query_device_anomalies,
            
            # æ‰§è¡Œå·¥å…·ï¼ˆä¿®æ”¹æ•°æ®åº“å’Œé˜²å¾¡è§„åˆ™ï¼‰
            "apply_rate_limit": self._tool_apply_rate_limit,
            "add_to_blacklist": self._tool_add_to_blacklist,
            "add_to_whitelist": self._tool_add_to_whitelist,
            "remove_from_blacklist": self._tool_remove_from_blacklist,
            "remove_from_whitelist": self._tool_remove_from_whitelist,
            "release_rate_limit": self._tool_release_rate_limit,
            "modify_rate_limit_duration": self._tool_modify_rate_limit_duration,
            "modify_rate_limit_kbps": self._tool_modify_rate_limit_kbps,
            
            # å…¼å®¹æ—§ç‰ˆæœ¬
            "check_ip_history": self._tool_check_ip_history,
            "get_network_status": self._tool_get_network_status,
        }
        
        print("âœ… Security Agentåˆå§‹åŒ–æˆåŠŸï¼ˆæ··åˆæ–¹æ¡ˆï¼šé˜¿é‡Œäº‘Embedding + æœ¬åœ°Ollama LLMï¼‰")
    
    def _initialize_knowledge_base(self):
        """åˆå§‹åŒ–é˜¿é‡Œäº‘RAGçŸ¥è¯†åº“"""
        try:
            import asyncio
            import os
            from pathlib import Path
            
            # çŸ¥è¯†åº“æ–‡æ¡£è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
            current_dir = Path(__file__).parent
            docs_dir = current_dir.parent / "docs" / "knowledge_base"
            
            print(f"ğŸ” æŸ¥æ‰¾çŸ¥è¯†åº“ç›®å½•: {docs_dir}")
            if not docs_dir.exists():
                print(f"âš ï¸ çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨: {docs_dir}")
                return
            
            # è¯»å–æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶ï¼ˆåŒ…æ‹¬TXTã€PDFç­‰ï¼‰
            all_files = list(docs_dir.glob("*"))
            doc_files = [f for f in all_files if f.is_file() and f.suffix in ['.txt', '.pdf', '.csv', '.docx']]
            
            if not doc_files:
                print(f"âš ï¸ çŸ¥è¯†åº“ç›®å½•ä¸­æ²¡æœ‰æ–‡æ¡£æ–‡ä»¶: {docs_dir}")
                return
            
            print(f"ğŸ“š å¼€å§‹åŠ è½½çŸ¥è¯†åº“æ–‡æ¡£ï¼Œå…±{len(doc_files)}ä¸ªæ–‡ä»¶...")
            
            # å¼‚æ­¥åŠ è½½æ–‡æ¡£
            async def load_documents():
                for doc_file in doc_files:
                    try:
                        content = None
                        
                        # æ ¹æ®æ–‡ä»¶ç±»å‹æå–å†…å®¹
                        if doc_file.suffix == '.txt':
                            with open(doc_file, 'r', encoding='utf-8') as f:
                                content = f.read()
                        elif doc_file.suffix == '.pdf':
                            # æå–PDFå†…å®¹
                            try:
                                import PyPDF2
                                with open(doc_file, 'rb') as f:
                                    pdf_reader = PyPDF2.PdfReader(f)
                                    content = ""
                                    for page in pdf_reader.pages:
                                        content += page.extract_text()
                            except Exception as e:
                                print(f"âš ï¸ PDFæå–å¤±è´¥ {doc_file.name}: {e}")
                                continue
                        elif doc_file.suffix == '.csv':
                            with open(doc_file, 'r', encoding='utf-8') as f:
                                content = f.read()
                        elif doc_file.suffix == '.docx':
                            # æå–DOCXå†…å®¹
                            try:
                                from docx import Document
                                doc = Document(doc_file)
                                content = "\n".join([para.text for para in doc.paragraphs])
                            except Exception as e:
                                print(f"âš ï¸ DOCXæå–å¤±è´¥ {doc_file.name}: {e}")
                                continue
                        
                        if content and content.strip():
                            await self.rag.create_embeddings_from_file(content, doc_file.name)
                            print(f"âœ… å·²åŠ è½½: {doc_file.name}")
                        else:
                            print(f"âš ï¸ æ–‡ä»¶ä¸ºç©º: {doc_file.name}")
                    except Exception as e:
                        print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {doc_file.name}: {e}")
            
            # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(asyncio.run, load_documents())
                        future.result(timeout=30)
                else:
                    loop.run_until_complete(load_documents())
            except RuntimeError:
                asyncio.run(load_documents())
            
            print("âœ… çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _build_local_knowledge_base(self):
        """æ„å»ºæœ¬åœ°RAGçŸ¥è¯†åº“"""
        try:
            from pathlib import Path
            current_dir = Path(__file__).parent
            docs_dir = str(current_dir.parent / "docs" / "knowledge_base")
            
            print(f"ğŸ” æ„å»ºæœ¬åœ°çŸ¥è¯†åº“: {docs_dir}")
            if os.path.exists(docs_dir):
                count = self.rag.build_knowledge_base(docs_dir)
                print(f"âœ… æœ¬åœ°çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œå…±{count}ä¸ªæ–‡æ¡£å—")
            else:
                print(f"âš ï¸ çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨: {docs_dir}")
        except Exception as e:
            print(f"âŒ æœ¬åœ°çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")
    
    def _call_llm(self, prompt: str, temperature: float = 0.3) -> str:
        """è°ƒç”¨LLM - ä½¿ç”¨Kimi API"""
        return self._call_kimi_llm(prompt, temperature)
    
    def _call_kimi_llm(self, prompt: str, temperature: float = 0.6) -> str:
        """è°ƒç”¨Kimi API (kimi-k2-turbo-preview)"""
        try:
            if not self.kimi_api_key:
                print("âŒ æœªé…ç½®KIMI_API_KEY")
                return "é”™è¯¯ï¼šæœªé…ç½®Kimi APIå¯†é’¥"
            
            headers = {
                "Authorization": f"Bearer {self.kimi_api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": self.model,  # kimi-k2-turbo-preview
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç½‘ç»œç®¡ç†AIåŠ©æ‰‹ï¼Œå…·å¤‡ç½‘ç»œè®¾å¤‡é…ç½®åˆ†æã€ç½‘ç»œå®‰å…¨è¯Šæ–­ã€æ€§èƒ½ä¼˜åŒ–å»ºè®®ã€æ•…éšœæ’æŸ¥æŒ‡å¯¼ç­‰èƒ½åŠ›ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œæä¾›å‡†ç¡®ã€ä¸“ä¸šçš„å»ºè®®ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": temperature
            }
            
            response = requests.post(
                self.kimi_api_url,
                headers=headers,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            if result.get("choices") and len(result["choices"]) > 0:
                return result["choices"][0]["message"]["content"]
            else:
                print(f"âš ï¸ Kimi APIå“åº”å¼‚å¸¸: {result}")
                return "Kimi APIè¿”å›å¼‚å¸¸å“åº”"
                
        except Exception as e:
            print(f"âŒ Kimi APIè°ƒç”¨å¤±è´¥: {e}")
            return f"Kimi APIè°ƒç”¨å¤±è´¥: {str(e)}"
    
    # ========== MCPå·¥å…· ==========
    
    def _tool_search_knowledge(self, query: str) -> Dict[str, Any]:
        """æœç´¢çŸ¥è¯†åº“ï¼ˆMCPå·¥å…·ï¼‰"""
        try:
            if self.use_dashscope_embedding:
                # ä½¿ç”¨é˜¿é‡Œäº‘Embeddingè¿›è¡ŒRAGæ£€ç´¢
                import asyncio
                try:
                    # å°è¯•è·å–å½“å‰äº‹ä»¶å¾ªç¯
                    loop = asyncio.get_event_loop()
                    if loop.is_running():
                        # å¦‚æœäº‹ä»¶å¾ªç¯å·²åœ¨è¿è¡Œï¼Œä½¿ç”¨run_coroutine_threadsafe
                        import concurrent.futures
                        with concurrent.futures.ThreadPoolExecutor() as executor:
                            future = executor.submit(
                                asyncio.run,
                                self.rag.search_similar_documents(query, k=3)
                            )
                            results = future.result(timeout=10)
                    else:
                        # äº‹ä»¶å¾ªç¯å­˜åœ¨ä½†æœªè¿è¡Œï¼Œç›´æ¥è¿è¡Œ
                        results = loop.run_until_complete(
                            self.rag.search_similar_documents(query, k=3)
                        )
                except RuntimeError:
                    # æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                    results = asyncio.run(
                        self.rag.search_similar_documents(query, k=3)
                    )
                
                knowledge = [r.get("content", "") for r in results]
            else:
                # ä½¿ç”¨æœ¬åœ°RAG
                knowledge = self.rag.retrieve_knowledge(query, top_k=3)
            
            return {
                "tool": "search_knowledge",
                "success": True,
                "data": knowledge,
                "count": len(knowledge)
            }
        except Exception as e:
            print(f"âš ï¸ çŸ¥è¯†åº“æœç´¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                "tool": "search_knowledge",
                "success": False,
                "error": str(e),
                "data": [],
                "count": 0
            }
    
    # ========== MCPå·¥å…·1: æŸ¥è¯¢ACLçŠ¶æ€ ==========
    def _tool_query_acl_status(self, ip: str) -> Dict[str, Any]:
        """æŸ¥è¯¢IPçš„é»‘ç™½åå•çŠ¶æ€"""
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                sql = "SELECT list_type, created_at FROM acl_entries WHERE ip=%s"
                cur.execute(sql, (ip,))
                result = cur.fetchone()
                
                if result:
                    return {
                        "tool": "query_acl_status",
                        "success": True,
                        "data": {
                            "ip": ip,
                            "status": result[0],  # 'white' or 'black'
                            "added_at": result[1].strftime('%Y-%m-%d %H:%M:%S') if result[1] else None
                        }
                    }
                else:
                    return {
                        "tool": "query_acl_status",
                        "success": True,
                        "data": {
                            "ip": ip,
                            "status": "normal",
                            "added_at": None
                        }
                    }
        except Exception as e:
            return {
                "tool": "query_acl_status",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·1.5: æŸ¥è¯¢æ‰€æœ‰é»‘åå•IP ==========
    def _tool_query_acl_blacklist(self) -> Dict[str, Any]:
        """æŸ¥è¯¢æ‰€æœ‰é»‘åå•IPï¼ˆå®Œæ•´åˆ—è¡¨ï¼‰"""
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                sql = "SELECT ip, created_at FROM acl_entries WHERE list_type='black' ORDER BY created_at DESC"
                cur.execute(sql)
                results = cur.fetchall()
                
                blacklist = []
                for row in results:
                    blacklist.append({
                        "ip": row[0],
                        "added_at": row[1].strftime('%Y-%m-%d %H:%M:%S') if row[1] else None
                    })
                
                return {
                    "tool": "query_acl_blacklist",
                    "success": True,
                    "data": {
                        "total": len(blacklist),
                        "blacklist": blacklist
                    }
                }
        except Exception as e:
            return {
                "tool": "query_acl_blacklist",
                "success": False,
                "error": str(e),
                "data": {"total": 0, "blacklist": []}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·1.6: æŸ¥è¯¢æ‰€æœ‰ç™½åå•IP ==========
    def _tool_query_acl_whitelist(self) -> Dict[str, Any]:
        """æŸ¥è¯¢æ‰€æœ‰ç™½åå•IPï¼ˆå®Œæ•´åˆ—è¡¨ï¼‰"""
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                sql = "SELECT ip, created_at FROM acl_entries WHERE list_type='white' ORDER BY created_at DESC"
                cur.execute(sql)
                results = cur.fetchall()
                
                whitelist = []
                for row in results:
                    whitelist.append({
                        "ip": row[0],
                        "added_at": row[1].strftime('%Y-%m-%d %H:%M:%S') if row[1] else None
                    })
                
                return {
                    "tool": "query_acl_whitelist",
                    "success": True,
                    "data": {
                        "total": len(whitelist),
                        "whitelist": whitelist
                    }
                }
        except Exception as e:
            return {
                "tool": "query_acl_whitelist",
                "success": False,
                "error": str(e),
                "data": {"total": 0, "whitelist": []}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·2: æŸ¥è¯¢é™é€Ÿå†å² ==========
    def _tool_query_rate_limit_history(self, ip: str = None, reason: str = None, days: int = 7) -> Dict[str, Any]:
        """
        æŸ¥è¯¢é™é€Ÿå†å²
        å¯æŒ‰IPæŸ¥è¯¢ï¼Œä¹Ÿå¯æŒ‰é™é€ŸåŸå› æŸ¥è¯¢ï¼Œæˆ–ä¸¤è€…ç»“åˆ
        ã€æ–°å¢ã€‘days=-1è¡¨ç¤ºä¸é™åˆ¶æ—¶é—´èŒƒå›´ï¼ŒæŸ¥è¯¢æ‰€æœ‰å†å²è®°å½•
        """
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                # ã€ä¿®å¤ã€‘æ”¯æŒæŒ‰IPæˆ–æŒ‰é™é€ŸåŸå› æŸ¥è¯¢
                
                # 1. æŸ¥è¯¢å½“å‰é™é€Ÿï¼ˆå¦‚æœæŒ‡å®šäº†IPï¼‰
                current_limits = []
                if ip and ip != "*":
                    sql = """SELECT src_ip, kbps, reason, expire_at, created_at 
                             FROM rate_limit_active 
                             WHERE src_ip=%s AND expire_at > NOW()"""
                    cur.execute(sql, (ip,))
                    current_limits = cur.fetchall()
                elif reason:
                    # å¦‚æœæŒ‰åŸå› æŸ¥è¯¢ï¼Œè·å–æ‰€æœ‰å› ä¸ºè¿™ä¸ªåŸå› è¢«é™é€Ÿçš„IP
                    sql = """SELECT src_ip, kbps, reason, expire_at, created_at 
                             FROM rate_limit_active 
                             WHERE reason LIKE %s AND expire_at > NOW()"""
                    cur.execute(sql, (f"%{reason}%",))
                    current_limits = cur.fetchall()
                else:
                    # è·å–æ‰€æœ‰å½“å‰é™é€Ÿçš„IP
                    sql = """SELECT src_ip, kbps, reason, expire_at, created_at 
                             FROM rate_limit_active 
                             WHERE expire_at > NOW()"""
                    cur.execute(sql)
                    current_limits = cur.fetchall()
                
                # 2. æŸ¥è¯¢å†å²é™é€Ÿï¼ˆlimit_sessionsè¡¨å­—æ®µï¼šid, src_ip, reason, start_time, kbpsï¼‰
                # ã€æ–°å¢ã€‘å¦‚æœdays=-1ï¼Œåˆ™ä¸é™åˆ¶æ—¶é—´èŒƒå›´ï¼ŒæŸ¥è¯¢æ‰€æœ‰å†å²è®°å½•
                if days == -1:
                    sql = """SELECT src_ip, reason, start_time, kbps 
                             FROM limit_sessions"""
                    params = []
                else:
                    sql = """SELECT src_ip, reason, start_time, kbps 
                             FROM limit_sessions 
                             WHERE start_time >= DATE_SUB(NOW(), INTERVAL %s DAY)"""
                    params = [days]
                
                # å¦‚æœæŒ‡å®šäº†IPï¼Œæ·»åŠ IPè¿‡æ»¤æ¡ä»¶
                if ip and ip != "*":
                    sql += " AND src_ip=%s"
                    params.append(ip)
                
                # å¦‚æœæŒ‡å®šäº†é™é€ŸåŸå› ï¼Œæ·»åŠ åŸå› è¿‡æ»¤æ¡ä»¶
                if reason:
                    sql += " AND reason LIKE %s"
                    params.append(f"%{reason}%")
                
                sql += " ORDER BY start_time DESC"
                
                cur.execute(sql, params)
                history = cur.fetchall()
                
                return {
                    "tool": "query_rate_limit_history",
                    "success": True,
                    "data": {
                        "ip": ip if ip and ip != "*" else "all",
                        "reason": reason if reason else "all",
                        "current_limits": {
                            "count": len(current_limits),
                            "limits": [
                                {
                                    "src_ip": c[0],
                                    "kbps": c[1],
                                    "reason": c[2],
                                    "expire_at": c[3].strftime('%Y-%m-%d %H:%M:%S') if hasattr(c[3], 'strftime') else str(c[3]),
                                    "created_at": c[4].strftime('%Y-%m-%d %H:%M:%S') if hasattr(c[4], 'strftime') else str(c[4])
                                } for c in current_limits
                            ]
                        },
                        "history": {
                            "count": len(history),
                            "records": [
                                {
                                    "src_ip": h[0],
                                    "reason": h[1],
                                    "start_time": h[2].strftime('%Y-%m-%d %H:%M:%S') if hasattr(h[2], 'strftime') else str(h[2]),
                                    "kbps": h[3]
                                } for h in history
                            ]
                        }
                    }
                }
        except Exception as e:
            return {
                "tool": "query_rate_limit_history",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·3: æŸ¥è¯¢æ”»å‡»å†å² ==========
    def _tool_query_attack_history(self, ip: str = None, attack_type: str = None, days: int = 7) -> Dict[str, Any]:
        """
        æŸ¥è¯¢æ”»å‡»å†å²
        å¯æŒ‰IPæŸ¥è¯¢ï¼Œä¹Ÿå¯æŒ‰æ”»å‡»ç±»å‹æŸ¥è¯¢ï¼Œæˆ–ä¸¤è€…ç»“åˆ
        ã€æ–°å¢ã€‘days=-1è¡¨ç¤ºä¸é™åˆ¶æ—¶é—´èŒƒå›´ï¼ŒæŸ¥è¯¢æ‰€æœ‰å†å²è®°å½•
        """
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                # ã€ä¿®å¤ã€‘æ”¯æŒæŒ‰IPæˆ–æŒ‰æ”»å‡»ç±»å‹æŸ¥è¯¢
                # ã€æ–°å¢ã€‘å¦‚æœdays=-1ï¼Œåˆ™ä¸é™åˆ¶æ—¶é—´èŒƒå›´
                if days == -1:
                    sql = """SELECT src_ip, anomaly_type, packet_count, start_time, end_time, 
                                    status, handle_action
                             FROM attack_sessions"""
                    params = []
                else:
                    sql = """SELECT src_ip, anomaly_type, packet_count, start_time, end_time, 
                                    status, handle_action
                             FROM attack_sessions 
                             WHERE start_time >= DATE_SUB(NOW(), INTERVAL %s DAY)"""
                    params = [days]
                
                # å¦‚æœæŒ‡å®šäº†IPï¼Œæ·»åŠ IPè¿‡æ»¤æ¡ä»¶
                if ip and ip != "*":
                    sql += " AND src_ip=%s"
                    params.append(ip)
                
                # å¦‚æœæŒ‡å®šäº†æ”»å‡»ç±»å‹ï¼Œæ·»åŠ æ”»å‡»ç±»å‹è¿‡æ»¤æ¡ä»¶
                if attack_type:
                    sql += " AND anomaly_type=%s"
                    params.append(attack_type)
                
                sql += " ORDER BY start_time DESC"
                
                cur.execute(sql, params)
                results = cur.fetchall()
                
                return {
                    "tool": "query_attack_history",
                    "success": True,
                    "data": {
                        "ip": ip if ip and ip != "*" else "all",
                        "attack_type": attack_type if attack_type else "all",
                        "total_attacks": len(results),
                        "attacks": [
                            {
                                "src_ip": r[0],
                                "type": r[1],
                                "packets": r[2],
                                "start_time": r[3].strftime('%Y-%m-%d %H:%M:%S') if hasattr(r[3], 'strftime') else str(r[3]),
                                "end_time": r[4].strftime('%Y-%m-%d %H:%M:%S') if r[4] and hasattr(r[4], 'strftime') else str(r[4]) if r[4] else None,
                                "status": r[5],
                                "action": r[6]
                            } for r in results
                        ]
                    }
                }
        except Exception as e:
            return {
                "tool": "query_attack_history",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·4: æŸ¥è¯¢æµé‡ç»Ÿè®¡ ==========
    def _tool_query_flow_stats(self, ip: str, time_range_minutes: int = 60) -> Dict[str, Any]:
        """æŸ¥è¯¢IPçš„æµé‡ç»Ÿè®¡"""
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                # æŸ¥è¯¢è¯¥IPçš„æ€»æ•°æ®åŒ…æ•°
                sql = """SELECT SUM(packet_count) as total_packets
                         FROM flow_stats 
                         WHERE src_ip=%s"""
                cur.execute(sql, (ip,))
                result = cur.fetchone()
                total_packets = result[0] if result and result[0] else 0
                
                # æŸ¥è¯¢è¯¥IPçš„å¼‚å¸¸æ•°æ®åŒ…æ•°
                sql = """SELECT COUNT(*) as anomaly_count
                         FROM anomaly_log 
                         WHERE src_ip=%s"""
                cur.execute(sql, (ip,))
                result = cur.fetchone()
                anomaly_packets = result[0] if result and result[0] else 0
                
                return {
                    "tool": "query_flow_stats",
                    "success": True,
                    "data": {
                        "ip": ip,
                        "total_packets": total_packets,
                        "anomaly_packets": anomaly_packets,
                        "normal_packets": total_packets - anomaly_packets,
                        "anomaly_rate": round(anomaly_packets / total_packets * 100, 2) if total_packets > 0 else 0
                    }
                }
        except Exception as e:
            return {
                "tool": "query_flow_stats",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·5: æŸ¥è¯¢è®¾å¤‡å¼‚å¸¸ ==========
    def _tool_query_device_anomalies(self, device_type: str = None, anomaly_type: str = None, severity: str = None, days: int = 7) -> Dict[str, Any]:
        """
        æŸ¥è¯¢è®¾å¤‡å¼‚å¸¸
        å¯æŒ‰è®¾å¤‡ç±»å‹ã€å¼‚å¸¸ç±»å‹ã€ä¸¥é‡ç¨‹åº¦æŸ¥è¯¢ï¼Œæˆ–å¤šæ¡ä»¶ç»„åˆ
        ã€æ–°å¢ã€‘days=-1è¡¨ç¤ºä¸é™åˆ¶æ—¶é—´èŒƒå›´ï¼ŒæŸ¥è¯¢æ‰€æœ‰å†å²è®°å½•
        """
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                # ã€æ–°å¢ã€‘æ”¯æŒå¤šæ¡ä»¶æŸ¥è¯¢è®¾å¤‡å¼‚å¸¸
                # ã€æ–°å¢ã€‘å¦‚æœdays=-1ï¼Œåˆ™ä¸é™åˆ¶æ—¶é—´èŒƒå›´
                if days == -1:
                    sql = """SELECT id, anomaly_type, device_type, device_id, description, severity, 
                                    detected_at, resolved_at, status, handled_by, handled_at, handle_action
                             FROM device_anomalies"""
                    params = []
                else:
                    sql = """SELECT id, anomaly_type, device_type, device_id, description, severity, 
                                    detected_at, resolved_at, status, handled_by, handled_at, handle_action
                             FROM device_anomalies 
                             WHERE detected_at >= DATE_SUB(NOW(), INTERVAL %s DAY)"""
                    params = [days]
                
                # å¦‚æœæŒ‡å®šäº†è®¾å¤‡ç±»å‹ï¼Œæ·»åŠ è¿‡æ»¤æ¡ä»¶
                if device_type:
                    sql += " AND device_type=%s"
                    params.append(device_type)
                
                # å¦‚æœæŒ‡å®šäº†å¼‚å¸¸ç±»å‹ï¼Œæ·»åŠ è¿‡æ»¤æ¡ä»¶
                if anomaly_type:
                    sql += " AND anomaly_type LIKE %s"
                    params.append(f"%{anomaly_type}%")
                
                # å¦‚æœæŒ‡å®šäº†ä¸¥é‡ç¨‹åº¦ï¼Œæ·»åŠ è¿‡æ»¤æ¡ä»¶
                if severity:
                    sql += " AND severity=%s"
                    params.append(severity)
                
                sql += " ORDER BY detected_at DESC"
                
                cur.execute(sql, params)
                results = cur.fetchall()
                
                return {
                    "tool": "query_device_anomalies",
                    "success": True,
                    "data": {
                        "device_type": device_type if device_type else "all",
                        "anomaly_type": anomaly_type if anomaly_type else "all",
                        "severity": severity if severity else "all",
                        "total_anomalies": len(results),
                        "anomalies": [
                            {
                                "id": r[0],
                                "anomaly_type": r[1],
                                "device_type": r[2],
                                "device_id": r[3],
                                "description": r[4],
                                "severity": r[5],
                                "detected_at": r[6].strftime('%Y-%m-%d %H:%M:%S') if hasattr(r[6], 'strftime') else str(r[6]),
                                "resolved_at": r[7].strftime('%Y-%m-%d %H:%M:%S') if r[7] and hasattr(r[7], 'strftime') else str(r[7]) if r[7] else None,
                                "status": r[8],
                                "handled_by": r[9],
                                "handled_at": r[10].strftime('%Y-%m-%d %H:%M:%S') if r[10] and hasattr(r[10], 'strftime') else str(r[10]) if r[10] else None,
                                "handle_action": r[11]
                            } for r in results
                        ]
                    }
                }
        except Exception as e:
            return {
                "tool": "query_device_anomalies",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·6: è·å–é˜²å¾¡è§„åˆ™ ==========
    def _tool_get_defense_rules(self, attack_type: Optional[str] = None) -> Dict[str, Any]:
        """è·å–é˜²å¾¡è§„åˆ™"""
        try:
            # é¦–å…ˆå°è¯•ä»RAGçŸ¥è¯†åº“è·å–é˜²å¾¡è§„åˆ™
            if attack_type:
                query = f"{attack_type}æ”»å‡»çš„æ£€æµ‹é˜ˆå€¼å’Œé˜²å¾¡æªæ–½"
            else:
                query = "ç½‘ç»œå®‰å…¨é˜²å¾¡è§„åˆ™å’Œæ”»å‡»æ£€æµ‹é˜ˆå€¼"
            
            knowledge_result = self._tool_search_knowledge(query)
            
            # å¦‚æœRAGæ£€ç´¢æˆåŠŸï¼Œè¿”å›ç»“æœ
            if knowledge_result['success'] and knowledge_result['data']:
                return {
                    "tool": "get_defense_rules",
                    "success": True,
                    "data": {
                        "attack_type": attack_type,
                        "rules": knowledge_result['data'],
                        "count": knowledge_result['count'],
                        "source": "rag"
                    }
                }
            
            # å¦‚æœRAGæ£€ç´¢å¤±è´¥æˆ–ä¸ºç©ºï¼Œè¿”å›ç¡¬ç¼–ç çš„é˜²å¾¡è§„åˆ™ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
            default_rules = {
                "DDoS": {
                    "detection_threshold": "æµé‡çªå¢è¶…è¿‡200pps",
                    "defense_measures": ["é™é€Ÿ", "é»‘åå•", "æµé‡æ¸…æ´—"],
                    "priority": "é«˜"
                },
                "SYN Flood": {
                    "detection_threshold": "SYNåŒ…å æ¯”>80%ï¼Œé€Ÿç‡>200pps",
                    "defense_measures": ["é™é€Ÿ", "é»‘åå•", "SYNä»£ç†"],
                    "priority": "é«˜"
                },
                "UDP Flood": {
                    "detection_threshold": "UDPåŒ…æ•°>200pps",
                    "defense_measures": ["é™é€Ÿ", "é»‘åå•", "UDPè¿‡æ»¤"],
                    "priority": "é«˜"
                },
                "ARP Spoofing": {
                    "detection_threshold": "MACåœ°å€å˜åŒ–",
                    "defense_measures": ["ARPé˜²æŠ¤", "é»‘åå•"],
                    "priority": "ä¸­"
                },
                "Port Scan": {
                    "detection_threshold": "å•IPæ‰«æç«¯å£æ•°>10",
                    "defense_measures": ["é™é€Ÿ", "é»‘åå•"],
                    "priority": "ä¸­"
                }
            }
            
            if attack_type and attack_type in default_rules:
                rules = [default_rules[attack_type]]
            else:
                rules = list(default_rules.values())
            
            return {
                "tool": "get_defense_rules",
                "success": True,
                "data": {
                    "attack_type": attack_type,
                    "rules": rules,
                    "count": len(rules),
                    "source": "default"
                }
            }
            
        except Exception as e:
            print(f"âš ï¸ è·å–é˜²å¾¡è§„åˆ™å¤±è´¥: {e}")
            return {
                "tool": "get_defense_rules",
                "success": False,
                "error": str(e),
                "data": {}
            }

    # ========== MCPå·¥å…·6: æŸ¥è¯¢ç½‘ç»œæ‹“æ‰‘ ==========
    def _tool_query_network_topology(self) -> Dict[str, Any]:
        """æŸ¥è¯¢ç½‘ç»œæ‹“æ‰‘"""
        try:
            # ä»RAGçŸ¥è¯†åº“è·å–æ‹“æ‰‘ä¿¡æ¯
            query = "ç½‘ç»œæ‹“æ‰‘ç»“æ„äº¤æ¢æœºä¸»æœºé…ç½®IPåœ°å€h1 h2 h3 h4 h5 h6 h7 h8"
            knowledge_result = self._tool_search_knowledge(query)
            
            print(f"[DEBUG] RAGæ‹“æ‰‘æŸ¥è¯¢ç»“æœ: {knowledge_result}")
            
            # ç¡®ä¿çŸ¥è¯†åº“æ•°æ®è¢«æ­£ç¡®è¿”å›
            topology_info = knowledge_result.get('data', [])
            if not topology_info:
                print(f"âš ï¸ RAGçŸ¥è¯†åº“è¿”å›ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼")
                topology_info = []
            
            # ç¡¬ç¼–ç çš„ä¸»æœºé…ç½®ï¼ˆä»çŸ¥è¯†åº“æ–‡ä»¶ä¸­æå–ï¼‰
            host_config = """## ä¸»æœºé…ç½®
æ‰€æœ‰ä¸»æœºå‡åœ¨ 192.168.1.0/24 å­ç½‘ï¼š
1. h1: IP=192.168.1.100/24, MAC=00:00:00:00:00:01
2. h2: IP=192.168.1.101/24, MAC=00:00:00:00:00:02
3. h3: IP=192.168.1.102/24, MAC=00:00:00:00:00:03
4. h4: IP=192.168.1.103/24, MAC=00:00:00:00:00:04
5. h5: IP=192.168.1.104/24, MAC=00:00:00:00:00:05
6. h6: IP=192.168.1.105/24, MAC=00:00:00:00:00:06
7. h7: IP=192.168.1.200/24, MAC=00:00:00:00:00:07
8. h8: IP=192.168.1.108/24, MAC=00:00:00:00:00:08"""
            
            # åˆå¹¶RAGç»“æœå’Œç¡¬ç¼–ç é…ç½®
            combined_info = host_config
            if topology_info:
                combined_info += "\n\nã€RAGçŸ¥è¯†åº“è¡¥å……ä¿¡æ¯ã€‘\n" + "\n".join(topology_info)
            
            return {
                "tool": "query_network_topology",
                "success": True,
                "data": {
                    "topology_type": "star",
                    "switches": ["s1"],
                    "hosts": ["h1", "h2", "h3", "h4", "h5", "h6", "h7", "h8"],
                    "ip_subnet": "192.168.1.0/24",
                    "total_hosts": 8,
                    "qos_levels": [256, 1024, 2048],
                    "host_mapping": {
                        "h1": "192.168.1.100",
                        "h2": "192.168.1.101",
                        "h3": "192.168.1.102",
                        "h4": "192.168.1.103",
                        "h5": "192.168.1.104",
                        "h6": "192.168.1.105",
                        "h7": "192.168.1.200",
                        "h8": "192.168.1.108"
                    },
                    "topology_info": combined_info,
                    "knowledge_success": knowledge_result.get('success', False)
                }
            }
        except Exception as e:
            print(f"[ERROR] æ‹“æ‰‘æŸ¥è¯¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                "tool": "query_network_topology",
                "success": False,
                "error": str(e),
                "data": {}
            }

    # ========== MCPå·¥å…·7: è·å–ç³»ç»Ÿå½“å‰çŠ¶æ€ ==========
    def _tool_get_current_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿå½“å‰çŠ¶æ€"""
        try:
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                # æŸ¥è¯¢é™é€ŸIPæ•°é‡
                sql = "SELECT COUNT(*) FROM rate_limit_active WHERE expire_at > NOW()"
                cur.execute(sql)
                limited_count = cur.fetchone()[0]
                
                # æŸ¥è¯¢é»‘åå•IPæ•°é‡
                sql = "SELECT COUNT(*) FROM acl_entries WHERE list_type='black'"
                cur.execute(sql)
                blacklist_count = cur.fetchone()[0]
                
                # æŸ¥è¯¢ç™½åå•IPæ•°é‡
                sql = "SELECT COUNT(*) FROM acl_entries WHERE list_type='white'"
                cur.execute(sql)
                whitelist_count = cur.fetchone()[0]
                
                # æŸ¥è¯¢æœ€è¿‘çš„æ”»å‡»äº‹ä»¶
                sql = """SELECT src_ip, anomaly_type, start_time, status
                         FROM attack_sessions 
                         ORDER BY start_time DESC LIMIT 5"""
                cur.execute(sql)
                recent_attacks = cur.fetchall()
                
                # æŸ¥è¯¢è®¾å¤‡å¼‚å¸¸æ•°é‡
                sql = "SELECT COUNT(*) FROM device_anomalies WHERE status='pending'"
                cur.execute(sql)
                device_anomalies_count = cur.fetchone()[0]
                
                return {
                    "tool": "get_current_status",
                    "success": True,
                    "data": {
                        "total_hosts": 8,
                        "limited_ips_count": limited_count,
                        "blacklist_count": blacklist_count,
                        "whitelist_count": whitelist_count,
                        "device_anomalies_count": device_anomalies_count,
                        "recent_attacks": [
                            {
                                "ip": r[0],
                                "type": r[1],
                                "time": r[2].strftime('%Y-%m-%d %H:%M:%S') if hasattr(r[2], 'strftime') else str(r[2]),
                                "status": r[3]
                            } for r in recent_attacks
                        ],
                        "system_status": "normal" if limited_count < 3 else "warning" if limited_count < 6 else "critical"
                    }
                }
        except Exception as e:
            return {
                "tool": "get_current_status",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·8: åº”ç”¨é™é€Ÿï¼ˆæ‰§è¡Œå·¥å…·ï¼‰==========
    def _tool_apply_rate_limit(self, ip: str, level: str, duration_seconds: int, reason: str) -> Dict[str, Any]:
        """åº”ç”¨é™é€Ÿè§„åˆ™
        
        ã€å…³é”®è®¾è®¡ã€‘ï¼šMCPå·¥å…·åªè´Ÿè´£è°ƒç”¨RYU APIï¼Œä¸ç›´æ¥æ“ä½œæ•°æ®åº“
        æ‰€æœ‰æ“ä½œï¼ˆæµè¡¨ä¸‹å‘ã€å†…å­˜æ›´æ–°ã€æ•°æ®åº“å†™å…¥ï¼‰éƒ½ç”±RYUæ§åˆ¶å™¨ç»Ÿä¸€å¤„ç†
        è¿™æ ·ä¿è¯æ•°æ®ä¸€è‡´æ€§å’Œæµè¡¨æœ‰æ•ˆæ€§
        
        ã€é‡è¦ã€‘ï¼šMCPå·¥å…·æ˜¯ç®¡ç†å‘˜è°ƒç”¨çš„ï¼Œæ‰€ä»¥operator='admin'
        è¿™æ ·RYUä¼šï¼š
        1. å†™å…¥rate_limit_logï¼ˆoperator='admin'ï¼‰
        2. å†™å…¥attack_sessionsï¼ˆstatus='handled'ï¼‰
        3. å†™å…¥limit_sessionsï¼ˆåˆ†é’Ÿåˆå¹¶ï¼‰
        """
        try:
            import requests
            
            # å¦‚æœæ²¡æœ‰æä¾›reasonï¼Œé»˜è®¤ä¸º"å‰ç«¯æ‰‹åŠ¨é™é€Ÿ"
            if not reason or reason.strip() == "":
                reason = "å‰ç«¯æ‰‹åŠ¨é™é€Ÿ"
            
            # æ˜ å°„é™é€Ÿæ¡£ä½
            level_map = {"low": 256, "medium": 1024, "high": 2048}
            kbps = level_map.get(level, 1024)
            
            # ã€å”¯ä¸€æ“ä½œã€‘ï¼šè°ƒç”¨RYUæ§åˆ¶å™¨çš„/v1/rate/applyæ¥å£
            # RYUä¼šè´Ÿè´£ï¼š
            # 1. ä¸‹å‘æµè¡¨åˆ°OVS
            # 2. æ›´æ–°å†…å­˜å­—å…¸ self.limited_ips
            # 3. å†™å…¥æ•°æ®åº“ rate_limit_active
            # 4. å†™å…¥rate_limit_logï¼ˆoperator='admin'ï¼‰
            # 5. å†™å…¥attack_sessionsï¼ˆstatus='handled'ï¼‰
            # 6. å†™å…¥limit_sessionsï¼ˆåˆ†é’Ÿåˆå¹¶ï¼‰
            RYU_BASE = "http://192.168.44.129:8080/v1"
            ryu_data = {
                "ip": ip,
                "kbps": kbps,
                "duration": duration_seconds,
                "reason": reason,
                "operator": "admin"  # âœ… æ”¹ä¸ºadminï¼Œè¡¨ç¤ºè¿™æ˜¯ç®¡ç†å‘˜æ“ä½œ
            }
            print(f"[DEBUG] MCPå·¥å…·è°ƒç”¨RYU API: POST {RYU_BASE}/rate/apply")
            print(f"[DEBUG] è¯·æ±‚æ•°æ®: {ryu_data}")
            
            try:
                ryu_response = requests.post(f"{RYU_BASE}/rate/apply", json=ryu_data, timeout=10)
                ryu_response.raise_for_status()
                ryu_result = ryu_response.json()
                print(f"[DEBUG] RYU APIå“åº”: {ryu_result}")
                
                # æ£€æŸ¥RYUæ˜¯å¦æˆåŠŸ
                if ryu_result.get('success'):
                    print(f"[SUCCESS] RYUæˆåŠŸå¤„ç†é™é€Ÿè¯·æ±‚")
                    return {
                        "tool": "apply_rate_limit",
                        "success": True,
                        "data": {
                            "ip": ip,
                            "level": level,
                            "kbps": kbps,
                            "duration_seconds": duration_seconds,
                            "reason": reason,
                            "message": f"âœ… å·²å¯¹{ip}åº”ç”¨{level}é™é€Ÿï¼ˆ{kbps}Kbpsï¼‰ï¼ŒæŒç»­{duration_seconds}ç§’"
                        }
                    }
                else:
                    # RYUè¿”å›å¤±è´¥
                    error_msg = ryu_result.get('message', 'æœªçŸ¥é”™è¯¯')
                    print(f"[ERROR] RYUè¿”å›å¤±è´¥: {error_msg}")
                    return {
                        "tool": "apply_rate_limit",
                        "success": False,
                        "error": f"RYUæ§åˆ¶å™¨è¿”å›å¤±è´¥: {error_msg}",
                        "data": {}
                    }
            except requests.exceptions.RequestException as req_error:
                print(f"[ERROR] è¯·æ±‚RYU APIå¤±è´¥: {req_error}")
                return {
                    "tool": "apply_rate_limit",
                    "success": False,
                    "error": f"æ— æ³•è¿æ¥RYUæ§åˆ¶å™¨: {str(req_error)}",
                    "data": {}
                }
        except Exception as e:
            print(f"[ERROR] MCPå·¥å…·å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return {
                "tool": "apply_rate_limit",
                "success": False,
                "error": str(e),
                "data": {}
            }

    # ========== MCPå·¥å…·9: åŠ å…¥é»‘åå•ï¼ˆæ‰§è¡Œå·¥å…·ï¼‰==========
    def _tool_add_to_blacklist(self, ip: str, reason: str) -> Dict[str, Any]:
        """å°†IPåŠ å…¥é»‘åå•"""
        try:
            import requests
            
            # ã€å…³é”®ã€‘ç¬¬1æ­¥ï¼šå…ˆè°ƒç”¨RYUæ§åˆ¶å™¨ä¸‹å‘ACLè§„åˆ™
            RYU_BASE = "http://192.168.44.129:8080/v1"
            ryu_data = {"ip": ip, "ttl": -1}
            print(f"[DEBUG] è°ƒç”¨RYUæ§åˆ¶å™¨åŠ å…¥é»‘åå•: {ryu_data}")
            ryu_success = False
            try:
                ryu_response = requests.post(f"{RYU_BASE}/acl/black", json=ryu_data, timeout=10)
                ryu_response.raise_for_status()
                ryu_result = ryu_response.json()
                print(f"[DEBUG] RYUæ§åˆ¶å™¨åŠ å…¥é»‘åå•å“åº”: {ryu_result}")
                ryu_success = ryu_result.get('success', False)
            except Exception as ryu_error:
                print(f"[ERROR] RYUæ§åˆ¶å™¨åŠ å…¥é»‘åå•å¤±è´¥: {ryu_error}")
                return {
                    "tool": "add_to_blacklist",
                    "success": False,
                    "error": f"RYUæ§åˆ¶å™¨åŠ å…¥é»‘åå•å¤±è´¥: {ryu_error}",
                    "data": {}
                }
            
            # ã€å…³é”®ä¿®å¤ã€‘åªæœ‰RYUæˆåŠŸæ‰ç»§ç»­å†™å…¥æ•°æ®åº“
            if ryu_success:
                # ç¬¬2æ­¥ï¼šå†™å…¥MySQLæ•°æ®åº“
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    sql = """INSERT INTO acl_entries (ip, list_type, created_at)
                             VALUES (%s, 'black', NOW())
                             ON DUPLICATE KEY UPDATE updated_at = NOW()"""
                    cur.execute(sql, (ip,))
                    conn.commit()
                    
                    return {
                        "tool": "add_to_blacklist",
                        "success": True,
                        "data": {
                            "ip": ip,
                            "reason": reason,
                            "message": f"å·²å°†{ip}åŠ å…¥é»‘åå•ï¼ŒåŸå› ï¼š{reason}ï¼ŒACLè§„åˆ™å·²ä¸‹å‘"
                        }
                    }
            else:
                return {
                    "tool": "add_to_blacklist",
                    "success": False,
                    "error": f"RYUæ§åˆ¶å™¨è¿”å›å¤±è´¥",
                    "data": {}
                }
        except Exception as e:
            print(f"[ERROR] åŠ å…¥é»‘åå•å¤±è´¥: {e}")
            return {
                "tool": "add_to_blacklist",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·10: åŠ å…¥ç™½åå•ï¼ˆæ‰§è¡Œå·¥å…·ï¼‰==========
    def _tool_add_to_whitelist(self, ip: str, reason: str) -> Dict[str, Any]:
        """å°†IPåŠ å…¥ç™½åå•"""
        try:
            import requests
            
            # ã€å…³é”®ã€‘ç¬¬1æ­¥ï¼šå…ˆè°ƒç”¨RYUæ§åˆ¶å™¨ä¸‹å‘ACLè§„åˆ™
            RYU_BASE = "http://192.168.44.129:8080/v1"
            ryu_data = {"ip": ip, "ttl": -1}
            print(f"[DEBUG] è°ƒç”¨RYUæ§åˆ¶å™¨åŠ å…¥ç™½åå•: {ryu_data}")
            ryu_success = False
            try:
                ryu_response = requests.post(f"{RYU_BASE}/acl/white", json=ryu_data, timeout=10)
                ryu_response.raise_for_status()
                ryu_result = ryu_response.json()
                print(f"[DEBUG] RYUæ§åˆ¶å™¨åŠ å…¥ç™½åå•å“åº”: {ryu_result}")
                ryu_success = ryu_result.get('success', False)
            except Exception as ryu_error:
                print(f"[ERROR] RYUæ§åˆ¶å™¨åŠ å…¥ç™½åå•å¤±è´¥: {ryu_error}")
                return {
                    "tool": "add_to_whitelist",
                    "success": False,
                    "error": f"RYUæ§åˆ¶å™¨åŠ å…¥ç™½åå•å¤±è´¥: {ryu_error}",
                    "data": {}
                }
            
            # ã€å…³é”®ä¿®å¤ã€‘åªæœ‰RYUæˆåŠŸæ‰ç»§ç»­å†™å…¥æ•°æ®åº“
            if ryu_success:
                # ç¬¬2æ­¥ï¼šå†™å…¥MySQLæ•°æ®åº“
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    sql = """INSERT INTO acl_entries (ip, list_type, created_at)
                             VALUES (%s, 'white', NOW())
                             ON DUPLICATE KEY UPDATE updated_at = NOW()"""
                    cur.execute(sql, (ip,))
                    conn.commit()
                    
                    return {
                        "tool": "add_to_whitelist",
                        "success": True,
                        "data": {
                            "ip": ip,
                            "reason": reason,
                            "message": f"å·²å°†{ip}åŠ å…¥ç™½åå•ï¼ŒåŸå› ï¼š{reason}ï¼ŒACLè§„åˆ™å·²ä¸‹å‘"
                        }
                    }
            else:
                return {
                    "tool": "add_to_whitelist",
                    "success": False,
                    "error": f"RYUæ§åˆ¶å™¨è¿”å›å¤±è´¥",
                    "data": {}
                }
        except Exception as e:
            print(f"[ERROR] åŠ å…¥ç™½åå•å¤±è´¥: {e}")
            return {
                "tool": "add_to_whitelist",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·11: ä»é»‘åå•åˆ é™¤IPï¼ˆæ‰§è¡Œå·¥å…·ï¼‰==========
    def _tool_remove_from_blacklist(self, ip: str, reason: str = "ç®¡ç†å‘˜è§£é™¤") -> Dict[str, Any]:
        """ä»é»‘åå•åˆ é™¤IP"""
        try:
            import requests
            
            # ã€å…³é”®ã€‘ç¬¬1æ­¥ï¼šå…ˆè°ƒç”¨RYUæ§åˆ¶å™¨åˆ é™¤ACLè§„åˆ™
            RYU_BASE = "http://192.168.44.129:8080/v1"
            print(f"[DEBUG] è°ƒç”¨RYUæ§åˆ¶å™¨ä»é»‘åå•åˆ é™¤: {ip}")
            ryu_success = False
            try:
                ryu_response = requests.delete(f"{RYU_BASE}/acl/black/{ip}", timeout=10)
                ryu_response.raise_for_status()
                ryu_result = ryu_response.json()
                print(f"[DEBUG] RYUæ§åˆ¶å™¨åˆ é™¤é»‘åå•å“åº”: {ryu_result}")
                ryu_success = ryu_result.get('success', False)
            except Exception as ryu_error:
                print(f"[ERROR] RYUæ§åˆ¶å™¨åˆ é™¤é»‘åå•å¤±è´¥: {ryu_error}")
                return {
                    "tool": "remove_from_blacklist",
                    "success": False,
                    "error": f"RYUæ§åˆ¶å™¨åˆ é™¤é»‘åå•å¤±è´¥: {ryu_error}",
                    "data": {}
                }
            
            # ã€å…³é”®ä¿®å¤ã€‘å¦‚æœRYUæˆåŠŸï¼Œå°±è¿”å›æˆåŠŸï¼Œä¸ç®¡æ•°æ®åº“æ˜¯å¦æœ‰è®°å½•
            if ryu_success:
                # ç¬¬2æ­¥ï¼šå°è¯•ä»æ•°æ®åº“ä¸­åˆ é™¤ï¼ˆä½†ä¸å½±å“æœ€ç»ˆç»“æœï¼‰
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    sql = "DELETE FROM acl_entries WHERE ip=%s AND list_type='black'"
                    affected = cur.execute(sql, (ip,))
                    conn.commit()
                    print(f"[DEBUG] æ•°æ®åº“DELETEå½±å“è¡Œæ•°: {affected}")
                
                # ã€å…³é”®ã€‘ï¼šRYUæˆåŠŸäº†ï¼Œå°±è¿”å›æˆåŠŸï¼Œå³ä½¿æ•°æ®åº“æ²¡æœ‰è®°å½•
                return {
                    "tool": "remove_from_blacklist",
                    "success": True,
                    "data": {
                        "ip": ip,
                        "reason": reason,
                        "message": f"å·²å°†{ip}ä»é»‘åå•ä¸­åˆ é™¤ï¼ŒåŸå› ï¼š{reason}ï¼ŒACLè§„åˆ™å·²åˆ é™¤"
                    }
                }
            else:
                return {
                    "tool": "remove_from_blacklist",
                    "success": False,
                    "error": f"RYUæ§åˆ¶å™¨è¿”å›å¤±è´¥",
                    "data": {}
                }
        except Exception as e:
            print(f"[ERROR] ä»é»‘åå•åˆ é™¤å¤±è´¥: {e}")
            return {
                "tool": "remove_from_blacklist",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·12: ä»ç™½åå•åˆ é™¤IPï¼ˆæ‰§è¡Œå·¥å…·ï¼‰==========
    def _tool_remove_from_whitelist(self, ip: str, reason: str = "ç®¡ç†å‘˜è§£é™¤") -> Dict[str, Any]:
        """ä»ç™½åå•åˆ é™¤IP"""
        try:
            import requests
            
            # ã€å…³é”®ã€‘ç¬¬1æ­¥ï¼šå…ˆè°ƒç”¨RYUæ§åˆ¶å™¨åˆ é™¤ACLè§„åˆ™
            RYU_BASE = "http://192.168.44.129:8080/v1"
            print(f"[DEBUG] è°ƒç”¨RYUæ§åˆ¶å™¨ä»ç™½åå•åˆ é™¤: {ip}")
            ryu_success = False
            try:
                ryu_response = requests.delete(f"{RYU_BASE}/acl/white/{ip}", timeout=10)
                ryu_response.raise_for_status()
                ryu_result = ryu_response.json()
                print(f"[DEBUG] RYUæ§åˆ¶å™¨åˆ é™¤ç™½åå•å“åº”: {ryu_result}")
                ryu_success = ryu_result.get('success', False)
            except Exception as ryu_error:
                print(f"[ERROR] RYUæ§åˆ¶å™¨åˆ é™¤ç™½åå•å¤±è´¥: {ryu_error}")
                return {
                    "tool": "remove_from_whitelist",
                    "success": False,
                    "error": f"RYUæ§åˆ¶å™¨åˆ é™¤ç™½åå•å¤±è´¥: {ryu_error}",
                    "data": {}
                }
            
            # ã€å…³é”®ä¿®å¤ã€‘å¦‚æœRYUæˆåŠŸï¼Œå°±è¿”å›æˆåŠŸï¼Œä¸ç®¡æ•°æ®åº“æ˜¯å¦æœ‰è®°å½•
            if ryu_success:
                # ç¬¬2æ­¥ï¼šå°è¯•ä»æ•°æ®åº“ä¸­åˆ é™¤ï¼ˆä½†ä¸å½±å“æœ€ç»ˆç»“æœï¼‰
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    sql = "DELETE FROM acl_entries WHERE ip=%s AND list_type='white'"
                    affected = cur.execute(sql, (ip,))
                    conn.commit()
                    print(f"[DEBUG] æ•°æ®åº“DELETEå½±å“è¡Œæ•°: {affected}")
                
                # ã€å…³é”®ã€‘ï¼šRYUæˆåŠŸäº†ï¼Œå°±è¿”å›æˆåŠŸï¼Œå³ä½¿æ•°æ®åº“æ²¡æœ‰è®°å½•
                return {
                    "tool": "remove_from_whitelist",
                    "success": True,
                    "data": {
                        "ip": ip,
                        "reason": reason,
                        "message": f"å·²å°†{ip}ä»ç™½åå•ä¸­åˆ é™¤ï¼ŒåŸå› ï¼š{reason}ï¼ŒACLè§„åˆ™å·²åˆ é™¤"
                    }
                }
            else:
                return {
                    "tool": "remove_from_whitelist",
                    "success": False,
                    "error": f"RYUæ§åˆ¶å™¨è¿”å›å¤±è´¥",
                    "data": {}
                }
        except Exception as e:
            print(f"[ERROR] ä»ç™½åå•åˆ é™¤å¤±è´¥: {e}")
            return {
                "tool": "remove_from_whitelist",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·13: è§£é™¤é™é€Ÿï¼ˆæ‰§è¡Œå·¥å…·ï¼‰==========
    def _tool_release_rate_limit(self, ip: str, reason: str = "ç®¡ç†å‘˜è§£é™¤") -> Dict[str, Any]:
        """è§£é™¤å¯¹IPçš„é™é€Ÿ"""
        try:
            import requests
            
            # ã€å…³é”®ã€‘ç¬¬1æ­¥ï¼šå…ˆè°ƒç”¨RYUæ§åˆ¶å™¨åˆ é™¤æµè¡¨
            RYU_BASE = "http://192.168.44.129:8080/v1"
            print(f"[DEBUG] è°ƒç”¨RYUæ§åˆ¶å™¨è§£é™¤é™é€Ÿ: {ip}")
            ryu_success = False
            try:
                ryu_response = requests.delete(f"{RYU_BASE}/rate/{ip}", timeout=10)
                ryu_response.raise_for_status()
                ryu_result = ryu_response.json()
                print(f"[DEBUG] RYUæ§åˆ¶å™¨è§£é™¤é™é€Ÿå“åº”: {ryu_result}")
                ryu_success = ryu_result.get('success', False)
            except Exception as ryu_error:
                print(f"[ERROR] RYUæ§åˆ¶å™¨è§£é™¤é™é€Ÿå¤±è´¥: {ryu_error}")
                return {
                    "tool": "release_rate_limit",
                    "success": False,
                    "error": f"RYUæ§åˆ¶å™¨è§£é™¤é™é€Ÿå¤±è´¥: {ryu_error}",
                    "data": {}
                }
            
            # ã€å…³é”®ä¿®å¤ã€‘å¦‚æœRYUæˆåŠŸï¼Œå°±è¿”å›æˆåŠŸï¼Œä¸ç®¡æ•°æ®åº“æ˜¯å¦æœ‰è®°å½•
            if ryu_success:
                # ç¬¬2æ­¥ï¼šå°è¯•ä»æ•°æ®åº“ä¸­åˆ é™¤ï¼ˆä½†ä¸å½±å“æœ€ç»ˆç»“æœï¼‰
                conn = pymysql.connect(**DB_CONFIG)
                with conn.cursor() as cur:
                    sql = "DELETE FROM rate_limit_active WHERE src_ip=%s"
                    affected = cur.execute(sql, (ip,))
                    conn.commit()
                    print(f"[DEBUG] æ•°æ®åº“DELETEå½±å“è¡Œæ•°: {affected}")
                
                # ã€å…³é”®ã€‘ï¼šRYUæˆåŠŸäº†ï¼Œå°±è¿”å›æˆåŠŸï¼Œå³ä½¿æ•°æ®åº“æ²¡æœ‰è®°å½•
                return {
                    "tool": "release_rate_limit",
                    "success": True,
                    "data": {
                        "ip": ip,
                        "reason": reason,
                        "message": f"å·²è§£é™¤å¯¹{ip}çš„é™é€Ÿï¼ŒåŸå› ï¼š{reason}ï¼Œæµè¡¨å·²åˆ é™¤"
                    }
                }
            else:
                return {
                    "tool": "release_rate_limit",
                    "success": False,
                    "error": f"RYUæ§åˆ¶å™¨è¿”å›å¤±è´¥",
                    "data": {}
                }
        except Exception as e:
            print(f"[ERROR] è§£é™¤é™é€Ÿå¤±è´¥: {e}")
            return {
                "tool": "release_rate_limit",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·14: ä¿®æ”¹é™é€Ÿæ—¶é•¿ï¼ˆæ‰§è¡Œå·¥å…·ï¼‰==========
    def _tool_modify_rate_limit_duration(self, ip: str, duration_seconds: int, reason: str = "ä¿®æ”¹é™é€Ÿæ—¶é•¿") -> Dict[str, Any]:
        """ä¿®æ”¹å¯¹IPçš„é™é€Ÿæ—¶é•¿"""
        try:
            import requests
            
            # ã€å…³é”®ã€‘ç¬¬1æ­¥ï¼šå…ˆè°ƒç”¨RYUæ§åˆ¶å™¨æ›´æ–°æµè¡¨è¿‡æœŸæ—¶é—´
            RYU_BASE = "http://192.168.44.129:8080/v1"
            ryu_data = {
                "extra_seconds": duration_seconds  # ã€ä¿®å¤ã€‘RYUæœŸæœ›çš„å‚æ•°åæ˜¯extra_secondsï¼Œä¸æ˜¯duration
            }
            print(f"[DEBUG] è°ƒç”¨RYUæ§åˆ¶å™¨ä¿®æ”¹é™é€Ÿæ—¶é•¿: {ryu_data}")
            try:
                ryu_response = requests.put(f"{RYU_BASE}/rate/duration/{ip}", json=ryu_data, timeout=10)
                ryu_response.raise_for_status()
                ryu_result = ryu_response.json()
                print(f"[DEBUG] RYUæ§åˆ¶å™¨ä¿®æ”¹é™é€Ÿæ—¶é•¿å“åº”: {ryu_result}")
            except Exception as ryu_error:
                print(f"[WARNING] RYUæ§åˆ¶å™¨ä¿®æ”¹é™é€Ÿæ—¶é•¿å¤±è´¥ï¼Œä½†ç»§ç»­æ›´æ–°æ•°æ®åº“: {ryu_error}")
                # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­æµç¨‹
            
            # ã€å…³é”®ã€‘ç¬¬2æ­¥ï¼šæ›´æ–°æ•°æ®åº“
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                # å…ˆæ£€æŸ¥IPæ˜¯å¦å­˜åœ¨
                sql_check = "SELECT 1 FROM rate_limit_active WHERE src_ip=%s"
                cur.execute(sql_check, (ip,))
                existing = cur.fetchone()
                
                if existing:
                    # IPå­˜åœ¨ï¼Œæ‰§è¡ŒUPDATE
                    sql = """UPDATE rate_limit_active 
                             SET expire_at = DATE_ADD(NOW(), INTERVAL %s SECOND)
                             WHERE src_ip=%s"""
                    affected = cur.execute(sql, (duration_seconds, ip))
                    conn.commit()
                    
                    print(f"[DEBUG] æ•°æ®åº“UPDATEå½±å“è¡Œæ•°: {affected}")
                    
                    # ã€å…³é”®ä¿®å¤ã€‘ï¼šå³ä½¿affected=0ï¼Œä¹Ÿåº”è¯¥è¿”å›æˆåŠŸ
                    # å› ä¸ºRYUå·²ç»æˆåŠŸæ›´æ–°äº†æµè¡¨å’Œå†…å­˜
                    return {
                        "tool": "modify_rate_limit_duration",
                        "success": True,
                        "data": {
                            "ip": ip,
                            "duration_seconds": duration_seconds,
                            "reason": reason,
                            "message": f"âœ… å·²ä¿®æ”¹{ip}çš„é™é€Ÿæ—¶é•¿ä¸º{duration_seconds}ç§’ï¼ŒåŸå› ï¼š{reason}ï¼Œæµè¡¨å·²æ›´æ–°"
                        }
                    }
                else:
                    # IPä¸å­˜åœ¨ï¼Œä½†RYUå·²ç»æˆåŠŸäº†
                    print(f"[WARNING] æ•°æ®åº“ä¸­æœªæ‰¾åˆ°{ip}çš„é™é€Ÿè®°å½•ï¼Œä½†RYUå·²æˆåŠŸå¤„ç†")
                    return {
                        "tool": "modify_rate_limit_duration",
                        "success": True,
                        "data": {
                            "ip": ip,
                            "duration_seconds": duration_seconds,
                            "reason": reason,
                            "message": f"âœ… å·²ä¿®æ”¹{ip}çš„é™é€Ÿæ—¶é•¿ä¸º{duration_seconds}ç§’ï¼ŒåŸå› ï¼š{reason}ï¼Œæµè¡¨å·²æ›´æ–°ï¼ˆæ•°æ®åº“è®°å½•å¯èƒ½å·²è¿‡æœŸï¼‰"
                        }
                    }
        except Exception as e:
            print(f"[ERROR] ä¿®æ”¹é™é€Ÿæ—¶é•¿å¤±è´¥: {e}")
            return {
                "tool": "modify_rate_limit_duration",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== MCPå·¥å…·15: ä¿®æ”¹é™é€Ÿæ•°å€¼ï¼ˆæ‰§è¡Œå·¥å…·ï¼‰==========
    def _tool_modify_rate_limit_kbps(self, ip: str, kbps: int, reason: str = "ä¿®æ”¹é™é€Ÿæ•°å€¼") -> Dict[str, Any]:
        """ä¿®æ”¹å¯¹IPçš„é™é€Ÿæ•°å€¼ï¼ˆkbpsï¼‰"""
        try:
            import requests
            
            # éªŒè¯kbpså€¼
            if kbps not in [256, 512, 1024, 2048]:
                return {
                    "tool": "modify_rate_limit_kbps",
                    "success": False,
                    "error": f"é™é€Ÿæ•°å€¼å¿…é¡»ä¸º256ã€512ã€1024æˆ–2048 kbpsï¼Œä¸æ”¯æŒ {kbps}",
                    "data": {}
                }
            
            # ã€å…³é”®ã€‘ç¬¬1æ­¥ï¼šå…ˆè°ƒç”¨RYUæ§åˆ¶å™¨æ›´æ–°æµè¡¨é™é€Ÿé€Ÿç‡
            RYU_BASE = "http://192.168.44.129:8080/v1"
            ryu_data = {
                "ip": ip,
                "kbps": kbps
            }
            print(f"[DEBUG] è°ƒç”¨RYUæ§åˆ¶å™¨ä¿®æ”¹é™é€Ÿé€Ÿç‡: {ryu_data}")
            try:
                ryu_response = requests.put(f"{RYU_BASE}/rate/speed/{ip}", json=ryu_data, timeout=10)
                ryu_response.raise_for_status()
                ryu_result = ryu_response.json()
                print(f"[DEBUG] RYUæ§åˆ¶å™¨ä¿®æ”¹é™é€Ÿé€Ÿç‡å“åº”: {ryu_result}")
            except Exception as ryu_error:
                print(f"[WARNING] RYUæ§åˆ¶å™¨ä¿®æ”¹é™é€Ÿé€Ÿç‡å¤±è´¥ï¼Œä½†ç»§ç»­æ›´æ–°æ•°æ®åº“: {ryu_error}")
                # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­æµç¨‹
            
            # ã€å…³é”®ã€‘ç¬¬2æ­¥ï¼šæ›´æ–°æ•°æ®åº“
            conn = pymysql.connect(**DB_CONFIG)
            with conn.cursor() as cur:
                # å…ˆæ£€æŸ¥IPæ˜¯å¦å­˜åœ¨
                sql_check = "SELECT expire_at FROM rate_limit_active WHERE src_ip=%s"
                cur.execute(sql_check, (ip,))
                existing = cur.fetchone()
                
                if existing:
                    # IPå­˜åœ¨ï¼Œæ‰§è¡ŒUPDATE
                    sql = """UPDATE rate_limit_active 
                             SET kbps = %s
                             WHERE src_ip=%s"""
                    affected = cur.execute(sql, (kbps, ip))
                    conn.commit()
                    
                    print(f"[DEBUG] æ•°æ®åº“UPDATEå½±å“è¡Œæ•°: {affected}")
                    
                    # ã€å…³é”®ä¿®å¤ã€‘ï¼šå³ä½¿affected=0ï¼Œä¹Ÿåº”è¯¥è¿”å›æˆåŠŸ
                    # å› ä¸ºRYUå·²ç»æˆåŠŸæ›´æ–°äº†æµè¡¨å’Œå†…å­˜
                    # æ•°æ®åº“å¯èƒ½å› ä¸ºå€¼ç›¸åŒè€Œaffected=0ï¼Œä½†è¿™ä¸æ˜¯å¤±è´¥
                    expire_at = existing[0].strftime('%Y-%m-%d %H:%M:%S') if existing[0] else "æœªçŸ¥"
                    
                    return {
                        "tool": "modify_rate_limit_kbps",
                        "success": True,
                        "data": {
                            "ip": ip,
                            "kbps": kbps,
                            "expire_at": expire_at,
                            "reason": reason,
                            "message": f"âœ… å·²ä¿®æ”¹{ip}çš„é™é€Ÿæ•°å€¼ä¸º{kbps} kbpsï¼ŒåŸå› ï¼š{reason}ï¼Œæµè¡¨å·²æ›´æ–°"
                        }
                    }
                else:
                    # IPä¸å­˜åœ¨ï¼Œä½†RYUå·²ç»æˆåŠŸäº†
                    # è¿™ç§æƒ…å†µä¸‹åº”è¯¥è¿”å›æˆåŠŸï¼ˆå› ä¸ºRYUå·²ç»å¤„ç†äº†ï¼‰
                    print(f"[WARNING] æ•°æ®åº“ä¸­æœªæ‰¾åˆ°{ip}çš„é™é€Ÿè®°å½•ï¼Œä½†RYUå·²æˆåŠŸå¤„ç†")
                    return {
                        "tool": "modify_rate_limit_kbps",
                        "success": True,
                        "data": {
                            "ip": ip,
                            "kbps": kbps,
                            "reason": reason,
                            "message": f"âœ… å·²ä¿®æ”¹{ip}çš„é™é€Ÿæ•°å€¼ä¸º{kbps} kbpsï¼ŒåŸå› ï¼š{reason}ï¼Œæµè¡¨å·²æ›´æ–°ï¼ˆæ•°æ®åº“è®°å½•å¯èƒ½å·²è¿‡æœŸï¼‰"
                        }
                    }
        except Exception as e:
            print(f"[ERROR] ä¿®æ”¹é™é€Ÿé€Ÿç‡å¤±è´¥: {e}")
            return {
                "tool": "modify_rate_limit_kbps",
                "success": False,
                "error": str(e),
                "data": {}
            }
        finally:
            if conn:
                conn.close()

    # ========== æ—§å·¥å…·ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰==========
    def _tool_check_ip_history(self, ip: str) -> Dict[str, Any]:
        """æ£€æŸ¥IPå†å²è®°å½•ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰"""
        # è°ƒç”¨æ–°çš„æŸ¥è¯¢å·¥å…·
        acl_status = self._tool_query_acl_status(ip)
        attack_history = self._tool_query_attack_history(ip)
        rate_limit = self._tool_query_rate_limit_history(ip)
        
        return {
            "tool": "check_ip_history",
            "success": True,
            "data": {
                "ip": ip,
                "acl_status": acl_status['data'],
                "attack_history": attack_history['data'],
                "rate_limit": rate_limit['data']
            }
        }
    
    def _tool_get_network_status(self) -> Dict[str, Any]:
        """è·å–ç½‘ç»œçŠ¶æ€ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰"""
        # è°ƒç”¨æ–°çš„æŸ¥è¯¢å·¥å…·
        return self._tool_get_current_status()
    
    # ========== Agentæ ¸å¿ƒåŠŸèƒ½ ==========
    
    def analyze_anomaly(self, anomaly_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†æç½‘ç»œå¼‚å¸¸ï¼ˆAgentä¸»è¦åŠŸèƒ½ï¼‰
        
        Args:
            anomaly_info: å¼‚å¸¸ä¿¡æ¯
                - type: æ”»å‡»ç±»å‹
                - src_ip: æºIP
                - features: ç‰¹å¾æè¿°
                
        Returns:
            åˆ†æç»“æœ
        """
        src_ip = anomaly_info.get('src_ip', 'æœªçŸ¥')
        anomaly_type = anomaly_info.get('type', 'æœªçŸ¥')
        features = anomaly_info.get('features', 'æ— ')
        
        print(f"\n{'='*60}")
        print(f"ğŸ¤– Security Agent å¼€å§‹åˆ†æå¼‚å¸¸...")
        print(f"   å¼‚å¸¸ç±»å‹: {anomaly_type}")
        print(f"   æºIP: {src_ip}")
        print(f"{'='*60}")
        
        # ========== é˜¶æ®µ1: çŸ¥è¯†æ£€ç´¢ï¼ˆRAGï¼‰ ==========
        print("\nğŸ“š [é˜¶æ®µ1] æ£€ç´¢çŸ¥è¯†åº“...")
        query = f"{anomaly_type}æ”»å‡»çš„ç‰¹å¾å’Œé˜²å¾¡ç­–ç•¥"
        knowledge_result = self._tool_search_knowledge(query)
        
        if knowledge_result['success'] and knowledge_result['data']:
            print(f"âœ… æ£€ç´¢åˆ° {knowledge_result['count']} æ¡ç›¸å…³çŸ¥è¯†")
            knowledge_context = "\n".join([f"- {k[:100]}..." for k in knowledge_result['data']])
        else:
            print("âš ï¸ æœªæ£€ç´¢åˆ°ç›¸å…³çŸ¥è¯†")
            knowledge_context = "ï¼ˆæš‚æ— ç›¸å…³çŸ¥è¯†åº“ä¿¡æ¯ï¼‰"
        
        # ========== é˜¶æ®µ2: ä¿¡æ¯æ”¶é›†ï¼ˆMCPå·¥å…·è°ƒç”¨ï¼‰ ==========
        print("\nğŸ” [é˜¶æ®µ2] è°ƒç”¨MCPå·¥å…·æ”¶é›†ä¿¡æ¯...")
        
        # è°ƒç”¨å·¥å…·1ï¼šæŸ¥è¯¢ACLçŠ¶æ€
        acl_status = self._tool_query_acl_status(src_ip)
        print(f"   âœ“ å·²æŸ¥è¯¢ACLçŠ¶æ€")
        
        # è°ƒç”¨å·¥å…·2ï¼šæŸ¥è¯¢é™é€Ÿå†å²
        rate_limit_history = self._tool_query_rate_limit_history(src_ip)
        print(f"   âœ“ å·²æŸ¥è¯¢é™é€Ÿå†å²")
        
        # è°ƒç”¨å·¥å…·3ï¼šæŸ¥è¯¢æ”»å‡»å†å²
        attack_history = self._tool_query_attack_history(src_ip)
        print(f"   âœ“ å·²æŸ¥è¯¢æ”»å‡»å†å²")
        
        # è°ƒç”¨å·¥å…·4ï¼šæŸ¥è¯¢æµé‡ç»Ÿè®¡
        flow_stats = self._tool_query_flow_stats(src_ip)
        print(f"   âœ“ å·²æŸ¥è¯¢æµé‡ç»Ÿè®¡")
        
        # è°ƒç”¨å·¥å…·5ï¼šè·å–é˜²å¾¡è§„åˆ™
        defense_rules = self._tool_get_defense_rules(anomaly_type)
        print(f"   âœ“ å·²è·å–é˜²å¾¡è§„åˆ™")
        
        # è°ƒç”¨å·¥å…·6ï¼šæŸ¥è¯¢ç½‘ç»œæ‹“æ‰‘
        network_topology = self._tool_query_network_topology()
        print(f"   âœ“ å·²æŸ¥è¯¢ç½‘ç»œæ‹“æ‰‘")
        
        # è°ƒç”¨å·¥å…·7ï¼šè·å–ç³»ç»ŸçŠ¶æ€
        system_status = self._tool_get_current_status()
        print(f"   âœ“ å·²è·å–ç³»ç»ŸçŠ¶æ€")
        
        # ========== é˜¶æ®µ3: LLMåˆ†æï¼ˆAgentæ€è€ƒï¼‰ ==========
        print("\nğŸ§  [é˜¶æ®µ3] AIåˆ†æä¸­...")
        
        # æ„å»ºå¢å¼ºæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªç½‘ç»œå®‰å…¨ä¸“å®¶ï¼Œæ­£åœ¨åˆ†æä¸€ä¸ªç½‘ç»œå¼‚å¸¸äº‹ä»¶ã€‚

ã€æ£€æµ‹åˆ°çš„å¼‚å¸¸ä¿¡æ¯ã€‘
- æ”»å‡»ç±»å‹ï¼š{anomaly_type}
- æºIPï¼š{src_ip}
- å¼‚å¸¸ç‰¹å¾ï¼š{features}

ã€çŸ¥è¯†åº“ç›¸å…³ä¿¡æ¯ã€‘
{knowledge_context}

ã€IPé»‘ç™½åå•çŠ¶æ€ã€‘
{json.dumps(acl_status['data'], ensure_ascii=False, indent=2)}

ã€IPé™é€Ÿå†å²ã€‘
{json.dumps(rate_limit_history['data'], ensure_ascii=False, indent=2)}

ã€IPæ”»å‡»å†å²ã€‘
{json.dumps(attack_history['data'], ensure_ascii=False, indent=2)}

ã€IPæµé‡ç»Ÿè®¡ï¼ˆæœ€è¿‘1å°æ—¶ï¼‰ã€‘
{json.dumps(flow_stats['data'], ensure_ascii=False, indent=2)}

ã€é˜²å¾¡è§„åˆ™ã€‘
{json.dumps(defense_rules['data'], ensure_ascii=False, indent=2)}

ã€ç½‘ç»œæ‹“æ‰‘ã€‘
{json.dumps(network_topology['data'], ensure_ascii=False, indent=2)}

ã€ç³»ç»Ÿå½“å‰çŠ¶æ€ã€‘
{json.dumps(system_status['data'], ensure_ascii=False, indent=2)}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç”¨JSONæ ¼å¼ç»™å‡ºåˆ†æç»“æœï¼š
{{
    "risk_level": "ä½/ä¸­/é«˜/ä¸¥é‡",
    "confidence": 0-100çš„æ•´æ•°,
    "recommended_action": "rate_limit/blacklist/alert_only/no_action",
    "kbps": å»ºè®®çš„é™é€Ÿé€Ÿç‡ï¼ˆå¦‚æœactionæ˜¯rate_limitï¼‰,
    "reason": "è¯¦ç»†çš„åˆ†æåŸå› ï¼Œ200å­—ä»¥å†…",
    "evidence": ["è¯æ®1", "è¯æ®2", "è¯æ®3"]
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
        
        llm_response = self._call_llm(prompt, temperature=0.2)
        
        # è§£æLLMå“åº”
        try:
            # æå–JSONéƒ¨åˆ†
            json_start = llm_response.find('{')
            json_end = llm_response.rfind('}') + 1
            if json_start >= 0 and json_end > json_start:
                analysis = json.loads(llm_response[json_start:json_end])
            else:
                raise ValueError("æœªæ‰¾åˆ°JSONæ ¼å¼çš„å“åº”")
        except Exception as e:
            print(f"âš ï¸ LLMå“åº”è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ: {e}")
            analysis = {
                "risk_level": "ä¸­",
                "confidence": 50,
                "recommended_action": "alert_only",
                "reason": f"æ£€æµ‹åˆ°{anomaly_type}å¼‚å¸¸ï¼Œå»ºè®®äººå·¥å®¡æ ¸",
                "evidence": ["è‡ªåŠ¨æ£€æµ‹åˆ°å¼‚å¸¸æµé‡"]
            }
        
        print(f"âœ… åˆ†æå®Œæˆ")
        print(f"   é£é™©ç­‰çº§: {analysis.get('risk_level', 'æœªçŸ¥')}")
        print(f"   ç½®ä¿¡åº¦: {analysis.get('confidence', 0)}%")
        print(f"   å»ºè®®æªæ–½: {analysis.get('recommended_action', 'æœªçŸ¥')}")
        
        # ========== é˜¶æ®µ4: ç”Ÿæˆå®Œæ•´æŠ¥å‘Š ==========
        result = {
            "anomaly_type": anomaly_type,
            "src_ip": src_ip,
            "timestamp": datetime.now().isoformat(),
            
            # RAGæ£€ç´¢ç»“æœ
            "knowledge_sources": knowledge_result['data'] if knowledge_result['success'] else [],
            "knowledge_count": knowledge_result.get('count', 0),
            
            # MCPå·¥å…·è°ƒç”¨ç»“æœ
            "tools_used": [
                "search_knowledge",
                "query_acl_status",
                "query_rate_limit_history",
                "query_attack_history",
                "query_flow_stats",
                "get_defense_rules",
                "query_network_topology",
                "get_current_status"
            ],
            "mcp_results": {
                "acl_status": acl_status['data'],
                "rate_limit_history": rate_limit_history['data'],
                "attack_history": attack_history['data'],
                "flow_stats": flow_stats['data'],
                "defense_rules": defense_rules['data'],
                "network_topology": network_topology['data'],
                "system_status": system_status['data']
            },
            
            # Agentåˆ†æç»“æœ
            "analysis": analysis,
            
            # å…ƒæ•°æ®
            "agent_version": "2.0",
            "model_used": self.model,
            "rag_enabled": True,
            "mcp_enabled": True
        }
        
        print(f"\n{'='*60}")
        print("âœ… Agentåˆ†æå®Œæˆï¼")
        print(f"{'='*60}\n")
        
        return result
    
    def quick_query(self, query: str) -> Dict[str, Any]:
        """
        å¿«é€ŸæŸ¥è¯¢ï¼ˆç®€å•çš„RAGé—®ç­”ï¼‰
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            æŸ¥è¯¢ç»“æœ
        """
        print(f"\nğŸ¤– Agentå¿«é€ŸæŸ¥è¯¢: {query}")
        
        # ä½¿ç”¨RAGç”Ÿæˆå›ç­”
        rag_result = self.rag.generate_with_rag(query, top_k=3)
        
        return {
            "query": query,
            "answer": rag_result['answer'],
            "knowledge_sources": rag_result['knowledge_sources'],
            "timestamp": datetime.now().isoformat(),
            "agent_version": "1.0"
        }


# å…¨å±€Agentå®ä¾‹
_agent_instance = None

def get_agent_instance() -> SecurityAgent:
    """è·å–Agentå®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = SecurityAgent()
    return _agent_instance


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("="*60)
    print("Security Agent æµ‹è¯•")
    print("="*60)
    
    # åˆå§‹åŒ–Agent
    agent = get_agent_instance()
    
    # æµ‹è¯•1: åˆ†æå¼‚å¸¸
    print("\n\nã€æµ‹è¯•1ï¼šåˆ†æDDoSæ”»å‡»ã€‘")
    result = agent.analyze_anomaly({
        "type": "DDoS",
        "src_ip": "192.168.1.100",
        "features": "æµé‡çªå¢ï¼ŒåŒ…å¤§å°512å­—èŠ‚ï¼Œç›®æ ‡ç«¯å£80"
    })
    
    print("\nã€åˆ†æç»“æœã€‘")
    print(json.dumps(result, ensure_ascii=False, indent=2))
    
    # æµ‹è¯•2: å¿«é€ŸæŸ¥è¯¢
    print("\n\nã€æµ‹è¯•2ï¼šå¿«é€ŸæŸ¥è¯¢ã€‘")
    query_result = agent.quick_query("ä»€ä¹ˆæ˜¯ç«¯å£æ‰«æï¼Ÿå¦‚ä½•é˜²å¾¡ï¼Ÿ")
    
    print("\nã€æŸ¥è¯¢ç»“æœã€‘")
    print(f"å›ç­”: {query_result['answer']}")
    print(f"\nçŸ¥è¯†æºæ•°é‡: {len(query_result['knowledge_sources'])}")
