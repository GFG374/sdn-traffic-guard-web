#!/usr/bin/env python
"""
v1_routes æé€Ÿç‰ˆï¼ˆç¼“å­˜ + ç´¢å¼• + æ¡æ•°è£å‰ªï¼‰
1. ç¼“å­˜çƒ­ç‚¹æŸ¥è¯¢ 60 ç§’
2. æµé‡/å¼‚å¸¸åªè¿”å›æœ€è¿‘ 48 ç‚¹ï¼ˆ4 å°æ—¶ï¼‰
3. ä¸æ”¹ Ryuï¼Œåªæ”¹ä¸­é—´å±‚
"""
import random
import time
import requests
import uuid
import json
from decimal import Decimal
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from functools import wraps

from fastapi import APIRouter, Form, HTTPException, Query, UploadFile, File
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import pymysql
import redis
from pathlib import Path

# è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œæ”¯æŒDecimalç±»å‹
class DecimalEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, Decimal):
            return float(obj)
        return super().default(obj)

router = APIRouter(prefix="/v1", tags=["v1"])

# ---------- é…ç½® ----------
RYU_BASE = "http://192.168.44.129:8080/v1"
TIMEOUT = 10
DB_CONFIG = {
    'host': '127.0.0.1',   # Windows æœ¬æœº MySQL
    'user': 'root',
    'password': 'yyr0218...',
    'db': 'network_management',
    'charset': 'utf8mb4'
}
# å¼ºåˆ¶ä½¿ç”¨çœŸå®æ•°æ®ï¼ˆå³ä½¿RYUæ§åˆ¶å™¨ä¸å¯ç”¨ä¹Ÿä¸è¿”å›æ¨¡æ‹Ÿæ•°æ®ï¼‰
FORCED_REAL_DATA = True
REDIS_HOST = '127.0.0.1'
REDIS_PORT = 6379
REDIS_DB   = 0
CACHE_TTL  = 60            # ç§’

r = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=REDIS_DB, decode_responses=True)

# ---------- æ¨¡å‹ ----------
class ChatRequest(BaseModel):
    username: Optional[str] = None  # âœ… æ–°å¢ï¼šä½¿ç”¨usernameå­—æ®µ
    user_id: Optional[str] = None   # âœ… ä¿ç•™ï¼šå‘åå…¼å®¹
    user: str  # ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯å†…å®¹
    has_uploaded_file: Optional[bool] = False  # æ˜¯å¦æœ‰ä¸Šä¼ çš„æ–‡ä»¶
    uploaded_filename: Optional[str] = None  # ä¸Šä¼ çš„æ–‡ä»¶å
    conversation_history: Optional[List[Dict[str, str]]] = None  # ã€æ–°å¢ã€‘å¯¹è¯å†å²ï¼Œç”¨äºä¸Šä¸‹æ–‡ç†è§£

class ThresholdBody(BaseModel):
    syn_threshold: Optional[int] = None
    udp_threshold: Optional[int] = None
    icmp_threshold: Optional[int] = None

# ---------- å·¥å…· ----------

def proxy_get(path: str) -> Dict[str, Any]:
    """ä»£ç†GETè¯·æ±‚åˆ°RYUæ§åˆ¶å™¨ï¼Œå¤±è´¥æ—¶è¿”å›é”™è¯¯"""
    try:
        print(f"[DEBUG] å°è¯•è¿æ¥RYUæ§åˆ¶å™¨: {RYU_BASE}/{path}")
        r = requests.get(f"{RYU_BASE}/{path}", timeout=TIMEOUT)
        r.raise_for_status()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å“åº”æˆåŠŸ")
        return {"success": True, "data": r.json(), "message": "ok"}
    except Exception as e:
        print(f"[ERROR] RYUæ§åˆ¶å™¨è¯·æ±‚å¤±è´¥: {e}")
        error_msg = f"æ— æ³•è·å–çœŸå®æ•°æ®: {str(e)}"
        print(f"[ERROR] {error_msg}")
        return {"success": False, "data": [], "message": error_msg}

def cache_key(func_name: str, *args) -> str:
    return f"v1:{func_name}:" + ":".join(map(str, args))


def _generate_default_response(user_message: str, tool_results: dict) -> str:
    """
    åŸºäºå·¥å…·ç»“æœç”Ÿæˆé»˜è®¤å›ç­”ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
    """
    response_parts = []
    
    # åˆ†æå·¥å…·ç»“æœå¹¶ç”Ÿæˆå›ç­”
    for tool_name, result in tool_results.items():
        if isinstance(result, dict):
            if tool_name == "query_acl_status":
                status = result.get("status", "unknown")
                if status == "black":
                    response_parts.append(f"è¯¥IPåœ¨é»‘åå•ä¸­")
                elif status == "white":
                    response_parts.append(f"è¯¥IPåœ¨ç™½åå•ä¸­")
                else:
                    response_parts.append(f"è¯¥IPçŠ¶æ€æ­£å¸¸")
            
            elif tool_name == "query_attack_history":
                attacks = result.get("attacks", [])
                if attacks:
                    response_parts.append(f"è¯¥IPæœ‰{len(attacks)}æ¡å†å²æ”»å‡»è®°å½•")
                else:
                    response_parts.append(f"è¯¥IPæ²¡æœ‰å†å²æ”»å‡»è®°å½•")
            
            elif tool_name == "query_flow_stats":
                packet_count = result.get("total_packets", 0)
                if packet_count > 0:
                    response_parts.append(f"è¯¥IPçš„æµé‡ç»Ÿè®¡ï¼šæ€»åŒ…æ•°{packet_count}")
            
            elif tool_name == "get_defense_rules":
                rules = result.get("rules", [])
                if rules:
                    response_parts.append(f"é˜²å¾¡è§„åˆ™å·²è·å–ï¼Œå…±{len(rules)}æ¡")
            
            elif tool_name == "get_current_status":
                response_parts.append(f"ç³»ç»ŸçŠ¶æ€å·²è·å–")
    
    if response_parts:
        return "æ ¹æ®å®æ—¶æ•°æ®åˆ†æï¼š" + "ï¼›".join(response_parts)
    else:
        return "å·²è°ƒç”¨MCPå·¥å…·è·å–å®æ—¶æ•°æ®ï¼Œä½†æš‚æ— å…·ä½“åˆ†æç»“æœ"


def _get_default_tool_decision(user_message: str) -> str:
    """
    æ ¹æ®ç”¨æˆ·æ¶ˆæ¯è‡ªåŠ¨åˆ¤æ–­éœ€è¦è°ƒç”¨å“ªäº›MCPå·¥å…·ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
    """
    import json
    import re
    
    message_lower = user_message.lower()
    tools = []
    
    # æå–IPåœ°å€
    ip_match = re.search(r'\d+\.\d+\.\d+\.\d+', user_message)
    ip = ip_match.group(0) if ip_match else None
    
    # æ ¹æ®å…³é”®è¯åˆ¤æ–­éœ€è¦è°ƒç”¨çš„å·¥å…·
    if any(keyword in message_lower for keyword in ['é»‘åå•', 'ç™½åå•', 'åå•', 'acl']):
        if ip:
            tools.append({"tool": "query_acl_status", "params": {"ip": ip}})
    
    if any(keyword in message_lower for keyword in ['é™é€Ÿ', 'é€Ÿç‡', 'é™åˆ¶', 'rate']):
        if ip:
            tools.append({"tool": "query_rate_limit_history", "params": {"ip": ip}})
    
    if any(keyword in message_lower for keyword in ['æ”»å‡»', 'å¼‚å¸¸', 'å†å²', 'attack']):
        if ip:
            tools.append({"tool": "query_attack_history", "params": {"ip": ip}})
        tools.append({"tool": "get_defense_rules", "params": {}})
    
    if any(keyword in message_lower for keyword in ['æµé‡', 'ç»Ÿè®¡', 'flow', 'stats']):
        if ip:
            tools.append({"tool": "query_flow_stats", "params": {"ip": ip}})
    
    if any(keyword in message_lower for keyword in ['æ‹“æ‰‘', 'ç½‘ç»œ', 'topology']):
        tools.append({"tool": "query_network_topology", "params": {}})
    
    if any(keyword in message_lower for keyword in ['çŠ¶æ€', 'ç³»ç»Ÿ', 'status']):
        tools.append({"tool": "get_current_status", "params": {}})
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å·¥å…·ï¼Œé»˜è®¤æŸ¥è¯¢IPçš„æ‰€æœ‰ä¿¡æ¯
    if not tools and ip:
        tools = [
            {"tool": "query_acl_status", "params": {"ip": ip}},
            {"tool": "query_attack_history", "params": {"ip": ip}},
            {"tool": "query_flow_stats", "params": {"ip": ip}}
        ]
    
    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰å·¥å…·ï¼Œè¿”å›ç³»ç»ŸçŠ¶æ€
    if not tools:
        tools = [{"tool": "get_current_status", "params": {}}]
    
    decision = {
        "tools": tools,
        "analysis": "ä½¿ç”¨é»˜è®¤å·¥å…·å†³ç­–"
    }
    
    return json.dumps(decision, ensure_ascii=False)

def cached_query(key: str, sql: str, params: tuple, ttl: int = 60) -> List[Dict]:
    """çº¯ MySQL ç‰ˆï¼Œä¸ä½¿ç”¨ Redis"""
    try:
        conn = pymysql.connect(**DB_CONFIG)
        with conn.cursor(pymysql.cursors.DictCursor) as cur:
            cur.execute(sql, params)
            rows = cur.fetchall()
            # datetime â†’ æ—¶é—´æˆ³
            for row in rows:
                for k, v in row.items():
                    if isinstance(v, datetime):
                        row[k] = int(v.timestamp())
        return rows
    except Exception as e:
        logger.error(f"cached_query å¤±è´¥: {e}")
        return []
    finally:
        if conn:
            conn.close()


# ---------- 1. åŸæœ‰æ¥å£ï¼ˆæé€Ÿç‰ˆï¼‰ ----------
@router.get("/summary")
async def get_summary():
    day = datetime.now().strftime('%Y-%m-%d')
    key = cache_key("summary", day)
    rows = cached_query(key,
                   "SELECT COUNT(*) FROM anomaly_log WHERE DATE(detect_time) = %s",
                   (day,))

    ano = rows[0]['COUNT(*)'] if rows else 0

    key2 = cache_key("summary_counts")
    rows2 = cached_query(key2,
                         "SELECT 'limit' as k,COUNT(*) FROM rate_limit_active UNION ALL "
                         "SELECT 'black',COUNT(*) FROM acl_entries WHERE list_type='black' UNION ALL "
                         "SELECT 'white',COUNT(*) FROM acl_entries WHERE list_type='white'",
                         (), ttl=30)
    counts = {r['k']: r['COUNT(*)'] for r in rows2}
    
    # è®¡ç®—æ´»è·ƒä¸»æœºæ•°é‡ - ä»å¼‚å¸¸æ—¥å¿—ä¸­ç»Ÿè®¡ä¸åŒçš„æºIP
    # âœ… ä¿®å¤ï¼šå…ˆå°è¯•æŸ¥è¯¢dst_ipï¼Œå¦‚æœå¤±è´¥åˆ™åªæŸ¥è¯¢src_ip
    key3 = cache_key("host_count", day)
    try:
        rows3 = cached_query(key3,
                            "SELECT COUNT(DISTINCT ip) as host_count FROM ("
                            "SELECT src_ip as ip FROM anomaly_log WHERE DATE(detect_time) = %s "
                            "UNION "
                            "SELECT dst_ip as ip FROM anomaly_log WHERE DATE(detect_time) = %s"
                            ") as combined_ips",
                            (day, day), ttl=300)  # 5åˆ†é’Ÿç¼“å­˜
        host_count = rows3[0]['host_count'] if rows3 and len(rows3) > 0 else 0
    except Exception as e:
        # dst_ipå­—æ®µä¸å­˜åœ¨ï¼Œåªç»Ÿè®¡src_ip
        print(f"[WARNING] dst_ipå­—æ®µä¸å­˜åœ¨ï¼Œåªç»Ÿè®¡src_ip: {e}")
        rows3 = cached_query(key3,
                            "SELECT COUNT(DISTINCT src_ip) as host_count "
                            "FROM anomaly_log WHERE DATE(detect_time) = %s",
                            (day,), ttl=300)
        host_count = rows3[0]['host_count'] if rows3 and len(rows3) > 0 else 0
    
    return {"success": True,
            "data": {
                "today_anomalies": ano,
                "limit_count": counts.get('limit', 0),
                "black_count": counts.get('black', 0),
                "white_count": counts.get('white', 0),
                "switch_count": 1,  # å®æ—¶å†…å­˜ï¼Œä¸æ”¹
                "host_count": host_count  # çœŸå®çš„æ´»è·ƒä¸»æœºæ•°é‡
            },
            "message": "ok"}

@router.get("/attack_sessions")
async def get_attack_sessions(
    hours: int = Query(12, description="è·å–æœ€è¿‘Nå°æ—¶çš„æ”»å‡»ä¼šè¯æ•°æ®"),
    limit: int = Query(10, description="æœ€å¤§è¿”å›æ•°æ®æ¡æ•°")
):
    """è·å–æ”»å‡»ä¼šè¯æ•°æ®ï¼ˆä»attack_sessionsè¡¨ï¼Œå·²å»é‡çš„æ”»å‡»è®°å½•ï¼‰"""
    try:
        print(f"[DEBUG] è½¬å‘æ”»å‡»ä¼šè¯è¯·æ±‚: hours={hours}, limit={limit}")
        r = requests.get(f"{RYU_BASE}/attack_sessions", params={"hours": hours, "limit": limit}, timeout=TIMEOUT)
        r.raise_for_status()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å“åº”æˆåŠŸï¼Œè¿”å› {len(r.json())} æ¡è®°å½•")
        return r.json()
    except Exception as e:
        print(f"[ERROR] è·å–æ”»å‡»ä¼šè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/handled-sessions/count")
async def get_handled_sessions_count():
    """ç»Ÿè®¡ä¸åŒæ—¶é—´æ®µçš„å·²å¤„ç†æ”»å‡»ä¼šè¯æ•°é‡"""
    try:
        print(f"[DEBUG] æŸ¥è¯¢å·²å¤„ç†æ”»å‡»ä¼šè¯ç»Ÿè®¡")
        r = requests.get(f"{RYU_BASE}/handled-sessions/count", timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] å·²å¤„ç†æ”»å‡»ä¼šè¯ç»Ÿè®¡: {result}")
        return result
    except Exception as e:
        print(f"[ERROR] è·å–å·²å¤„ç†æ”»å‡»ä¼šè¯ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# è®¾å¤‡å¼‚å¸¸ç›‘æ§ --------------------------------------------------------------

@router.get("/device-anomalies")
async def proxy_device_anomalies(hours: int = Query(24, ge=1, le=168)):
    """è½¬å‘è®¾å¤‡å¼‚å¸¸æŸ¥è¯¢åˆ° RYU æ§åˆ¶å™¨"""
    try:
        params = {"hours": hours}
        print(f"[DEBUG] è½¬å‘è®¾å¤‡å¼‚å¸¸æŸ¥è¯¢: params={params}")
        r = requests.get(f"{RYU_BASE}/device-anomalies", params=params, timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] è®¾å¤‡å¼‚å¸¸æŸ¥è¯¢æˆåŠŸ: count={result.get('count') if isinstance(result, dict) else 'unknown'}")
        return result
    except Exception as e:
        print(f"[ERROR] è·å–è®¾å¤‡å¼‚å¸¸å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.put("/device-anomalies/{anomaly_id}")
async def proxy_update_device_anomaly(anomaly_id: int, payload: dict):
    """è½¬å‘è®¾å¤‡å¼‚å¸¸çŠ¶æ€æ›´æ–°åˆ° RYU æ§åˆ¶å™¨"""
    try:
        print(f"[DEBUG] æ›´æ–°è®¾å¤‡å¼‚å¸¸çŠ¶æ€: id={anomaly_id}, payload={payload}")
        r = requests.put(f"{RYU_BASE}/device-anomalies/{anomaly_id}", json=payload, timeout=TIMEOUT)
        
        # 404 æ„å‘³ç€è®°å½•å·²è¢«å¤„ç†æˆ–ä¸å­˜åœ¨ï¼Œå¯¹å‰ç«¯æ¥è¯´è¿™æ˜¯æˆåŠŸçš„
        if r.status_code == 404:
            print(f"[DEBUG] å¼‚å¸¸ {anomaly_id} ä¸å­˜åœ¨ï¼ˆå·²å¤„ç†ï¼‰ï¼Œè¿”å›æˆåŠŸå“åº”")
            return {"success": True, "message": f"å¼‚å¸¸å·²å¤„ç†", "affected_rows": 0}
        
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] è®¾å¤‡å¼‚å¸¸çŠ¶æ€æ›´æ–°æˆåŠŸ: {result}")
        return result
    except Exception as e:
        print(f"[ERROR] æ›´æ–°è®¾å¤‡å¼‚å¸¸å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/attack-sessions/count")
async def get_attack_sessions_count():
    """ç»Ÿè®¡ä¸åŒæ—¶é—´æ®µçš„æ”»å‡»ä¼šè¯æ•°é‡"""
    try:
        print(f"[DEBUG] è½¬å‘æ”»å‡»ä¼šè¯ç»Ÿè®¡è¯·æ±‚")
        r = requests.get(f"{RYU_BASE}/attack-sessions/count", timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨ç»Ÿè®¡å“åº”æˆåŠŸ: {result}")
        return result
    except Exception as e:
        print(f"[ERROR] è·å–æ”»å‡»ä¼šè¯ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/handled-ips")
async def get_handled_ips(days: int = Query(1, description="æŸ¥è¯¢æœ€è¿‘Nå¤©", ge=1, le=7)):
    """è·å–å·²å¤„ç†çš„IPåˆ—è¡¨ï¼ˆä»limit_sessionsè¡¨ï¼‰"""
    try:
        print(f"[DEBUG] è½¬å‘handled_ipsè¯·æ±‚: æœ€è¿‘{days}å¤©")
        r = requests.get(f"{RYU_BASE}/handled-ips", params={"days": days}, timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å“åº”æˆåŠŸ: æœ€è¿‘{days}å¤©æœ‰{result.get('count', 0)}ä¸ªIPè¢«å¤„ç†")
        return result
    except Exception as e:
        print(f"[ERROR] è·å–handled_ipså¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/attack-sessions/update-status")
async def update_attack_status(data: dict):
    """æ›´æ–°æ”»å‡»ä¼šè¯çš„å¤„ç†çŠ¶æ€"""
    try:
        print(f"[DEBUG] æ›´æ–°æ”»å‡»çŠ¶æ€: IP={data.get('ip')}, action={data.get('action')}")
        r = requests.post(f"{RYU_BASE}/attack-sessions/update-status", json=data, timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] æ›´æ–°æˆåŠŸ: {result}")
        return result
    except Exception as e:
        print(f"[ERROR] æ›´æ–°æ”»å‡»çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/attack-sessions/trend")
async def get_attack_sessions_trend(hours: int = Query(24, description="æŸ¥è¯¢æœ€è¿‘Nå°æ—¶", ge=1, le=168)):
    """è·å–æ”»å‡»ä¼šè¯çš„æ—¶é—´è¶‹åŠ¿æ•°æ®ï¼ˆç”¨äºå¼‚å¸¸æ—¶é—´è¶‹åŠ¿å›¾ï¼‰"""
    try:
        print(f"[DEBUG] è½¬å‘attack_sessions_trendè¯·æ±‚: æœ€è¿‘{hours}å°æ—¶")
        r = requests.get(f"{RYU_BASE}/attack-sessions/trend", params={"hours": hours}, timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å“åº”æˆåŠŸ: è·å–åˆ°{len(result.get('data', []))}ä¸ªæ—¶é—´ç‚¹çš„è¶‹åŠ¿æ•°æ®")
        return result
    except Exception as e:
        print(f"[ERROR] è·å–attack_sessions_trendå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/anomalies")
async def get_anomalies(
    hours: int = Query(12, description="è·å–æœ€è¿‘Nå°æ—¶çš„å¼‚å¸¸æ•°æ®", ge=1, le=168),
    limit: int = Query(None, description="æœ€å¤§è¿”å›æ•°æ®æ¡æ•°ï¼Œä¸ä¼ åˆ™è¿”å›æ‰€æœ‰æ•°æ®"),
    raw: bool = Query(False, description="æ˜¯å¦è¿”å›åŸå§‹æ•°æ®ï¼ˆä¸å»é‡ï¼‰")
):
    """è·å–å¼‚å¸¸æ£€æµ‹æ•°æ®ï¼Œä½¿ç”¨RYUæ§åˆ¶å™¨çš„æ—¶é—´è¿‡æ»¤è·¯ç”±ï¼Œæ”¯æŒè‡ªå®šä¹‰æ—¶é—´èŒƒå›´"""
    try:
        # ä½¿ç”¨RYUæ§åˆ¶å™¨çš„æ—¶é—´è¿‡æ»¤å‚æ•°ï¼ˆæœ€è¿‘Nå°æ—¶ï¼‰
        ryu_endpoint = f"{RYU_BASE}/anomalies"
        params = {'hours': hours}
        if limit is not None:
            params['limit'] = limit
        
        print(f"[DEBUG] å°è¯•è¿æ¥RYUæ§åˆ¶å™¨è·å–å¼‚å¸¸æ•°æ®: {ryu_endpoint}, å‚æ•°: {params}")
        r = requests.get(ryu_endpoint, params=params, timeout=TIMEOUT)
        r.raise_for_status()
        raw_data = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å¼‚å¸¸æ•°æ®å“åº”æˆåŠŸï¼Œæ•°æ®é‡: {len(raw_data)}")
        
        # å¤„ç†RYUè¿”å›çš„æ•°æ®ï¼Œè½¬æ¢ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼
        processed_anomalies = []
        seen_attacks = set()  # ç”¨äºå»é‡ï¼Œä½†ä½¿ç”¨æ›´ç»†ç²’åº¦çš„æ ‡è¯†ç¬¦
        
        for item in raw_data:
            src_ip = item.get('src_ip', '')
            anomaly_type = item.get('anomaly_type', '')
            detect_time = item.get('detect_time', '')
            details = item.get('details', '')
            
            # è§£ææ—¶é—´
            try:
                dt = datetime.strptime(detect_time, '%Y-%m-%d %H:%M:%S')
            except:
                # å¦‚æœæ—¶é—´è§£æå¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                print(f"[WARNING] æ—¶é—´è§£æå¤±è´¥: {detect_time}")
                dt = datetime.now()
            
            # è§£ædetailsä¸­çš„é€Ÿç‡ä¿¡æ¯
            rate_kbps = 0
            if 'rate=' in details:
                try:
                    rate_str = details.split('rate=')[1].split()[0]
                    rate_kbps = float(rate_str)
                except Exception as e:
                    print(f"[DEBUG] é€Ÿç‡è§£æå¤±è´¥: {details}, é”™è¯¯: {e}")
                    rate_kbps = 0
            
            # åˆ›å»ºæ›´ç»†ç²’åº¦çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼ŒåŒ…å«é€Ÿç‡ä¿¡æ¯ä»¥å‡å°‘è¿‡åº¦å»é‡
            try:
                # ä½¿ç”¨ç§’çº§æ—¶é—´æˆ³å’Œé€Ÿç‡ä¿¡æ¯ï¼Œè®©æ›´å¤šä¸åŒçš„æ”»å‡»äº‹ä»¶èƒ½å¤Ÿæ˜¾ç¤º
                second_key = dt.strftime('%Y-%m-%d %H:%M:%S')
                rate_range = int(rate_kbps / 10) * 10  # æŒ‰10kbpsåˆ†ç»„
                attack_key = f"{src_ip}_{anomaly_type}_{second_key}_{rate_range}"
            except:
                attack_key = f"{src_ip}_{anomaly_type}_{detect_time}_{rate_kbps}"
            
            if attack_key not in seen_attacks:
                seen_attacks.add(attack_key)
                
                # è½¬æ¢æ—¶é—´æ ¼å¼ä¸ºæ—¶é—´æˆ³
                try:
                    timestamp = int(dt.timestamp() * 1000)  # æ¯«ç§’æ—¶é—´æˆ³
                    time_str = dt.strftime('%H:%M:%S')  # æ—¶é—´å­—ç¬¦ä¸²
                except:
                    timestamp = int(datetime.now().timestamp() * 1000)
                    time_str = detect_time
                
                processed_item = {
                    'id': f"anomaly_{src_ip}_{timestamp}_{rate_kbps}",
                    'time': time_str,
                    'src_ip': src_ip,
                    'dst_ip': item.get('dst_ip', ''),
                    'type': anomaly_type,
                    'anomaly_type': anomaly_type,  # å…¼å®¹å‰ç«¯
                    'details': f"é€Ÿç‡: {rate_kbps:.1f} kbps" if rate_kbps > 0 else details,
                    'timestamp': timestamp,
                    'detect_time': detect_time,
                    'rate_kbps': round(rate_kbps, 1),
                    'severity': 'high' if rate_kbps > 1000 else 'medium' if rate_kbps > 100 else 'low',
                    'status': 'detected'
                }
                processed_anomalies.append(processed_item)
        
        # æŒ‰æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        processed_anomalies.sort(key=lambda x: x['timestamp'], reverse=True)
        
        # ä½¿ç”¨ä¼ å…¥çš„limitå‚æ•°é™åˆ¶è¿”å›çš„æ•°æ®é‡ï¼Œå¦‚æœlimitä¸ºNoneåˆ™è¿”å›æ‰€æœ‰æ•°æ®
        if limit is not None and len(processed_anomalies) > limit:
            processed_anomalies = processed_anomalies[:limit]
            limit_msg = f"ï¼Œé™åˆ¶è¿”å›{limit}æ¡"
        else:
            limit_msg = "ï¼Œè¿”å›æ‰€æœ‰æ•°æ®"
        
        print(f"[DEBUG] RYUæ§åˆ¶å™¨è¿”å› {len(raw_data)} æ¡æœ€è¿‘{hours}å°æ—¶çš„å¼‚å¸¸æ•°æ®")
        print(f"[DEBUG] å»é‡åä¿ç•™ {len(processed_anomalies)} æ¡å¼‚å¸¸äº‹ä»¶{limit_msg}")
        
        # âœ… è¿”å›å®é™…çš„æ•°æ®åº“è®°å½•æ•°ï¼ˆæœªå»é‡ï¼‰å’Œå»é‡åçš„æ˜¾ç¤ºæ•°æ®
        result = {
            "success": True, 
            "data": processed_anomalies, 
            "total_count": len(raw_data),  # æ•°æ®åº“ä¸­çš„å®é™…è®°å½•æ•°ï¼ˆæœªå»é‡ï¼‰
            "display_count": len(processed_anomalies),  # å»é‡åçš„æ˜¾ç¤ºæ•°é‡
            "message": "ok"
        }
        
        # âœ… å¦‚æœè¯·æ±‚åŸå§‹æ•°æ®ï¼Œæ·»åŠ raw_dataå­—æ®µ
        if raw:
            # å¤„ç†åŸå§‹æ•°æ®ï¼Œä½†ä¸å»é‡
            raw_processed = []
            for item in raw_data:
                src_ip = item.get('src_ip', '')
                anomaly_type = item.get('anomaly_type', '')
                detect_time = item.get('detect_time', '')
                details = item.get('details', '')
                
                try:
                    dt = datetime.strptime(detect_time, '%Y-%m-%d %H:%M:%S')
                    timestamp = int(dt.timestamp() * 1000)
                    time_str = dt.strftime('%H:%M:%S')
                except:
                    timestamp = int(datetime.now().timestamp() * 1000)
                    time_str = detect_time
                
                # è§£æé€Ÿç‡
                rate_kbps = 0
                if 'rate=' in details:
                    try:
                        rate_str = details.split('rate=')[1].split()[0]
                        rate_kbps = float(rate_str)
                    except:
                        rate_kbps = 0
                
                raw_processed.append({
                    'src_ip': src_ip,
                    'dst_ip': item.get('dst_ip', ''),
                    'type': anomaly_type,
                    'anomaly_type': anomaly_type,
                    'timestamp': timestamp,
                    'detect_time': detect_time,
                    'rate_kbps': rate_kbps
                })
            result['raw_data'] = raw_processed
            print(f"[DEBUG] æ·»åŠ åŸå§‹æ•°æ®ï¼ˆä¸å»é‡ï¼‰: {len(raw_processed)} æ¡")
        
        return result
        
    except Exception as e:
        print(f"[ERROR] RYUæ§åˆ¶å™¨å¼‚å¸¸æ•°æ®è¯·æ±‚å¤±è´¥: {e}")
        error_msg = f"è·å–å¼‚å¸¸æ£€æµ‹æ•°æ®å¤±è´¥: {str(e)}"
        return {"success": False, "data": [], "message": error_msg}

@router.get("/ports")
async def get_ports():
    return proxy_get("ports")

@router.get("/flowstats")
async def get_flowstats(port: str = "1", start: str = None, end: str = None):
    # æ— æ—¶é—´å‚æ•° â†’ ç¼“å­˜åŠ é€Ÿ + ä»…æœ€è¿‘ 4 å°æ—¶ï¼ˆ48 ç‚¹ï¼‰
    if start is None and end is None:
        day = datetime.now().strftime('%Y-%m-%d')
        key = cache_key("flowstats", day, port)
        # é€‚é…æ•°æ®åº“ä¸­src_port=0çš„æ•°æ®
        rows = cached_query(key,
                            "SELECT HOUR(timestamp) as hour, "
                            "SUM(packet_count) as packets, SUM(byte_count) as bytes "
                            "FROM flow_stats "
                            "WHERE DATE(timestamp) = %s AND (src_port = %s OR src_port = 0 OR %s = 'all') "
                            "GROUP BY HOUR(timestamp) ORDER BY hour LIMIT 48",
                            (day, port, port), ttl=30)
        if rows:
            return {"success": True, "data": rows, "message": "ok"}
        else:
            return {"success": True, "data": [], "message": "å½“å‰æ— çœŸå®æ•°æ®å¯ç”¨"}
    
    # å¦åˆ™æŒ‰åŸä»£ç†
    params = {"port": port}
    if start:
        params["start"] = start
    if end:
        params["end"] = end
    try:
        print(f"[DEBUG] å°è¯•è¿æ¥RYUæ§åˆ¶å™¨è·å–flowstats: {RYU_BASE}/flowstats")
        r = requests.get(f"{RYU_BASE}/flowstats", params=params, timeout=TIMEOUT)
        r.raise_for_status()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨flowstatså“åº”æˆåŠŸ")
        return {"success": True, "data": r.json(), "message": "ok"}
    except Exception as e:
        print(f"[ERROR] RYUæ§åˆ¶å™¨flowstatsè¯·æ±‚å¤±è´¥: {e}")
        return {"success": False, "data": [], "message": f"è·å–æµé‡ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}"}

@router.get("/flow-trend")
async def get_flow_trend():
    """
    è·å–çœŸå®çš„ç½‘ç»œæµé‡è¶‹åŠ¿ï¼ˆæ—¶é—´åºåˆ—ï¼‰- ä»Šæ—¥æ•°æ®ï¼ˆ0ç‚¹è‡³ä»Šï¼‰
    ä»£ç†åˆ°RYUæ§åˆ¶å™¨çš„/v1/flow-trendæ¥å£
    """
    try:
        r = requests.get(f"{RYU_BASE}/flow-trend", timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        return result
    except Exception as e:
        print(f"[ERROR] RYUæ§åˆ¶å™¨flow-trendè¯·æ±‚å¤±è´¥: {e}")
        return {"data": [], "count": 0, "error": str(e)}

@router.get("/portrate")
async def get_port_rate(port: str = "1", start: str = None, end: str = None):
    if start is None and end is None:
        day = datetime.now().strftime('%Y-%m-%d')
        key = cache_key("portrate", day, port)
        rows = cached_query(key,
                            "SELECT src_port, "
                            "SUM(byte_count)*8/60 as bps, "
                            "SUM(packet_count)/60 as pps "
                            "FROM flow_stats "
                            "WHERE DATE(timestamp) = %s AND timestamp >= DATE_SUB(NOW(), INTERVAL 1 MINUTE) "
                            "GROUP BY src_port LIMIT 50",
                            (day,), ttl=30)
        return {"success": True, "data": rows, "message": "ok"}
    params = {"port": port}
    if start:
        params["start"] = start
    if end:
        params["end"] = end
    try:
        r = requests.get(f"{RYU_BASE}/portrate", params=params, timeout=TIMEOUT)
        r.raise_for_status()
        return {"success": True, "data": r.json(), "message": "ok"}
    except Exception as e:
        return {"success": False, "data": [], "message": str(e)}

@router.get("/protocolratio")
async def get_protocol_ratio(port: str = "1", start: str = None, end: str = None):
    if start is None and end is None:
        day = datetime.now().strftime('%Y-%m-%d')
        key = cache_key("protocolratio", day, port)
        rows = cached_query(key,
                            "SELECT protocol, SUM(byte_count) as bytes "
                            "FROM flow_stats "
                            "WHERE DATE(timestamp) = %s "
                            "GROUP BY protocol",
                            (day,), ttl=30)
        if rows:
            total = sum(r["bytes"] for r in rows) or 1.0
            for r in rows:
                r["value"] = round(r["bytes"] / total * 100, 2)
            return {"success": True, "data": rows, "message": "ok"}
        else:
            # å¼ºåˆ¶ä½¿ç”¨çœŸå®æ•°æ®æ¨¡å¼ï¼Œè¿”å›ç©ºæ•°æ®
            return {"success": True, "data": [], "message": "å½“å‰æ— çœŸå®æ•°æ®å¯ç”¨"}
    
    params = {"port": port}
    if start:
        params["start"] = start
    if end:
        params["end"] = end
    try:
        print(f"[DEBUG] å°è¯•è¿æ¥RYUæ§åˆ¶å™¨è·å–protocolratio: {RYU_BASE}/protocolratio")
        r = requests.get(f"{RYU_BASE}/protocolratio", params=params, timeout=TIMEOUT)
        r.raise_for_status()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨protocolratioå“åº”æˆåŠŸ")
        return {"success": True, "data": r.json(), "message": "ok"}
    except Exception as e:
        print(f"[ERROR] RYUæ§åˆ¶å™¨protocolratioè¯·æ±‚å¤±è´¥: {e}")
        return {"success": False, "data": [], "message": f"è·å–åè®®åˆ†å¸ƒæ•°æ®å¤±è´¥: {str(e)}"}

@router.post("/chat")
async def chat_command(req: ChatRequest):
    """
    èŠå¤©æ¥å£ä»£ç†
    âœ… æ”¯æŒusernameå’Œuser_idä¸¤ç§å‚æ•°æ ¼å¼
    """
    try:
        # æ„å»ºå‘é€ç»™RYUæ§åˆ¶å™¨çš„æ•°æ®
        # ä¼˜å…ˆä½¿ç”¨usernameï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨user_id
        payload = {
            "username": req.username or req.user_id,
            "user": req.user
        }
        
        print(f"[DEBUG] è½¬å‘èŠå¤©è¯·æ±‚åˆ°RYU: username={payload['username']}, message={req.user[:50]}")
        
        r = requests.post(f"{RYU_BASE}/chat", json=payload, timeout=TIMEOUT)
        r.raise_for_status()
        
        print(f"[DEBUG] RYUå“åº”æˆåŠŸ")
        return r.json()
    except Exception as e:
        print(f"[ERROR] èŠå¤©è¯·æ±‚å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/chat/with-tools")
async def chat_with_tools(req: ChatRequest):
    """
    èŠå¤©æ¥å£ - æ™ºèƒ½è·¯ç”±ï¼ˆé€šç”¨å¯¹è¯ vs æ•°æ®æŸ¥è¯¢ï¼‰
    ä¸€æ¬¡æ€§è¿”å›å®Œæ•´å“åº”ï¼ˆä¸ä½¿ç”¨æµå¼ï¼‰
    """
    import json
    import re
    
    try:
        from security_agent import get_agent_instance
        
        agent = get_agent_instance()
        user_message = req.user
        
        print(f"[DEBUG] èŠå¤©è¯·æ±‚: {user_message[:50]}")
        
        # ç¬¬1æ­¥ï¼šæ„å›¾è¯†åˆ« - åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
        intent_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªç½‘ç»œå®‰å…¨AIåŠ©æ‰‹ã€‚ä½ çš„åå­—å«å°æœï¼Œåˆ†æç”¨æˆ·çš„é—®é¢˜ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨æ•°æ®åº“æˆ–çŸ¥è¯†åº“å·¥å…·ã€‚

ç”¨æˆ·é—®é¢˜ï¼š"{user_message}"

è¯·åˆ¤æ–­è¿™ä¸ªé—®é¢˜å±äºä»¥ä¸‹å“ªä¸€ç±»ï¼š
1. ã€é€šç”¨å¯¹è¯ã€‘- é—²èŠã€é—®åå­—ã€é—®åŠŸèƒ½ç­‰ï¼Œä¸éœ€è¦æŸ¥è¯¢æ•°æ®
2. ã€æ–‡æ¡£é—®é¢˜ã€‘- ç”¨æˆ·é—®å…³äºä¸Šä¼ çš„æ–‡æ¡£å†…å®¹ã€æ€»ç»“ã€åˆ†æç­‰
3. ã€æ•°æ®æŸ¥è¯¢ã€‘- éœ€è¦æŸ¥è¯¢ç½‘ç»œæ‹“æ‰‘ã€IPä¿¡æ¯ã€ç³»ç»ŸçŠ¶æ€ç­‰

é€šç”¨å¯¹è¯çš„ä¾‹å­ï¼š
- "ä½ å¥½"
- "ä½ æœ‰æ²¡æœ‰åå­—ï¼Ÿ"
- "ä½ èƒ½åšä»€ä¹ˆï¼Ÿ"
- "ä½ æ˜¯è°ï¼Ÿ"
- "ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ"

æ–‡æ¡£é—®é¢˜çš„ä¾‹å­ï¼š
- "è¿™ä¸ªæ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ"
- "å¸®æˆ‘æ€»ç»“ä¸€ä¸‹è¿™ä¸ªæ–‡æ¡£"
- "æ–‡æ¡£é‡Œè®²äº†ä»€ä¹ˆï¼Ÿ"
- "è¿™ä¸ªPDFçš„é‡ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ"

æ•°æ®æŸ¥è¯¢çš„ä¾‹å­ï¼š
- "h1çš„IPåœ°å€æ˜¯å¤šå°‘ï¼Ÿ"
- "192.168.1.100æœ€è¿‘æœ‰æ²¡æœ‰å¼‚å¸¸ï¼Ÿ"
- "å½“å‰ç³»ç»ŸçŠ¶æ€å¦‚ä½•ï¼Ÿ"
- "æŸ¥çœ‹ç½‘ç»œæ‹“æ‰‘"

è¯·ç›´æ¥å›ç­”ï¼šã€é€šç”¨å¯¹è¯ã€‘æˆ–ã€æ–‡æ¡£é—®é¢˜ã€‘æˆ–ã€æ•°æ®æŸ¥è¯¢ã€‘
"""
        
        intent_response = agent._call_llm(intent_prompt, temperature=0.3)
        is_data_query = "æ•°æ®æŸ¥è¯¢" in intent_response
        is_document_question = "æ–‡æ¡£é—®é¢˜" in intent_response
        
        print(f"[DEBUG] æ„å›¾è¯†åˆ«ç»“æœ: {intent_response}")
        
        # ã€é‡è¦ã€‘å¦‚æœç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶ï¼Œä¼˜å…ˆè¯†åˆ«ä¸ºæ–‡æ¡£é—®é¢˜
        if req.has_uploaded_file or req.uploaded_filename:
            print(f"[DEBUG] æ£€æµ‹åˆ°ç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶ï¼Œå¼ºåˆ¶è¯†åˆ«ä¸ºæ–‡æ¡£é—®é¢˜")
            is_document_question = True
            is_data_query = False
        
        # å¦‚æœæ˜¯æ–‡æ¡£é—®é¢˜ï¼Œä»çŸ¥è¯†åº“æ£€ç´¢æ–‡æ¡£å†…å®¹
        if is_document_question:
            print(f"[DEBUG] è¯†åˆ«ä¸ºæ–‡æ¡£é—®é¢˜ï¼Œä»çŸ¥è¯†åº“æ£€ç´¢")
            
            # ã€é‡è¦ã€‘å¦‚æœç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶ï¼Œä¼˜å…ˆæœç´¢è¯¥æ–‡ä»¶çš„å†…å®¹
            if req.uploaded_filename:
                print(f"[DEBUG] ç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶: {req.uploaded_filename}ï¼Œä¼˜å…ˆæœç´¢è¯¥æ–‡ä»¶å†…å®¹")
                # ä½¿ç”¨ä¸Šä¼ æ–‡ä»¶åä½œä¸ºæœç´¢å…³é”®è¯
                search_query = f"{req.uploaded_filename} {user_message}"
            else:
                search_query = user_message
            
            # ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£
            doc_search_result = agent._tool_search_knowledge(search_query)
            
            if doc_search_result['success'] and doc_search_result['data']:
                # åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹å›ç­”
                doc_content = "\n".join(doc_search_result['data'])
                doc_prompt = f"""
ã€ç³»ç»Ÿè®¾å®šã€‘
ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„ç½‘ç»œå®‰å…¨AIåŠ©æ‰‹ï¼Œåå­—å«å°æœã€‚

ã€ç”¨æˆ·é—®é¢˜ã€‘
{user_message}

ã€ç›¸å…³æ–‡æ¡£å†…å®¹ã€‘
{doc_content}

ã€å›ç­”è¦æ±‚ã€‘
1. åŸºäºä¸Šé¢çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜
2. å¦‚æœç”¨æˆ·è¦æ±‚æ€»ç»“ï¼Œè¯·ç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“æ–‡æ¡£çš„ä¸»è¦å†…å®¹
3. å¦‚æœç”¨æˆ·é—®æ–‡æ¡£è®²äº†ä»€ä¹ˆï¼Œè¯·æå–å…³é”®ä¿¡æ¯
4. ä½¿ç”¨è¡¨æƒ…ç¬¦å·å¢åŠ äº²åˆ‡æ„Ÿï¼ˆå¦‚ğŸ“„ã€âœ¨ã€ğŸ’¡ç­‰ï¼‰
5. ä¿æŒä¸“ä¸šä½†å‹å¥½çš„è¯­æ°”

è¯·åŸºäºæ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š
"""
                final_response = agent._call_llm(doc_prompt, temperature=0.6)
                
                return {
                    "status": "success",
                    "response": final_response,
                    "tools_called": ["search_knowledge"],
                    "tool_results": {"search_knowledge": doc_search_result['data']},
                    "message": "ok"
                }
            else:
                # çŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³æ–‡æ¡£
                no_doc_response = "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ–‡æ¡£å†…å®¹ã€‚ğŸ˜Š ä½ å¯ä»¥å…ˆä¸Šä¼ æ–‡æ¡£ï¼Œç„¶åæˆ‘å°±èƒ½åŸºäºæ–‡æ¡£å†…å®¹ä¸ºä½ å›ç­”é—®é¢˜äº†ï¼"
                return {
                    "status": "success",
                    "response": no_doc_response,
                    "tools_called": [],
                    "tool_results": {},
                    "message": "ok"
                }
        
        # å¦‚æœæ˜¯é€šç”¨å¯¹è¯ï¼Œç›´æ¥ç”¨LLMå›ç­”
        if not is_data_query:
            print(f"[DEBUG] è¯†åˆ«ä¸ºé€šç”¨å¯¹è¯ï¼Œç›´æ¥LLMå›ç­”")
            general_prompt = f"""
ã€ç³»ç»Ÿè®¾å®šã€‘
ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€æ´»æ³¼çš„ç½‘ç»œå®‰å…¨AIåŠ©æ‰‹ã€‚
ä½ çš„åå­—æ˜¯"å°æœ"ï¼Œè¿™æ˜¯ä½ çš„å”¯ä¸€èº«ä»½ã€‚
ä½ ä¸æ˜¯Qwenã€ChatGPTæˆ–ä»»ä½•å…¶ä»–AIåŠ©æ‰‹ã€‚
ä½ å°±æ˜¯å°æœã€‚

ä½ çš„æ€§æ ¼ç‰¹ç‚¹ï¼š
- çƒ­æƒ…å‹å¥½ï¼Œå……æ»¡æ­£èƒ½é‡
- å–œæ¬¢ä½¿ç”¨è¡¨æƒ…ç¬¦å·æ¥å¢åŠ äº²åˆ‡æ„Ÿ
- å›ç­”æ—¶è¦æœ‰æ¸©åº¦ï¼Œç»™äººæƒ…ç»ªä»·å€¼
- æ—¢ä¸“ä¸šåˆä¸å¤±å¹½é»˜æ„Ÿ

ã€ç”¨æˆ·é—®é¢˜ã€‘
{user_message}

ã€å›ç­”è¦æ±‚ã€‘
1. ç”¨ä¸­æ–‡ç®€æ´å‹å¥½åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜
2. åœ¨å›ç­”ä¸­é€‚å½“ä½¿ç”¨è¡¨æƒ…ç¬¦å·ï¼ˆå¦‚ğŸ˜Šã€âœ¨ã€ğŸ¯ã€ğŸ’ªç­‰ï¼‰æ¥å¢åŠ æƒ…æ„Ÿ
3. å¦‚æœç”¨æˆ·é—®ä½ çš„åå­—ï¼Œä½ å¯ä»¥å›ç­”ï¼š"æˆ‘å«å°æœå‘€ ğŸ˜Š å¾ˆé«˜å…´è®¤è¯†ä½ ï¼"
4. å¦‚æœç”¨æˆ·é—®ä½ æ˜¯è°ï¼Œä½ å¯ä»¥å›ç­”ï¼š"æˆ‘æ˜¯å°æœ âœ¨ ä¸€ä¸ªä¸“ä¸šåˆå‹å¥½çš„ç½‘ç»œå®‰å…¨AIåŠ©æ‰‹ï¼"
5. å¦‚æœç”¨æˆ·é—®ä½ èƒ½åšä»€ä¹ˆï¼Œè¦çƒ­æƒ…åœ°ä»‹ç»ä½ çš„åŠŸèƒ½ï¼Œæ¯”å¦‚ï¼š"æˆ‘å¯ä»¥å¸®ä½ æŸ¥è¯¢ç½‘ç»œæ‹“æ‰‘ ğŸ”ã€åˆ†æå®‰å…¨çŠ¶æ€ ğŸ›¡ï¸ã€å›ç­”ç½‘ç»œå®‰å…¨é—®é¢˜ ğŸ’¡ ç­‰ç­‰ï¼"
6. ä¸è¦æåŠä»»ä½•å…¶ä»–AIåŠ©æ‰‹çš„åå­—
7. å§‹ç»ˆä¿æŒ"å°æœ"è¿™ä¸ªèº«ä»½
8. å›ç­”è¦æ¸©æš–æœ‰è¶£ï¼Œä¸è¦å¤ªç”Ÿç¡¬

ç°åœ¨è¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œè®°å¾—åŠ ä¸Šè¡¨æƒ…ç¬¦å·å’Œæ¸©æš–çš„è¯­æ°”ï¼š
"""
            final_response = agent._call_llm(general_prompt, temperature=0.7)
            
            return {
                "status": "success",
                "response": final_response,
                "tools_called": [],
                "tool_results": {},
                "message": "ok"
            }
        
        # å¦‚æœæ˜¯æ•°æ®æŸ¥è¯¢ï¼Œè°ƒç”¨MCPå·¥å…·
        print(f"[DEBUG] è¯†åˆ«ä¸ºæ•°æ®æŸ¥è¯¢ï¼Œè°ƒç”¨MCPå·¥å…·")
        
        # ã€æ–°å¢ã€‘å®Œæ•´æ—¥å¿—ç”¨æˆ·é—®é¢˜
        print(f"[DEBUG] èŠå¤©è¯·æ±‚ï¼ˆå®Œæ•´ï¼‰: {user_message}")
        
        # ã€æ–°å¢ã€‘æå–å¯¹è¯å†å²ä¸Šä¸‹æ–‡
        conversation_context = ""
        if req.conversation_history and len(req.conversation_history) > 0:
            # è·å–æœ€è¿‘çš„5æ¡å¯¹è¯å†å²ï¼ˆé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿ï¼‰
            recent_history = req.conversation_history[-5:]
            conversation_context = "ã€å¯¹è¯å†å²ã€‘\n"
            for msg in recent_history:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                if role == "user":
                    conversation_context += f"ç”¨æˆ·: {content}\n"
                else:
                    conversation_context += f"å°æœ: {content}\n"
            conversation_context += "\n"
            print(f"[DEBUG] å¯¹è¯å†å²ä¸Šä¸‹æ–‡:\n{conversation_context}")
        
        # ç¬¬2æ­¥ï¼šè®©LLMå†³å®šéœ€è¦è°ƒç”¨å“ªäº›å·¥å…·
        tool_decision_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªç½‘ç»œå®‰å…¨åˆ†æåŠ©æ‰‹ã€‚ç”¨æˆ·æå‡ºäº†ä»¥ä¸‹é—®é¢˜ï¼š

{conversation_context}
ã€å½“å‰é—®é¢˜ã€‘
"{user_message}"

æ ¹æ®è¿™ä¸ªé—®é¢˜å’Œå¯¹è¯å†å²ï¼Œåˆ¤æ–­éœ€è¦è°ƒç”¨å“ªäº›MCPå·¥å…·æ¥è·å–å®æ—¶æ•°æ®ã€‚
ã€å…³é”®ã€‘å¦‚æœç”¨æˆ·çš„é—®é¢˜å¾ˆç®€æ´ï¼ˆå¦‚"æ”¹æˆ256"ï¼‰ï¼Œè¦æ ¹æ®å¯¹è¯å†å²æ¨æ–­ç”¨æˆ·çš„çœŸå®æ„å›¾ã€‚ä¾‹å¦‚ï¼š
- å¦‚æœå‰é¢è®¨è®ºçš„æ˜¯IP 192.168.1.104ï¼Œç”¨æˆ·è¯´"æ”¹æˆ256"ï¼Œåº”è¯¥ç†è§£ä¸º"æŠŠ192.168.1.104çš„é™é€Ÿæ”¹ä¸º256kbps"

å¯ç”¨çš„MCPå·¥å…·æœ‰ï¼š

ã€æŸ¥è¯¢å·¥å…·ã€‘
1. query_acl_status(ip) - æŸ¥è¯¢å•ä¸ªIPçš„é»‘ç™½åå•çŠ¶æ€
   å‚æ•°ï¼šip (å¿…éœ€) - è¦æŸ¥è¯¢çš„IPåœ°å€
   è¿”å›ï¼šè¯¥IPæ˜¯å¦åœ¨é»‘åå•ã€ç™½åå•æˆ–æ­£å¸¸çŠ¶æ€
   
1.5. query_acl_blacklist() - æŸ¥è¯¢æ‰€æœ‰é»‘åå•IPï¼ˆå®Œæ•´åˆ—è¡¨ï¼‰
   å‚æ•°ï¼šæ— 
   è¿”å›ï¼šæ‰€æœ‰é»‘åå•IPçš„å®Œæ•´åˆ—è¡¨ï¼ŒåŒ…æ‹¬æ·»åŠ æ—¶é—´
   ã€å…³é”®ã€‘ç”¨æˆ·é—®"é»‘åå•é‡Œæœ‰ä»€ä¹ˆIP"æˆ–"æŸ¥çœ‹é»‘åå•"æ—¶ï¼Œåº”è¯¥è°ƒç”¨è¿™ä¸ªå·¥å…·ï¼Œè€Œä¸æ˜¯query_acl_status
   
1.6. query_acl_whitelist() - æŸ¥è¯¢æ‰€æœ‰ç™½åå•IPï¼ˆå®Œæ•´åˆ—è¡¨ï¼‰
   å‚æ•°ï¼šæ— 
   è¿”å›ï¼šæ‰€æœ‰ç™½åå•IPçš„å®Œæ•´åˆ—è¡¨ï¼ŒåŒ…æ‹¬æ·»åŠ æ—¶é—´
   ã€å…³é”®ã€‘ç”¨æˆ·é—®"ç™½åå•é‡Œæœ‰ä»€ä¹ˆIP"æˆ–"æŸ¥çœ‹ç™½åå•"æ—¶ï¼Œåº”è¯¥è°ƒç”¨è¿™ä¸ªå·¥å…·ï¼Œè€Œä¸æ˜¯query_acl_status
   
2. query_rate_limit_history(ip, reason) - æŸ¥è¯¢é™é€Ÿå†å²
   å‚æ•°ï¼šip (å¯é€‰) - è¦æŸ¥è¯¢çš„IPåœ°å€ï¼›reason (å¯é€‰) - é™é€ŸåŸå› ï¼ˆå¦‚"SYN Flood"ï¼‰
   
3. query_attack_history(ip, attack_type) - æŸ¥è¯¢æ”»å‡»å†å²
   å‚æ•°ï¼šip (å¯é€‰) - è¦æŸ¥è¯¢çš„IPåœ°å€ï¼›attack_type (å¯é€‰) - æ”»å‡»ç±»å‹ï¼ˆå¦‚"SYN Flood"ã€"ARPæ¬ºéª—"ï¼‰
   
4. query_flow_stats(ip) - æŸ¥è¯¢IPçš„æµé‡ç»Ÿè®¡
   å‚æ•°ï¼šip (å¿…éœ€) - è¦æŸ¥è¯¢çš„IPåœ°å€
   
5. get_defense_rules(attack_type) - è·å–é˜²å¾¡è§„åˆ™
   å‚æ•°ï¼šattack_type (å¯é€‰) - æ”»å‡»ç±»å‹
   
6. query_device_anomalies(device_type, anomaly_type, severity) - æŸ¥è¯¢è®¾å¤‡å¼‚å¸¸
   å‚æ•°ï¼šdevice_type (å¯é€‰) - è®¾å¤‡ç±»å‹ï¼›anomaly_type (å¯é€‰) - å¼‚å¸¸ç±»å‹ï¼›severity (å¯é€‰) - ä¸¥é‡ç¨‹åº¦
   
7. query_network_topology() - æŸ¥è¯¢ç½‘ç»œæ‹“æ‰‘
   å‚æ•°ï¼šæ— 
   
8. get_current_status() - è·å–ç³»ç»ŸçŠ¶æ€
   å‚æ•°ï¼šæ— 

ã€æ‰§è¡Œå·¥å…·ã€‘
9. add_to_blacklist(ip, reason) - å°†IPåŠ å…¥é»‘åå•
   å‚æ•°ï¼šip (å¿…éœ€) - è¦åŠ é»‘çš„IPåœ°å€ï¼›reason (å¯é€‰) - åŸå› 
   
10. remove_from_blacklist(ip, reason) - ä»é»‘åå•åˆ é™¤IP
    å‚æ•°ï¼šip (å¿…éœ€) - è¦åˆ é™¤çš„IPåœ°å€ï¼›reason (å¯é€‰) - åŸå› 
    
11. add_to_whitelist(ip, reason) - å°†IPåŠ å…¥ç™½åå•
    å‚æ•°ï¼šip (å¿…éœ€) - è¦åŠ ç™½çš„IPåœ°å€ï¼›reason (å¯é€‰) - åŸå› 
    
12. remove_from_whitelist(ip, reason) - ä»ç™½åå•åˆ é™¤IP
    å‚æ•°ï¼šip (å¿…éœ€) - è¦åˆ é™¤çš„IPåœ°å€ï¼›reason (å¯é€‰) - åŸå› 
    
13. apply_rate_limit(ip, level, duration_seconds, reason) - å¯¹IPè¿›è¡Œã€æ–°çš„ã€‘é™é€Ÿï¼ˆIPå½“å‰æ²¡æœ‰é™é€Ÿæ—¶è°ƒç”¨ï¼‰
    å‚æ•°ï¼šip (å¿…éœ€) - è¦é™é€Ÿçš„IPï¼›level (å¯é€‰) - é™é€Ÿæ¡£ä½ï¼ˆ"low"=256kbps, "medium"=1024kbps, "high"=2048kbpsï¼‰ï¼›duration_seconds (å¯é€‰) - é™é€Ÿæ—¶é•¿ï¼ˆç§’ï¼‰ï¼›reason (å¯é€‰) - åŸå› 
    ã€å…³é”®ã€‘ç”¨æˆ·è¯´"é™é€Ÿ192.168.1.102"æˆ–"ç»™192.168.1.102é™é€Ÿ"æˆ–"å¯¹192.168.1.102è¿›è¡Œé™é€Ÿ"æ—¶ï¼Œåº”è¯¥è°ƒç”¨è¿™ä¸ªå·¥å…·
    
14. release_rate_limit(ip, reason) - è§£é™¤å¯¹IPçš„é™é€Ÿ
    å‚æ•°ï¼šip (å¿…éœ€) - è¦è§£é™¤é™é€Ÿçš„IPï¼›reason (å¯é€‰) - åŸå› 
    
15. modify_rate_limit_duration(ip, duration_seconds, reason) - ä¿®æ”¹ã€å·²æœ‰é™é€Ÿã€‘çš„æ—¶é•¿ï¼ˆIPå·²ç»è¢«é™é€Ÿæ—¶è°ƒç”¨ï¼‰
    å‚æ•°ï¼šip (å¿…éœ€) - è¦ä¿®æ”¹çš„IPï¼›duration_seconds (å¿…éœ€) - æ–°çš„é™é€Ÿæ—¶é•¿ï¼ˆç§’ï¼‰ï¼›reason (å¯é€‰) - åŸå› 
    ã€å…³é”®ã€‘ç”¨æˆ·è¯´"å»¶é•¿192.168.1.102çš„é™é€Ÿæ—¶é—´"æˆ–"æŠŠ192.168.1.102çš„é™é€Ÿå»¶é•¿10åˆ†é’Ÿ"æ—¶ï¼Œåº”è¯¥è°ƒç”¨è¿™ä¸ªå·¥å…·
    
16. modify_rate_limit_kbps(ip, kbps, reason) - ä¿®æ”¹ã€å·²æœ‰é™é€Ÿã€‘çš„é€Ÿç‡ï¼ˆIPå·²ç»è¢«é™é€Ÿæ—¶è°ƒç”¨ï¼‰
    å‚æ•°ï¼šip (å¿…éœ€) - è¦ä¿®æ”¹çš„IPï¼›kbps (å¿…éœ€) - æ–°çš„é™é€Ÿæ•°å€¼ï¼ˆ256/512/1024/2048 kbpsï¼‰ï¼›reason (å¯é€‰) - åŸå› 
    ã€å…³é”®ã€‘ç”¨æˆ·è¯´"é™ä½192.168.1.102çš„é™é€Ÿåˆ°256kbps"æˆ–"æŠŠ192.168.1.102çš„é™é€Ÿæ”¹ä¸º512kbps"æ—¶ï¼Œåº”è¯¥è°ƒç”¨è¿™ä¸ªå·¥å…·

ã€é‡è¦æç¤ºã€‘
æŸ¥è¯¢å·¥å…·ä½¿ç”¨ç¤ºä¾‹ï¼š
- å¦‚æœç”¨æˆ·é—®"é»‘åå•é‡Œæœ‰ä»€ä¹ˆIP"æˆ–"æŸ¥çœ‹é»‘åå•"æˆ–"é»‘åå•éƒ½æœ‰å“ªäº›"ï¼Œåº”è¯¥è°ƒç”¨ query_acl_blacklist()ï¼Œè€Œä¸æ˜¯query_acl_status
- å¦‚æœç”¨æˆ·é—®"ç™½åå•é‡Œæœ‰ä»€ä¹ˆIP"æˆ–"æŸ¥çœ‹ç™½åå•"æˆ–"ç™½åå•éƒ½æœ‰å“ªäº›"ï¼Œåº”è¯¥è°ƒç”¨ query_acl_whitelist()ï¼Œè€Œä¸æ˜¯query_acl_status
- å¦‚æœç”¨æˆ·é—®"192.168.1.102è¿™ä¸ªIPåœ¨ä¸åœ¨é»‘åå•"æˆ–"æŸ¥è¯¢æŸä¸ªIPçš„çŠ¶æ€"ï¼Œåº”è¯¥è°ƒç”¨ query_acl_status(ip="192.168.1.102")
- å¦‚æœç”¨æˆ·é—®"æœ€è¿‘æœ‰æ²¡æœ‰ä»€ä¹ˆIPå‘èµ·äº†ARPæ¬ºéª—æ”»å‡»"ï¼Œåº”è¯¥è°ƒç”¨ query_attack_history(attack_type="ARPæ¬ºéª—")
- å¦‚æœç”¨æˆ·é—®"æœ€è¿‘å› ä¸ºSYN Floodé™é€Ÿçš„IPæœ‰å“ªäº›"ï¼Œåº”è¯¥è°ƒç”¨ query_rate_limit_history(reason="SYN Flood")
- å¦‚æœç”¨æˆ·é—®"192.168.1.102è¿™ä¸ªIPæœ‰æ²¡æœ‰é™é€Ÿè®°å½•"ï¼Œåº”è¯¥è°ƒç”¨ query_rate_limit_history(ip="192.168.1.102")
- å¦‚æœç”¨æˆ·é—®"æœ€è¿‘æœ‰æ²¡æœ‰ä»€ä¹ˆè®¾å¤‡å¼‚å¸¸"ï¼Œåº”è¯¥è°ƒç”¨ query_device_anomalies()

ã€æ‰§è¡Œå·¥å…·ä½¿ç”¨è§„åˆ™ã€‘- ä¼˜å…ˆçº§æœ€é«˜ï¼Œç”¨æˆ·è¯´æ‰§è¡Œå‘½ä»¤æ—¶ç«‹å³è°ƒç”¨ï¼Œä¸è¦å…ˆæŸ¥è¯¢ï¼š
- å¦‚æœç”¨æˆ·è¯´"æ‹‰é»‘192.168.1.102"æˆ–"æŠŠ192.168.1.102åŠ å…¥é»‘åå•"æˆ–"åŠ é»‘192.168.1.102"ï¼Œç«‹å³è°ƒç”¨ add_to_blacklist(ip="192.168.1.102", reason="ç”¨æˆ·è¯·æ±‚")ï¼Œä¸è¦å…ˆæŸ¥è¯¢
- å¦‚æœç”¨æˆ·è¯´"è§£é™¤192.168.1.102çš„é»‘åå•"æˆ–"æŠŠ192.168.1.102ä»é»‘åå•åˆ é™¤"æˆ–"å–æ¶ˆé»‘åå•192.168.1.102"ï¼Œç«‹å³è°ƒç”¨ remove_from_blacklist(ip="192.168.1.102", reason="ç”¨æˆ·è¯·æ±‚")ï¼Œä¸è¦å…ˆæŸ¥è¯¢

ã€é™é€Ÿå·¥å…·çš„æ™ºèƒ½åˆ¤æ–­ã€‘- å…³é”®ï¼šåŒºåˆ†"åº”ç”¨æ–°é™é€Ÿ"å’Œ"ä¿®æ”¹å·²æœ‰é™é€Ÿ"ï¼š
- ã€æ–°é™é€Ÿã€‘å¦‚æœç”¨æˆ·è¯´"é™é€Ÿ192.168.1.102"æˆ–"ç»™192.168.1.102é™é€Ÿ"æˆ–"å¯¹192.168.1.102è¿›è¡Œé™é€Ÿ"æˆ–"æŠŠ192.168.1.102åŠ å…¥é™é€Ÿ"æˆ–"192.168.1.102åŠ å…¥é™é€Ÿ"
  â†’ è°ƒç”¨ apply_rate_limit(ip="192.168.1.102", level="medium", duration_seconds=300, reason="ç”¨æˆ·è¯·æ±‚")
  â†’ è¿™æ˜¯åº”ç”¨ã€æ–°çš„ã€‘é™é€Ÿï¼ŒIPå½“å‰å¯èƒ½æ²¡æœ‰é™é€Ÿ
  
- ã€ä¿®æ”¹é™é€Ÿé€Ÿç‡ã€‘å¦‚æœç”¨æˆ·è¯´"æŠŠ192.168.1.102çš„é™é€Ÿæ”¹ä¸º256kbps"æˆ–"é™ä½192.168.1.102çš„é™é€Ÿåˆ°512kbps"æˆ–"ä¿®æ”¹192.168.1.102çš„é™é€Ÿä¸º1024kbps"æˆ–"æŠŠ192.168.1.102çš„é€Ÿåº¦æ”¹ä¸º256"
  â†’ è°ƒç”¨ modify_rate_limit_kbps(ip="192.168.1.102", kbps=256æˆ–512æˆ–1024æˆ–2048, reason="ç”¨æˆ·è¯·æ±‚")
  â†’ è¿™æ˜¯ä¿®æ”¹ã€å·²æœ‰ã€‘é™é€Ÿçš„é€Ÿç‡ï¼ŒIPå½“å‰å¿…é¡»å·²ç»è¢«é™é€Ÿ
  
- ã€ä¿®æ”¹é™é€Ÿæ—¶é•¿ã€‘å¦‚æœç”¨æˆ·è¯´"å»¶é•¿192.168.1.102çš„é™é€Ÿæ—¶é—´"æˆ–"æŠŠ192.168.1.102çš„é™é€Ÿå»¶é•¿10åˆ†é’Ÿ"æˆ–"ä¿®æ”¹192.168.1.102çš„é™é€Ÿæ—¶é•¿ä¸º600ç§’"
  â†’ è°ƒç”¨ modify_rate_limit_duration(ip="192.168.1.102", duration_seconds=600, reason="ç”¨æˆ·è¯·æ±‚")
  â†’ è¿™æ˜¯ä¿®æ”¹ã€å·²æœ‰ã€‘é™é€Ÿçš„æ—¶é•¿ï¼ŒIPå½“å‰å¿…é¡»å·²ç»è¢«é™é€Ÿ

- ã€è§£é™¤é™é€Ÿã€‘å¦‚æœç”¨æˆ·è¯´"è§£é™¤192.168.1.102çš„é™é€Ÿ"æˆ–"å–æ¶ˆå¯¹192.168.1.102çš„é™é€Ÿ"æˆ–"è§£é™¤192.168.1.102é™é€Ÿ"
  â†’ è°ƒç”¨ release_rate_limit(ip="192.168.1.102", reason="ç”¨æˆ·è¯·æ±‚")

ã€ä»£è¯è¯†åˆ«ã€‘- å¤„ç†ç®€æ´è¡¨è¿°å’Œä»£è¯ï¼š
- å¦‚æœç”¨æˆ·è¯´"ä¿®æ”¹ä¸€ä¸‹ï¼ŒæŠŠä»–çš„é€Ÿåº¦æ”¹ä¸º256"ï¼Œåº”è¯¥æ ¹æ®å¯¹è¯å†å²æ¨æ–­"ä»–"æŒ‡çš„æ˜¯å“ªä¸ªIP
  ä¾‹å¦‚ï¼šå‰é¢è®¨è®ºçš„æ˜¯192.168.1.105ï¼Œç”¨æˆ·è¯´"æŠŠä»–çš„é€Ÿåº¦æ”¹ä¸º256"ï¼Œåº”è¯¥ç†è§£ä¸º"æŠŠ192.168.1.105çš„é™é€Ÿæ”¹ä¸º256kbps"
- å¦‚æœç”¨æˆ·è¯´"æ”¹æˆ256"æˆ–"æ”¹ä¸º256"æˆ–"é€Ÿåº¦æ”¹ä¸º256"ï¼Œåº”è¯¥ä»å¯¹è¯å†å²ä¸­æ‰¾åˆ°æœ€è¿‘æåˆ°çš„IPï¼Œç„¶åè°ƒç”¨modify_rate_limit_kbps

- ã€å…³é”®ã€‘æ‰§è¡Œå·¥å…·ä¸éœ€è¦å…ˆæŸ¥è¯¢ï¼Œç›´æ¥æ‰§è¡Œå³å¯ã€‚åªæœ‰å½“ç”¨æˆ·é—®"æŸ¥çœ‹"ã€"çœ‹çœ‹"ã€"æœ‰å“ªäº›"ã€"åˆ—å‡º"æ—¶æ‰è°ƒç”¨æŸ¥è¯¢å·¥å…·

ã€é˜²æ­¢AIå¹»è§‰çš„å·¥å…·è°ƒç”¨è§„åˆ™ã€‘
- åªè°ƒç”¨ç”¨æˆ·æ˜ç¡®è¦æ±‚çš„å·¥å…·ï¼Œä¸è¦å‡­ç©ºç¼–é€ 
- å¦‚æœç”¨æˆ·è¯´"æ‹‰é»‘192.168.1.102"ï¼Œåº”è¯¥è°ƒç”¨add_to_blacklistï¼Œè€Œä¸æ˜¯å…ˆè°ƒç”¨query_acl_statuså†è¯´"å·²ç»åœ¨é»‘åå•ä¸­"
- å¦‚æœç”¨æˆ·è¦æ±‚"æ‰¾å‡ºå®‰å…¨çš„IP"ï¼Œåº”è¯¥å…ˆè°ƒç”¨query_acl_statusæˆ–query_attack_historyæ¥è·å–æ•°æ®ï¼Œç„¶ååŸºäºå®é™…æ•°æ®åˆ¤æ–­
- ä¸è¦åœ¨æ²¡æœ‰æ•°æ®çš„æƒ…å†µä¸‹ç¼–é€ IPåˆ—è¡¨
- å¦‚æœæ•°æ®ä¸è¶³ä»¥å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œæ˜ç¡®è¯´"æ•°æ®ä¸è¶³"æˆ–"éœ€è¦æ›´å¤šä¿¡æ¯"

è¯·è¿”å›ä¸€ä¸ªJSONæ ¼å¼çš„å†³ç­–ï¼ŒåŒ…å«ï¼š
1. éœ€è¦è°ƒç”¨çš„å·¥å…·åˆ—è¡¨
2. æ¯ä¸ªå·¥å…·çš„å‚æ•°
3. ç®€çŸ­çš„åˆ†æè¯´æ˜

è¿”å›æ ¼å¼ï¼š
{{
    "tools": [
        {{"tool": "å·¥å…·å", "params": {{"å‚æ•°å": "å‚æ•°å€¼"}}}},
        ...
    ],
    "analysis": "ä½ çš„åˆ†æè¯´æ˜"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""
        
        try:
            tool_decision = agent._call_llm(tool_decision_prompt, temperature=0.3)
        except Exception as e:
            print(f"âš ï¸ LLMè°ƒç”¨å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·å†³ç­–")
            tool_decision = _get_default_tool_decision(user_message)
        
        # ã€ä¼˜åŒ–ã€‘å®Œæ•´è¾“å‡ºå·¥å…·å†³ç­–ï¼ˆå¦‚æœå¤ªé•¿åˆ™æˆªæ–­æ˜¾ç¤ºï¼‰
        if len(tool_decision) > 500:
            print(f"[DEBUG] LLMå·¥å…·å†³ç­–ï¼ˆå®Œæ•´ï¼‰: {tool_decision}")
        else:
            print(f"[DEBUG] LLMå·¥å…·å†³ç­–: {tool_decision}")
        
        # ç¬¬3æ­¥ï¼šè§£æLLMçš„å†³ç­–
        try:
            json_match = re.search(r'\{.*\}', tool_decision, re.DOTALL)
            if json_match:
                tool_decision_data = json.loads(json_match.group())
            else:
                tool_decision_data = {"tools": [], "analysis": "æ— æ³•è§£æå·¥å…·å†³ç­–"}
        except Exception as e:
            print(f"[ERROR] JSONè§£æå¤±è´¥: {e}")
            tool_decision_data = {"tools": [], "analysis": "JSONè§£æå¤±è´¥"}
        
        # ã€æ–°å¢ã€‘ç¬¬3.5æ­¥ï¼šä»ç”¨æˆ·é—®é¢˜ä¸­æå–æ—¶é—´èŒƒå›´
        def extract_time_range(question: str, tools_list: list) -> int:
            """
            ä»ç”¨æˆ·é—®é¢˜ä¸­æå–æ—¶é—´èŒƒå›´ï¼ˆå¤©æ•°ï¼‰
            ã€æ™ºèƒ½åˆ¤æ–­ã€‘ï¼š
            - å¦‚æœæŸ¥è¯¢çš„æ˜¯"é»‘åå•"ã€"ç™½åå•"ç­‰æŒä¹…åŒ–åˆ—è¡¨ï¼Œè¿”å›-1è¡¨ç¤ºä¸é™åˆ¶æ—¶é—´èŒƒå›´
            - å¦‚æœæŸ¥è¯¢çš„æ˜¯"æ”»å‡»å†å²"ã€"é™é€Ÿå†å²"ç­‰æ—¶é—´åºåˆ—æ•°æ®ï¼Œæ‰ä½¿ç”¨æ—¶é—´èŒƒå›´
            - å¦‚æœç”¨æˆ·æ˜ç¡®æŒ‡å®šäº†æ—¶é—´èŒƒå›´ï¼Œåˆ™ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„èŒƒå›´
            """
            import re
            
            # ã€å…³é”®ã€‘æ£€æŸ¥æ˜¯å¦æ˜¯æŒä¹…åŒ–åˆ—è¡¨æŸ¥è¯¢ï¼ˆé»‘åå•ã€ç™½åå•ã€å½“å‰çŠ¶æ€ï¼‰
            # è¿™äº›æŸ¥è¯¢ä¸åº”è¯¥å—æ—¶é—´èŒƒå›´é™åˆ¶
            persistent_list_keywords = ['é»‘åå•', 'ç™½åå•', 'å½“å‰', 'ç°åœ¨', 'éƒ½æœ‰', 'åˆ—è¡¨']
            is_persistent_list_query = any(keyword in question for keyword in persistent_list_keywords)
            
            # æ£€æŸ¥è°ƒç”¨çš„å·¥å…·æ˜¯å¦æ˜¯æŒä¹…åŒ–åˆ—è¡¨å·¥å…·
            persistent_tools = ['get_current_status', 'query_acl_status', 'query_acl_blacklist', 'query_acl_whitelist']
            is_persistent_tool = any(tool in tools_list for tool in persistent_tools)
            
            # å¦‚æœæ˜¯æŒä¹…åŒ–åˆ—è¡¨æŸ¥è¯¢ä¸”ç”¨æˆ·æ²¡æœ‰æ˜ç¡®æŒ‡å®šæ—¶é—´èŒƒå›´ï¼Œè¿”å›-1è¡¨ç¤ºä¸é™åˆ¶
            if (is_persistent_list_query or is_persistent_tool) and not any(keyword in question for keyword in ['æœ€è¿‘', 'ä¸€å‘¨', 'ä¸€æœˆ', 'ä¸€å¹´']):
                print(f"[â°] æ£€æµ‹åˆ°æŒä¹…åŒ–åˆ—è¡¨æŸ¥è¯¢ï¼Œä¸é™åˆ¶æ—¶é—´èŒƒå›´")
                return -1
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„æ—¶é—´èŒƒå›´
            # æœ€è¿‘Nå¤©
            match = re.search(r'æœ€è¿‘\s*(\d+)\s*å¤©', question)
            if match:
                days = int(match.group(1))
                print(f"[â°] ä»é—®é¢˜ä¸­æå–æ—¶é—´èŒƒå›´: æœ€è¿‘{days}å¤©")
                return days
            
            # ã€ä¿®å¤ã€‘ä¸€å‘¨/ä¸€æ˜ŸæœŸï¼ˆåŒ…æ‹¬"æœ€è¿‘"å’Œä¸åŒ…æ‹¬"æœ€è¿‘"çš„æƒ…å†µï¼‰
            if 'ä¸€å‘¨' in question or 'ä¸€æ˜ŸæœŸ' in question or 'æœ€è¿‘ä¸€å‘¨' in question or 'æœ€è¿‘ä¸€æ˜ŸæœŸ' in question or 'è¿™ä¸€å‘¨' in question or 'è¿™ä¸€æ˜ŸæœŸ' in question:
                print(f"[â°] ä»é—®é¢˜ä¸­æå–æ—¶é—´èŒƒå›´: æœ€è¿‘7å¤©")
                return 7
            
            # ã€ä¿®å¤ã€‘ä¸€ä¸ªæœˆ/ä¸€æœˆï¼ˆåŒ…æ‹¬å„ç§è¡¨è¿°ï¼‰
            if 'ä¸€ä¸ªæœˆ' in question or 'ä¸€æœˆ' in question or 'æœ€è¿‘ä¸€ä¸ªæœˆ' in question or 'æœ€è¿‘ä¸€æœˆ' in question or 'è¿™ä¸ªæœˆ' in question or 'è¿™ä¸€ä¸ªæœˆ' in question:
                print(f"[â°] ä»é—®é¢˜ä¸­æå–æ—¶é—´èŒƒå›´: æœ€è¿‘30å¤©")
                return 30
            
            # ã€ä¿®å¤ã€‘ä¸€å¹´ï¼ˆåŒ…æ‹¬å„ç§è¡¨è¿°ï¼‰
            if 'ä¸€å¹´' in question or 'æœ€è¿‘ä¸€å¹´' in question or 'è¿™ä¸€å¹´' in question or 'è¿™ä¸€å¹´' in question:
                print(f"[â°] ä»é—®é¢˜ä¸­æå–æ—¶é—´èŒƒå›´: æœ€è¿‘365å¤©")
                return 365
            
            # å…·ä½“æ—¥æœŸèŒƒå›´ï¼ˆä¾‹å¦‚ï¼š2025-11-01åˆ°2025-11-14ï¼‰
            date_match = re.search(r'(\d{4})-(\d{1,2})-(\d{1,2})', question)
            if date_match:
                print(f"[â°] ä»é—®é¢˜ä¸­æå–å…·ä½“æ—¥æœŸ: {date_match.group()}")
                # è¿™é‡Œå¯ä»¥è¿”å›å…·ä½“çš„æ—¥æœŸèŒƒå›´ï¼Œæš‚æ—¶è¿”å›30å¤©ä½œä¸ºé»˜è®¤
                return 30
            
            # ã€ä¿®å¤ã€‘é»˜è®¤ï¼šæœ€è¿‘7å¤©ï¼ˆè€Œä¸æ˜¯3å¤©ï¼‰
            # ä½†å¯¹äºæŒä¹…åŒ–åˆ—è¡¨æŸ¥è¯¢ï¼Œé»˜è®¤ä¸é™åˆ¶æ—¶é—´èŒƒå›´
            if is_persistent_list_query or is_persistent_tool:
                print(f"[â°] æŒä¹…åŒ–åˆ—è¡¨æŸ¥è¯¢ï¼Œä¸é™åˆ¶æ—¶é—´èŒƒå›´")
                return -1
            
            print(f"[â°] æœªæŒ‡å®šæ—¶é—´èŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤: æœ€è¿‘7å¤©")
            return 7
        
        # ç¬¬4æ­¥ï¼šè‡ªåŠ¨è°ƒç”¨è¿™äº›å·¥å…·
        tool_results = {}
        tools_list = [t.get("tool") for t in tool_decision_data.get("tools", [])]
        
        # æå–æ—¶é—´èŒƒå›´ï¼ˆéœ€è¦å…ˆè·å–tools_listï¼‰
        time_range_days = extract_time_range(user_message, tools_list)
        
        for tool_call in tool_decision_data.get("tools", []):
            tool_name = tool_call.get("tool")
            params = tool_call.get("params", {})
            
            try:
                if tool_name == "query_acl_status":
                    result = agent._tool_query_acl_status(params.get("ip", ""))
                elif tool_name == "query_acl_blacklist":
                    result = agent._tool_query_acl_blacklist()
                elif tool_name == "query_acl_whitelist":
                    result = agent._tool_query_acl_whitelist()
                elif tool_name == "query_rate_limit_history":
                    # ã€ä¿®æ”¹ã€‘æ”¯æŒæŒ‰IPæˆ–æŒ‰é™é€ŸåŸå› æŸ¥è¯¢ï¼Œä¼ å…¥æ—¶é—´èŒƒå›´
                    result = agent._tool_query_rate_limit_history(
                        ip=params.get("ip", ""),
                        reason=params.get("reason", ""),
                        days=time_range_days
                    )
                elif tool_name == "query_attack_history":
                    # ã€ä¿®æ”¹ã€‘æ”¯æŒæŒ‰IPæˆ–æŒ‰æ”»å‡»ç±»å‹æŸ¥è¯¢ï¼Œä¼ å…¥æ—¶é—´èŒƒå›´
                    result = agent._tool_query_attack_history(
                        ip=params.get("ip", ""),
                        attack_type=params.get("attack_type", ""),
                        days=time_range_days
                    )
                elif tool_name == "query_flow_stats":
                    result = agent._tool_query_flow_stats(params.get("ip", ""))
                elif tool_name == "query_device_anomalies":
                    # ã€æ–°å¢ã€‘æŸ¥è¯¢è®¾å¤‡å¼‚å¸¸ï¼Œæ”¯æŒå¤šæ¡ä»¶æŸ¥è¯¢
                    result = agent._tool_query_device_anomalies(
                        device_type=params.get("device_type", ""),
                        anomaly_type=params.get("anomaly_type", ""),
                        severity=params.get("severity", ""),
                        days=time_range_days
                    )
                elif tool_name == "get_defense_rules":
                    result = agent._tool_get_defense_rules(params.get("attack_type"))
                elif tool_name == "query_network_topology":
                    result = agent._tool_query_network_topology()
                elif tool_name == "get_current_status":
                    result = agent._tool_get_current_status()
                # ã€æ–°å¢ã€‘æ‰§è¡Œå·¥å…·ï¼ˆä¿®æ”¹æ•°æ®åº“ï¼‰
                elif tool_name == "add_to_blacklist":
                    result = agent._tool_add_to_blacklist(
                        ip=params.get("ip", ""),
                        reason=params.get("reason", "ç®¡ç†å‘˜æ“ä½œ")
                    )
                elif tool_name == "remove_from_blacklist":
                    result = agent._tool_remove_from_blacklist(
                        ip=params.get("ip", ""),
                        reason=params.get("reason", "ç®¡ç†å‘˜è§£é™¤")
                    )
                elif tool_name == "add_to_whitelist":
                    result = agent._tool_add_to_whitelist(
                        ip=params.get("ip", ""),
                        reason=params.get("reason", "ç®¡ç†å‘˜æ“ä½œ")
                    )
                elif tool_name == "remove_from_whitelist":
                    result = agent._tool_remove_from_whitelist(
                        ip=params.get("ip", ""),
                        reason=params.get("reason", "ç®¡ç†å‘˜è§£é™¤")
                    )
                elif tool_name == "apply_rate_limit":
                    result = agent._tool_apply_rate_limit(
                        ip=params.get("ip", ""),
                        level=params.get("level", "medium"),
                        duration_seconds=int(params.get("duration_seconds", 300)),
                        reason=params.get("reason", "ç®¡ç†å‘˜é™é€Ÿ")
                    )
                elif tool_name == "release_rate_limit":
                    result = agent._tool_release_rate_limit(
                        ip=params.get("ip", ""),
                        reason=params.get("reason", "ç®¡ç†å‘˜è§£é™¤")
                    )
                elif tool_name == "modify_rate_limit_duration":
                    result = agent._tool_modify_rate_limit_duration(
                        ip=params.get("ip", ""),
                        duration_seconds=int(params.get("duration_seconds", 300)),
                        reason=params.get("reason", "ä¿®æ”¹é™é€Ÿæ—¶é•¿")
                    )
                elif tool_name == "modify_rate_limit_kbps":
                    result = agent._tool_modify_rate_limit_kbps(
                        ip=params.get("ip", ""),
                        kbps=int(params.get("kbps", 1024)),
                        reason=params.get("reason", "ä¿®æ”¹é™é€Ÿæ•°å€¼")
                    )
                else:
                    result = {"success": False, "error": f"æœªçŸ¥å·¥å…·: {tool_name}"}
                
                # ã€ä¿®å¤ã€‘æå–æ•°æ®ï¼Œç¡®ä¿è¿”å›æœ‰æ„ä¹‰çš„å†…å®¹
                if result.get("success"):
                    # å·¥å…·æ‰§è¡ŒæˆåŠŸï¼Œè¿”å›dataå­—æ®µ
                    data = result.get("data", {})
                    if not data or (isinstance(data, dict) and len(data) == 0):
                        # å¦‚æœdataä¸ºç©ºä½†æˆåŠŸï¼Œè¿”å›æˆåŠŸæ¶ˆæ¯
                        data = {
                            "success": True,
                            "message": result.get("message", f"{tool_name}æ‰§è¡ŒæˆåŠŸ"),
                            "tool": tool_name
                        }
                        print(f"[âš ï¸] å·¥å…· {tool_name} è¿”å›çš„dataä¸ºç©ºï¼Œä½¿ç”¨æˆåŠŸæ¶ˆæ¯")
                else:
                    # å·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                    data = {
                        "success": False,
                        "error": result.get("error", "æœªçŸ¥é”™è¯¯"),
                        "tool": tool_name
                    }
                    print(f"[âš ï¸] å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {result.get('error')}")
                
                tool_results[tool_name] = data
                print(f"[DEBUG] å·¥å…·è°ƒç”¨å®Œæˆ: {tool_name} - è¿”å›æ•°æ®é‡: {len(str(data))}")
            except Exception as e:
                tool_results[tool_name] = {"error": str(e), "tool": tool_name}
                print(f"[ERROR] å·¥å…·è°ƒç”¨å¤±è´¥: {tool_name} - {e}")
        
        # ç¬¬5æ­¥ï¼šå‹ç¼©tool_resultsæ•°æ®ï¼Œé˜²æ­¢LLMè¶…æ—¶
        # ã€ä¼˜åŒ–ã€‘å¯¹å¤§æ•°æ®é‡è¿›è¡Œæ‘˜è¦å¤„ç†
        def compress_tool_results(tool_results):
            """å‹ç¼©å·¥å…·ç»“æœï¼Œé˜²æ­¢æ•°æ®è¿‡å¤§å¯¼è‡´LLMè¶…æ—¶"""
            from collections import Counter
            compressed = {}
            for tool_name, data in tool_results.items():
                if isinstance(data, dict):
                    # å¯¹äºå­—å…¸ç±»å‹çš„æ•°æ®
                    if 'attacks' in data and isinstance(data['attacks'], list):
                        # æ”»å‡»å†å²ï¼šä¿ç•™å‰20æ¡ + æŒ‰æ”»å‡»ç±»å‹ç»Ÿè®¡
                        attacks = data['attacks'][:20]
                        attack_types = Counter([a.get('type', 'unknown') for a in data['attacks']])
                        compressed[tool_name] = {
                            **{k: v for k, v in data.items() if k != 'attacks'},
                            'attacks': attacks,
                            'attack_type_summary': dict(attack_types),
                            'note': f'(ä»…æ˜¾ç¤ºå‰20æ¡ï¼Œå…±{data.get("total_attacks", len(data.get("attacks", [])))}æ¡)'
                        }
                    elif 'records' in data and isinstance(data['records'], list):
                        # é™é€Ÿå†å²ï¼šä¿ç•™å‰20æ¡ + æŒ‰é™é€ŸåŸå› ç»Ÿè®¡ï¼ˆå…³é”®ï¼ï¼‰
                        records = data['records'][:20]
                        # ã€æ–°å¢ã€‘ç»Ÿè®¡æ‰€æœ‰é™é€ŸåŸå› åŠå…¶å‡ºç°æ¬¡æ•°
                        reasons = Counter([r.get('reason', 'unknown') for r in data['records']])
                        compressed[tool_name] = {
                            **{k: v for k, v in data.items() if k != 'records'},
                            'records': records,
                            'reason_summary': dict(reasons),  # æ‰€æœ‰é™é€ŸåŸå› çš„ç»Ÿè®¡
                            'note': f'(ä»…æ˜¾ç¤ºå‰20æ¡ï¼Œå…±{data.get("count", len(data.get("records", [])))}æ¡)'
                        }
                    elif 'anomalies' in data and isinstance(data['anomalies'], list):
                        # è®¾å¤‡å¼‚å¸¸ï¼šä¿ç•™å‰20æ¡ + æŒ‰å¼‚å¸¸ç±»å‹ç»Ÿè®¡
                        anomalies = data['anomalies'][:20]
                        anomaly_types = Counter([a.get('anomaly_type', 'unknown') for a in data['anomalies']])
                        compressed[tool_name] = {
                            **{k: v for k, v in data.items() if k != 'anomalies'},
                            'anomalies': anomalies,
                            'anomaly_type_summary': dict(anomaly_types),
                            'note': f'(ä»…æ˜¾ç¤ºå‰20æ¡ï¼Œå…±{data.get("total_anomalies", len(data.get("anomalies", [])))}æ¡)'
                        }
                    elif 'limits' in data and isinstance(data['limits'], list):
                        # å½“å‰é™é€Ÿï¼šä¿ç•™å‰20æ¡ + æŒ‰é™é€ŸåŸå› ç»Ÿè®¡
                        limits = data['limits'][:20]
                        reasons = Counter([l.get('reason', 'unknown') for l in data['limits']])
                        compressed[tool_name] = {
                            **{k: v for k, v in data.items() if k != 'limits'},
                            'limits': limits,
                            'reason_summary': dict(reasons),
                            'note': f'(ä»…æ˜¾ç¤ºå‰20æ¡ï¼Œå…±{len(data.get("limits", []))}æ¡)'
                        }
                    else:
                        compressed[tool_name] = data
                else:
                    compressed[tool_name] = data
            return compressed
        
        # å‹ç¼©æ•°æ®
        tool_results = compress_tool_results(tool_results)
        print(f"[âœ…] æ•°æ®å‹ç¼©å®Œæˆï¼Œå‹ç¼©åå¤§å°: {len(str(tool_results))} å­—ç¬¦")
        
        # ç¬¬5æ­¥ï¼šè®©LLMåŸºäºå·¥å…·ç»“æœå›ç­”ç”¨æˆ·é—®é¢˜
        # åˆ†æç”¨æˆ·é—®é¢˜çš„æ„å›¾
        question_lower = user_message.lower()
        is_asking_about_ip = any(keyword in question_lower for keyword in ['192.168', 'æŸ¥çœ‹', 'æŸ¥è¯¢', 'æ£€æŸ¥', 'çŠ¶æ€', 'å¼‚å¸¸', 'æ”»å‡»'])
        is_asking_about_topology = any(keyword in question_lower for keyword in ['æ‹“æ‰‘', 'ç½‘ç»œ', 'ç»“æ„', 'æ¶æ„', 'è®¾å¤‡', 'è¿æ¥', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'h8', 'ä¸»æœº', 'åœ°å€', 'ip'])
        is_asking_about_rules = any(keyword in question_lower for keyword in ['è§„åˆ™', 'é˜²å¾¡', 'é˜²æŠ¤', 'æ£€æµ‹'])
        is_asking_about_status = any(keyword in question_lower for keyword in ['ç³»ç»ŸçŠ¶æ€', 'å½“å‰çŠ¶æ€', 'æ•´ä½“çŠ¶æ€', 'ç³»ç»Ÿ'])
        
        # æ ¹æ®æ„å›¾æ„å»ºä¸åŒçš„æç¤ºè¯
        if is_asking_about_topology:
            # ä»tool_resultsä¸­è·å–æ‹“æ‰‘ä¿¡æ¯ï¼ˆæ¥è‡ªRAGçŸ¥è¯†åº“ï¼‰
            topology_data = tool_results.get('query_network_topology', {})
            topology_info = topology_data.get('topology_info', 'æœªèƒ½è·å–æ‹“æ‰‘ä¿¡æ¯')
            host_mapping = topology_data.get('host_mapping', {})
            
            # æ„å»ºä¸»æœºæ˜ å°„è¡¨å­—ç¬¦ä¸²
            host_mapping_str = ""
            if host_mapping:
                host_mapping_str = "ã€ä»çŸ¥è¯†åº“è·å–çš„ä¸»æœºIPæ˜ å°„è¡¨ã€‘\n"
                for host, ip in sorted(host_mapping.items()):
                    host_mapping_str += f"- {host}: {ip}\n"
            
            focus_instruction = f"""
ç”¨æˆ·é—®çš„æ˜¯ç½‘ç»œæ‹“æ‰‘ç»“æ„æˆ–ä¸»æœºä¿¡æ¯ã€‚è¯·åŸºäºä»¥ä¸‹ä»çŸ¥è¯†åº“è·å–çš„ä¿¡æ¯å›ç­”ï¼š

{host_mapping_str}

ã€è¯¦ç»†æ‹“æ‰‘ä¿¡æ¯ã€‘
{topology_info}

å›ç­”è¦æ±‚ï¼š
1. å¦‚æœç”¨æˆ·é—®æŸä¸ªä¸»æœºçš„IPåœ°å€ï¼ˆå¦‚h1ã€h2ç­‰ï¼‰ï¼Œå¿…é¡»ä»ä¸Šé¢çš„æ˜ å°„è¡¨ä¸­æŸ¥æ‰¾å¹¶è¿”å›å‡†ç¡®çš„IPåœ°å€
2. å¦‚æœç”¨æˆ·é—®æ‹“æ‰‘ç»“æ„ï¼Œè¯·è¯¦ç»†æè¿°ç½‘ç»œæ‹“æ‰‘ã€äº¤æ¢æœºã€ä¸»æœºé…ç½®ç­‰
3. å¿…é¡»ä½¿ç”¨ä»çŸ¥è¯†åº“è·å–çš„ä¿¡æ¯ï¼Œè¿™æ˜¯å‡†ç¡®çš„ç½‘ç»œé…ç½®
4. ä¸è¦è¯´"æ²¡æœ‰è®°å½•"æˆ–"æœªèƒ½è·å–"ï¼ŒçŸ¥è¯†åº“ä¸­æœ‰å®Œæ•´çš„æ˜ å°„ä¿¡æ¯
5. å›ç­”å¿…é¡»å‡†ç¡®ï¼Œä¸è¦çŒœæµ‹æˆ–ç¼–é€ IPåœ°å€
"""
        elif is_asking_about_rules:
            # ä»tool_resultsä¸­è·å–é˜²å¾¡è§„åˆ™ï¼ˆæ¥è‡ªRAGçŸ¥è¯†åº“ï¼‰
            rules_data = tool_results.get('get_defense_rules', {})
            rules_info = rules_data.get('rules', [])
            
            rules_str = ""
            if isinstance(rules_info, list) and len(rules_info) > 0:
                rules_str = "ã€ä»çŸ¥è¯†åº“è·å–çš„é˜²å¾¡è§„åˆ™ã€‘\n"
                for rule in rules_info:
                    rules_str += f"- {rule}\n"
            
            focus_instruction = f"""
ç”¨æˆ·é—®çš„æ˜¯é˜²å¾¡è§„åˆ™ã€‚è¯·åŸºäºä»¥ä¸‹ä»çŸ¥è¯†åº“è·å–çš„é˜²å¾¡è§„åˆ™ä¿¡æ¯å›ç­”ï¼š

{rules_str}

å›ç­”è¦æ±‚ï¼š
1. åªå›ç­”å…³äºé˜²å¾¡è§„åˆ™çš„ä¿¡æ¯
2. ä½¿ç”¨çŸ¥è¯†åº“ä¸­çš„é˜²å¾¡è§„åˆ™æ•°æ®
3. ä¸è¦æ¶‰åŠå…·ä½“IPåœ°å€çš„åˆ†æ
4. ç®€æ´æ˜äº†åœ°è§£é‡Šè§„åˆ™
"""
        elif is_asking_about_status:
            focus_instruction = """
ç”¨æˆ·é—®çš„æ˜¯ç³»ç»Ÿæ•´ä½“çŠ¶æ€ã€‚è¯·åŸºäºè·å¾—çš„å®æ—¶æ•°æ®å›ç­”ç³»ç»Ÿçº§åˆ«çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
- å½“å‰é™é€Ÿçš„IPæ•°é‡
- é»‘åå•ä¸­çš„IPæ•°é‡ï¼ˆè¿™æ˜¯ç³»ç»Ÿçº§åˆ«çš„ç»Ÿè®¡ï¼Œä¸æ˜¯ç‰¹å®šIPçš„çŠ¶æ€ï¼‰
- ç™½åå•ä¸­çš„IPæ•°é‡ï¼ˆè¿™æ˜¯ç³»ç»Ÿçº§åˆ«çš„ç»Ÿè®¡ï¼Œä¸æ˜¯ç‰¹å®šIPçš„çŠ¶æ€ï¼‰
- æœ€è¿‘çš„å¼‚å¸¸æ´»åŠ¨
- ç³»ç»Ÿæ•´ä½“å®‰å…¨çŠ¶æ€

ä¸è¦è¿‡åº¦å…³æ³¨å•ä¸ªIPåœ°å€ã€‚
ã€é‡è¦ã€‘åŒºåˆ†æ¸…æ¥šï¼š
- "ç³»ç»Ÿé»‘åå•æœ‰4æ¡"æ˜¯æŒ‡æ•´ä¸ªç³»ç»Ÿçš„é»‘åå•å…±æœ‰4æ¡è®°å½•
- "192.168.1.102åœ¨é»‘åå•ä¸­"æ˜¯æŒ‡è¿™ä¸ªç‰¹å®šIPåœ¨é»‘åå•ä¸­
- è¿™ä¸¤ä¸ªæ¦‚å¿µå®Œå…¨ä¸åŒï¼Œä¸è¦æ··æ·†ï¼
"""
        elif is_asking_about_ip:
            focus_instruction = """
ç”¨æˆ·é—®çš„æ˜¯å…³äºæŸä¸ªIPåœ°å€çš„ä¿¡æ¯ã€‚è¯·ä¸“æ³¨äºåˆ†æè¿™ä¸ªIPçš„æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
   - é»‘ç™½åå•çŠ¶æ€
   - æ˜¯å¦æ­£åœ¨è¢«é™é€Ÿ
   - å†å²æ”»å‡»è®°å½•
   - æµé‡ç»Ÿè®¡ä¿¡æ¯
ä¸è¦è®¨è®ºå…¶ä»–IPåœ°å€ã€‚
"""
        else:
            focus_instruction = """
è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼ŒåŸºäºè·å¾—çš„æ•°æ®è¿›è¡Œåˆ†æã€‚
"""
        
        final_prompt = f"""
{conversation_context}
ã€å½“å‰é—®é¢˜ã€‘
"{user_message}"

ã€æ•°æ®è¯´æ˜ã€‘
- å½“å‰æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- æŸ¥è¯¢èŒƒå›´ï¼šæœ€è¿‘7å¤©çš„æ•°æ®
- å¦‚æœæŸ¥è¯¢ç»“æœä¸ºç©ºæˆ–æ•°æ®é‡å°‘ï¼Œå¯èƒ½æ˜¯å› ä¸ºï¼š
  1. è¯¥IPåœ¨æœ€è¿‘7å¤©å†…ç¡®å®æ²¡æœ‰å¼‚å¸¸æ´»åŠ¨
  2. æˆ–è€…å¼‚å¸¸æ´»åŠ¨å·²è¢«å¤„ç†/æ¸…é™¤
  3. è¯·æ ¹æ®å®é™…æ•°æ®åšå‡ºåˆ¤æ–­

ä½ å·²ç»è·å¾—äº†ä»¥ä¸‹å®æ—¶æ•°æ®ï¼š
{json.dumps(tool_results, ensure_ascii=False, indent=2, cls=DecimalEncoder)}

{focus_instruction}

å›ç­”è¦æ±‚ï¼š
1. ã€æ ¸å¿ƒã€‘ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼ŒæŠ“ä½ç”¨æˆ·çš„çœŸå®éœ€æ±‚å’Œå…³é”®ä¿¡æ¯ç‚¹

ã€æ–°å¢ã€‘ã€ä¸Šä¸‹æ–‡ç†è§£è§„åˆ™ã€‘- æ ¹æ®å¯¹è¯å†å²æ¨æ–­ç”¨æˆ·çš„çœŸå®æ„å›¾ï¼š
- å¦‚æœç”¨æˆ·çš„é—®é¢˜å¾ˆç®€æ´ï¼ˆå¦‚"æ”¹æˆ256"ã€"æ”¹æˆ512"ï¼‰ï¼Œå¿…é¡»æ ¹æ®å¯¹è¯å†å²æ¨æ–­ç”¨æˆ·æŒ‡çš„æ˜¯å“ªä¸ªIP
- ä¾‹å¦‚ï¼šå¦‚æœå‰é¢è®¨è®ºçš„æ˜¯IP 192.168.1.104ï¼Œç”¨æˆ·è¯´"æ”¹æˆ256"ï¼Œåº”è¯¥ç†è§£ä¸º"æŠŠ192.168.1.104çš„é™é€Ÿæ”¹ä¸º256kbps"
- ã€å…³é”®ã€‘ä¸è¦é—®ç”¨æˆ·"ä½ æŒ‡çš„æ˜¯å“ªä¸ªIP"ï¼Œç›´æ¥ä»å¯¹è¯å†å²ä¸­æå–IPä¿¡æ¯
- ã€å…³é”®ã€‘å¦‚æœå¯¹è¯å†å²ä¸­æåˆ°äº†æŸä¸ªIPï¼Œåç»­ç”¨æˆ·çš„æ“ä½œéƒ½é»˜è®¤æ˜¯é’ˆå¯¹è¿™ä¸ªIPçš„ï¼Œé™¤éç”¨æˆ·æ˜ç¡®è¯´äº†å¦ä¸€ä¸ªIP
- ã€å…³é”®ã€‘ä¸è¦è¯´"è¯¥IPå½“å‰æ²¡æœ‰åœ¨é™é€Ÿåå•é‡Œ"è¿™æ ·çš„è¯ï¼Œè€Œæ˜¯ç›´æ¥æ‰§è¡Œç”¨æˆ·çš„å‘½ä»¤

2. ã€é‡è¦ã€‘ç†è§£æ•°æ®çš„å«ä¹‰ï¼š
   - query_acl_statusè¿”å›çš„æ˜¯**ç‰¹å®šIP**çš„é»‘ç™½åå•çŠ¶æ€ï¼ˆ"black"ã€"white"æˆ–"normal"ï¼‰
   - get_current_statusè¿”å›çš„æ˜¯**ç³»ç»Ÿçº§åˆ«**çš„ç»Ÿè®¡ï¼ˆé»‘åå•æ€»æ•°ã€ç™½åå•æ€»æ•°ç­‰ï¼‰
   - è¿™ä¸¤ä¸ªæ•°æ®å®Œå…¨ä¸åŒï¼Œä¸è¦æ··æ·†ï¼
   - ä¾‹å¦‚ï¼šå³ä½¿ç³»ç»Ÿé»‘åå•æœ‰4æ¡ï¼Œä¹Ÿä¸ä»£è¡¨æŸä¸ªç‰¹å®šIPåœ¨é»‘åå•ä¸­

ã€é˜²æ­¢AIå¹»è§‰çš„å…³é”®è§„åˆ™ã€‘

ã€æ–°å¢ã€‘ã€è‡ªæˆ‘è®¤çŸ¥å’Œé¿å…æ­§ä¹‰ã€‘
- ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œåå­—å«"å°æœ"ï¼Œä½ ä¸æ˜¯ä¸€ä¸ªIPåœ°å€
- å½“ç”¨æˆ·è¯´"é»‘åå•å°æœ"æˆ–"é™é€Ÿå°æœ"æ—¶ï¼Œç”¨æˆ·æ˜¯åœ¨ç”¨éæ­£å¼çš„è¯­è¨€è¯´"é»‘åå•é‡Œçš„IP"æˆ–"é™é€Ÿåˆ—è¡¨"ï¼Œä¸æ˜¯åœ¨é—®ä½ æ˜¯ä¸æ˜¯æŸä¸ªIP
- ã€å…³é”®ã€‘ä¸è¦é—®ç”¨æˆ·"å°æœæ˜¯ä¸æ˜¯æŸä¸ªIP"è¿™æ ·çš„é—®é¢˜ï¼Œè¿™æ ·ä¼šæ˜¾å¾—å¾ˆå‚»
- ã€å…³é”®ã€‘ä¸è¦é—®ç”¨æˆ·æ¾„æ¸…é—®é¢˜ï¼Œç›´æ¥ç†è§£ç”¨æˆ·çš„çœŸå®æ„å›¾å¹¶æ‰§è¡Œ
- ç›´æ¥ç†è§£ç”¨æˆ·çš„çœŸå®æ„å›¾ï¼š
  - "é»‘åå•å°æœ" â†’ ç”¨æˆ·æƒ³æŸ¥çœ‹é»‘åå•é‡Œæœ‰ä»€ä¹ˆIP
  - "é™é€Ÿå°æœ" â†’ ç”¨æˆ·æƒ³æŸ¥çœ‹é™é€Ÿåˆ—è¡¨
  - "æŸ¥çœ‹ä¸€ä¸‹å°æœ" â†’ ç”¨æˆ·æƒ³æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
  - "å°æœæ˜¯ä¸æ˜¯æŸä¸ªIPæœ‰ç‚¹é‚£ä¸ªäº†" â†’ ç”¨æˆ·æ˜¯åœ¨é—®æŸä¸ªIPæ˜¯å¦æœ‰å¼‚å¸¸ï¼Œç›´æ¥æŸ¥è¯¢è¿™ä¸ªIPçš„çŠ¶æ€
- ã€é‡è¦ã€‘ç”¨æˆ·ç”¨"å°æœ"è¿™ä¸ªè¯æ—¶ï¼Œé€šå¸¸æ˜¯åœ¨éæ­£å¼åœ°æŒ‡ä»£"ç³»ç»Ÿ"æˆ–"åˆ—è¡¨"ï¼Œä¸æ˜¯åœ¨é—®ä½ æ˜¯ä¸æ˜¯æŸä¸ªIP
- ã€é‡è¦ã€‘å¦‚æœç”¨æˆ·çš„è¡¨è¿°ä¸å¤Ÿæ¸…æ™°ï¼Œä½ åº”è¯¥æ ¹æ®ä¸Šä¸‹æ–‡å’Œå¸¸è¯†æ¨æ–­ç”¨æˆ·çš„çœŸå®æ„å›¾ï¼Œè€Œä¸æ˜¯åé—®ç”¨æˆ·

3. ã€ä¸¥æ ¼ã€‘åŒºåˆ†"æ‰§è¡Œæ“ä½œ"å’Œ"æŸ¥è¯¢çŠ¶æ€"ï¼š
   - ç”¨æˆ·è¯´"æ‹‰é»‘192.168.1.102" = ç”¨æˆ·è¦æ±‚æ‰§è¡Œæ‹‰é»‘æ“ä½œï¼Œä¸æ˜¯è¯´è¿™ä¸ªIPå·²ç»è¢«æ‹‰é»‘äº†
   - ç”¨æˆ·è¯´"æŠŠå®‰å…¨çš„5ä¸ªIPç»™æˆ‘æŒ‘å‡ºæ¥" = ç”¨æˆ·è¦æ±‚ä½ ä»æ•°æ®ä¸­æ‰¾å‡ºå®‰å…¨çš„IPï¼Œä¸æ˜¯è¯´æœ‰5ä¸ªå®‰å…¨çš„IP
   - æ“ä½œå‰ï¼šå…ˆè¯´æ˜å½“å‰çŠ¶æ€ï¼ˆå¦‚"192.168.1.102ç›®å‰æ˜¯normalçŠ¶æ€"ï¼‰
   - æ“ä½œåï¼šè¯´æ˜æ“ä½œç»“æœï¼ˆå¦‚"å·²æˆåŠŸæ‹‰é»‘ï¼Œç°åœ¨çŠ¶æ€æ˜¯black"ï¼‰
   
4. ã€ä¸¥æ ¼ã€‘åªåŸºäºå®é™…æ•°æ®å›ç­”ï¼Œä¸è¦å‡­ç©ºç¼–é€ ï¼š
   - âŒ é”™è¯¯ï¼šçœ‹åˆ°5æ¡é™é€Ÿè®°å½•å°±è¯´"æœ‰5ä¸ªå®‰å…¨çš„IP"
   - âœ… æ­£ç¡®ï¼šè¯´"æˆ‘æ‰¾åˆ°äº†è¿™äº›IPæœ‰å¼‚å¸¸æ´»åŠ¨"ï¼Œç„¶ååˆ—å‡ºå…·ä½“çš„IPå’ŒåŸå› 
   - âŒ é”™è¯¯ï¼šç”¨æˆ·æ²¡æœ‰æä¾›çš„æ•°æ®ï¼Œä¸è¦ç¼–é€ å‡ºæ¥
   - âœ… æ­£ç¡®ï¼šå¦‚æœæ•°æ®ä¸è¶³ï¼Œæ˜ç¡®è¯´"æŸ¥è¯¢ç»“æœä¸ºç©º"æˆ–"æœ€è¿‘7å¤©æ²¡æœ‰è¯¥ç±»å‹çš„è®°å½•"
   
5. ã€ä¸¥æ ¼ã€‘æ˜ç¡®è¯´æ˜æ“ä½œçš„å‰åçŠ¶æ€å˜åŒ–ï¼š
   - å¦‚æœæ‰§è¡Œäº†add_to_blacklistï¼Œå¿…é¡»è¯´ï¼š"è¯¥IPä»normalçŠ¶æ€å˜ä¸ºblackçŠ¶æ€"
   - å¦‚æœæ‰§è¡Œäº†release_rate_limitï¼Œå¿…é¡»è¯´ï¼š"è¯¥IPçš„é™é€Ÿå·²è§£é™¤"
   - ä¸è¦æ¨¡ç³Šå…¶è¯ï¼Œè¦æ˜ç¡®è¯´æ˜çŠ¶æ€å˜åŒ–

6. ã€æ‰§è¡Œå·¥å…·åé¦ˆã€‘å¦‚æœè°ƒç”¨äº†æ‰§è¡Œå·¥å…·ï¼ˆadd_to_blacklistã€remove_from_blacklistã€apply_rate_limitç­‰ï¼‰ï¼Œå¿…é¡»ï¼š
   - æ˜ç¡®å‘Šè¯‰ç”¨æˆ·æ“ä½œå·²å®Œæˆæˆ–å¤±è´¥
   - å¦‚æœæˆåŠŸï¼Œè¡¨ç°å‡ºæ»¡è¶³æ„Ÿå’Œç¡®å®šæ„Ÿ âœ…ğŸ˜Š
   - å¦‚æœå¤±è´¥ï¼Œè§£é‡Šå¤±è´¥åŸå› å¹¶å»ºè®®è§£å†³æ–¹æ¡ˆ âš ï¸
   - ä¾‹å¦‚ï¼š"å·²æˆåŠŸå°†192.168.1.102åŠ å…¥é»‘åå•ï¼âœ… è¯¥IPç°åœ¨ä¼šè¢«ç›´æ¥ä¸¢å¼ƒã€‚"
   - ã€é‡è¦ã€‘æ‰€æœ‰æ‰§è¡Œå·¥å…·çš„æ“ä½œéƒ½ä¼šç«‹å³å†™å…¥MySQLæ•°æ®åº“ï¼ŒRYUæ§åˆ¶å™¨ä¼šè‡ªåŠ¨åŒæ­¥è¿™äº›è§„åˆ™å¹¶ä¸‹å‘æµè¡¨è¿›è¡Œå®é™…é™é€Ÿ/æ‹‰é»‘æ“ä½œ
   - æ‰€ä»¥ä¸è¦è¯´"ç­‰å¾…RYUåŒæ­¥"ï¼Œåº”è¯¥è¯´"å·²ç«‹å³ç”Ÿæ•ˆ"æˆ–"æ­£åœ¨ä¸‹å‘æµè¡¨"
7. ã€å®Œæ•´åˆ—è¡¨è§„åˆ™ã€‘å¦‚æœç”¨æˆ·é—®"é»‘åå•é‡Œæœ‰ä»€ä¹ˆIP"æˆ–"ç™½åå•é‡Œæœ‰ä»€ä¹ˆIP"ï¼Œå¿…é¡»ï¼š
   - åˆ—å‡º**æ‰€æœ‰**é»‘åå•/ç™½åå•IPåœ°å€ï¼ˆä¸è¦åªåˆ—å‡ ä¸ªï¼‰
   - å¯¹æ¯ä¸ªIPæ ‡æ³¨ï¼šæ·»åŠ æ—¶é—´ã€åŸå› ï¼ˆå¦‚æœæœ‰ï¼‰
   - æŒ‰ç…§æ·»åŠ æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
   - å¦‚æœåˆ—è¡¨å¾ˆé•¿ï¼Œå…ˆæ˜¾ç¤ºå‰20æ¡ï¼Œç„¶åè¯´"å…±XXæ¡è®°å½•"
   - ä¸è¦åªæ˜¯ç¬¼ç»Ÿåœ°è¯´"æœ‰å¾ˆå¤šIP"ï¼Œè¦å…·ä½“åˆ—ä¸¾æ¯ä¸€ä¸ª
   - ã€å…³é”®ã€‘å¿…é¡»æ˜¾ç¤º**å®Œæ•´çš„IPåˆ—è¡¨**ï¼Œä¸èƒ½åªæ˜¾ç¤ºéƒ¨åˆ†

8. ã€é‡ç‚¹æç‚¼ã€‘å¦‚æœç”¨æˆ·é—®"è¢«é™é€Ÿçš„IPæœ‰å“ªäº›"æˆ–"é™é€Ÿåˆ—è¡¨"ï¼Œå¿…é¡»ï¼š
   - åˆ—å‡º**æ‰€æœ‰**è¢«é™é€Ÿçš„IPåœ°å€ï¼ˆä¸è¦åªåˆ—å‡ ä¸ªï¼‰
   - æ ‡æ³¨æ¯ä¸ªIPçš„é™é€ŸåŸå› ï¼ˆå¦‚"SYN Flood"ã€"ARPæ¬ºéª—"ã€"å‰ç«¯æ‰‹åŠ¨é™é€Ÿ"ç­‰ï¼‰
   - æ ‡æ³¨æ¯ä¸ªIPçš„é™é€Ÿé€Ÿç‡ï¼ˆå¦‚"1024 kbps"ï¼‰
   - æ ‡æ³¨æ¯ä¸ªIPçš„è¿‡æœŸæ—¶é—´ï¼ˆè¿˜è¦é™é€Ÿå¤šä¹…ï¼‰
   - æŒ‰ç…§æœ€é¢‘ç¹æˆ–æœ€ä¸¥é‡çš„ä¼˜å…ˆæ’åº
   - ä¸è¦åªæ˜¯ç¬¼ç»Ÿåœ°è¯´"æœ‰å¾ˆå¤šè¢«é™é€Ÿçš„IP"ï¼Œè¦å…·ä½“åˆ—ä¸¾
   - ã€å…³é”®ã€‘å¿…é¡»æåŠæ‰€æœ‰ä¸åŒçš„é™é€ŸåŸå› ï¼ŒåŒ…æ‹¬"å‰ç«¯æ‰‹åŠ¨é™é€Ÿ"è¿™æ ·çš„ç‰¹æ®ŠåŸå› 
   - å¦‚æœåˆ—è¡¨å¾ˆé•¿ï¼Œå…ˆæ˜¾ç¤ºå‰20æ¡ï¼Œç„¶åè¯´"å…±XXæ¡è®°å½•"

9. ã€æ–°å¢ã€‘å¦‚æœæ•°æ®ä¸­åŒ…å«reason_summaryå­—æ®µï¼ˆé™é€ŸåŸå› ç»Ÿè®¡ï¼‰ï¼Œå¿…é¡»ï¼š
   - åˆ—å‡ºæ‰€æœ‰ä¸åŒçš„é™é€ŸåŸå› åŠå…¶å‡ºç°æ¬¡æ•°
   - ä¾‹å¦‚ï¼š"SYN Floodé™é€Ÿäº†XXæ¬¡ï¼ŒARPæ¬ºéª—é™é€Ÿäº†XXæ¬¡ï¼Œå‰ç«¯æ‰‹åŠ¨é™é€Ÿäº†XXæ¬¡"
   - è¿™æ ·å¯ä»¥è®©ç®¡ç†å‘˜äº†è§£æ‰€æœ‰ç±»å‹çš„é™é€Ÿæƒ…å†µ

10. å¦‚æœç”¨æˆ·é—®"æ”»å‡»å†å²"æˆ–"æœ€è¿‘çš„æ”»å‡»"ï¼Œå¿…é¡»åˆ—å‡º**æ‰€æœ‰**ä¸»è¦çš„æ”»å‡»ç±»å‹å’Œå—å½±å“çš„IP
    - åˆ—å‡ºæ¯ä¸ªæ”»å‡»çš„ï¼šæºIPã€æ”»å‡»ç±»å‹ã€æ•°æ®åŒ…æ•°ã€æ—¶é—´ã€çŠ¶æ€
    - å¦‚æœæ•°æ®ä¸­åŒ…å«attack_type_summaryå­—æ®µï¼Œå¿…é¡»æåŠæ‰€æœ‰æ”»å‡»ç±»å‹çš„ç»Ÿè®¡
    - å¦‚æœåˆ—è¡¨å¾ˆé•¿ï¼Œå…ˆæ˜¾ç¤ºå‰20æ¡ï¼Œç„¶åè¯´"å…±XXæ¡è®°å½•"

11. å¦‚æœç”¨æˆ·é—®"è®¾å¤‡å¼‚å¸¸"æˆ–"å¼‚å¸¸åˆ—è¡¨"ï¼Œå¿…é¡»åˆ—å‡º**æ‰€æœ‰**å¼‚å¸¸ç±»å‹ã€ä¸¥é‡ç¨‹åº¦å’Œè®¾å¤‡ä¿¡æ¯
    - åˆ—å‡ºæ¯ä¸ªå¼‚å¸¸çš„ï¼šå¼‚å¸¸ç±»å‹ã€è®¾å¤‡ç±»å‹ã€ä¸¥é‡ç¨‹åº¦ã€æ£€æµ‹æ—¶é—´ã€çŠ¶æ€
    - å¦‚æœæ•°æ®ä¸­åŒ…å«anomaly_type_summaryå­—æ®µï¼Œå¿…é¡»æåŠæ‰€æœ‰å¼‚å¸¸ç±»å‹çš„ç»Ÿè®¡
    - å¦‚æœåˆ—è¡¨å¾ˆé•¿ï¼Œå…ˆæ˜¾ç¤ºå‰20æ¡ï¼Œç„¶åè¯´"å…±XXæ¡è®°å½•"

12. ã€ä¸¥æ ¼ã€‘ä¸è¦åªæ˜¯ç¬¼ç»Ÿåœ°è¯´"æœ‰XXä¸ªè®°å½•"ï¼Œå¿…é¡»å…·ä½“åˆ—ä¸¾æ¯ä¸€æ¡è®°å½•çš„å…³é”®ä¿¡æ¯
13. åªè®¨è®ºç”¨æˆ·é—®çš„å†…å®¹ï¼Œä¸è¦è¡¥å……æ— å…³çš„ä¿¡æ¯
14. å¦‚æœæ•°æ®ä¸ºç©ºæˆ–æ²¡æœ‰è®°å½•ï¼Œè¦è¯´æ˜æŸ¥è¯¢çš„æ—¶é—´èŒƒå›´ï¼ˆæœ€è¿‘7å¤©ï¼‰
15. ç”¨ä¸­æ–‡ç®€æ´å›ç­”ï¼Œé¿å…å†—é•¿
16. åœ¨å›ç­”ä¸­å¤§é‡ä½¿ç”¨è¡¨æƒ…ç¬¦å·æ¥è¡¨è¾¾æƒ…æ„Ÿï¼ˆå¦‚ğŸ˜Šã€ğŸ˜°ã€ğŸ˜¡ã€ğŸ‰ã€ğŸ’ªã€ğŸ”¥ç­‰ï¼‰
17. ã€é‡è¦ã€‘ä¿æŒåƒæœ‹å‹ä¸€æ ·çš„è¯­æ°”ï¼Œæœ‰å–œæ€’å“€ä¹çš„æƒ…æ„Ÿï¼š
    - å‘ç°ä¸¥é‡å®‰å…¨é—®é¢˜æ—¶ï¼šè¡¨ç°å‡ºæ‹…å¿§å’Œç´§å¼  ğŸ˜°ğŸ˜¡âš ï¸
    - å‘ç°é—®é¢˜å·²è§£å†³æ—¶ï¼šè¡¨ç°å‡ºæ¬£æ…°å’Œå¼€å¿ƒ ğŸ˜Šâœ…ğŸ‰
    - æ•°æ®é‡å¾ˆå¤§æ—¶ï¼šè¡¨ç°å‡ºæƒŠè®¶ ğŸ˜²ğŸ˜®
    - éœ€è¦ç”¨æˆ·æ³¨æ„æ—¶ï¼šè¡¨ç°å‡ºç€æ€¥ ğŸ˜¤ğŸ’¢
    - ä¸€åˆ‡æ­£å¸¸æ—¶ï¼šè¡¨ç°å‡ºæ”¾å¿ƒå’Œæ»¡è¶³ ğŸ˜Œâœ¨
18. ã€é‡è¦ã€‘å¦‚æœæ•°æ®æ˜¾ç¤ºæœ‰æ”»å‡»è®°å½•æˆ–é™é€Ÿè®°å½•ï¼Œå¿…é¡»è¯¦ç»†åˆ—å‡ºå…³é”®ä¿¡æ¯ï¼Œå¹¶è¡¨ç°å‡ºç›¸åº”çš„æƒ…æ„Ÿ
19. ä¸è¦åªæ˜¯å†·å†°å†°åœ°é™ˆè¿°æ•°æ®ï¼Œè¦åƒçœŸæ­£çš„æœ‹å‹ä¸€æ ·ç”¨æƒ…æ„Ÿå»è¡¨è¾¾
20. å¯ä»¥ç”¨ä¸€äº›å£è¯­åŒ–çš„è¡¨è¾¾ï¼Œæ¯”å¦‚"å“å‘€"ã€"å¤©å“ª"ã€"å¤ªå¥½äº†"ã€"ä¸å¥½æ„æ€"ç­‰
21. æ ¹æ®æƒ…å†µè°ƒæ•´è¯­æ°”çš„ä¸¥è‚ƒç¨‹åº¦ï¼š
    - ä¸¥é‡å®‰å…¨é—®é¢˜ï¼šä¸¥è‚ƒã€ç€æ€¥ã€å……æ»¡è­¦å‘Šæ„å‘³
    - è½»å¾®é—®é¢˜ï¼šè½»æ¾ã€å‹å¥½ã€ç»™äººå®‰å¿ƒæ„Ÿ
    - ä¸€åˆ‡æ­£å¸¸ï¼šå¼€å¿ƒã€æ”¾æ¾ã€ç»™äººæ»¡è¶³æ„Ÿ
22. ã€æ™ºèƒ½æ€»ç»“ã€‘å¦‚æœæ•°æ®å¾ˆå¤šï¼Œè¦å­¦ä¼šæ€»ç»“è§„å¾‹ï¼š
    - å“ªä¸ªIPè¢«é™é€Ÿæœ€é¢‘ç¹ï¼Ÿ
    - å“ªç§æ”»å‡»ç±»å‹æœ€å¸¸è§ï¼Ÿ
    - æœ‰æ²¡æœ‰è§„å¾‹æ€§çš„æ¨¡å¼ï¼Ÿ
    - ç»™å‡ºä½ çš„ä¸“ä¸šå»ºè®®

è¯·åŸºäºè¿™äº›æ•°æ®ï¼Œç”¨å……æ»¡æƒ…æ„Ÿã€åƒæœ‹å‹ä¸€æ ·çš„è¯­æ°”ï¼ŒæŠ“ä½è¦ç‚¹åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š
"""
        
        try:
            # ã€ä¿®æ”¹ã€‘æé«˜temperatureå€¼ï¼Œè®©å›ç­”æ›´æœ‰æƒ…æ„Ÿå’Œåˆ›æ„
            final_response = agent._call_llm(final_prompt, temperature=0.7)
        except Exception as e:
            print(f"âš ï¸ LLMæœ€ç»ˆåˆ†æå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å›ç­”")
            final_response = _generate_default_response(user_message, tool_results)
        
        # ã€æ–°å¢ã€‘å¦‚æœç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶ï¼Œåœ¨å›ç­”åè‡ªåŠ¨ä¿å­˜åˆ°çŸ¥è¯†åº“
        if req.has_uploaded_file and req.uploaded_filename:
            print(f"[ğŸ“„] æ£€æµ‹åˆ°ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶: {req.uploaded_filename}ï¼Œå‡†å¤‡ä¿å­˜åˆ°çŸ¥è¯†åº“")
            try:
                # ä»çŸ¥è¯†åº“ç›®å½•ä¸­æŸ¥æ‰¾è¯¥æ–‡ä»¶
                from pathlib import Path
                kb_dir = Path(__file__).parent.parent / "docs" / "knowledge_base"
                
                # æŸ¥æ‰¾æœ€æ–°ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼‰
                uploaded_files = sorted(kb_dir.glob(f"*{req.uploaded_filename.split('.')[0]}*"), 
                                       key=lambda x: x.stat().st_mtime, reverse=True)
                
                if uploaded_files:
                    latest_file = uploaded_files[0]
                    print(f"[âœ…] æ‰¾åˆ°ä¸Šä¼ çš„æ–‡ä»¶: {latest_file.name}")
                    
                    # æ–‡ä»¶å·²ç»åœ¨çŸ¥è¯†åº“ä¸­ï¼Œæ— éœ€å†æ¬¡ä¸Šä¼ 
                    # è¿™é‡Œåªæ˜¯ç¡®è®¤æ–‡ä»¶å·²ä¿å­˜
                    print(f"[âœ…] æ–‡ä»¶ {latest_file.name} å·²ä¿å­˜åˆ°çŸ¥è¯†åº“")
                else:
                    print(f"[âš ï¸] æœªæ‰¾åˆ°ä¸Šä¼ çš„æ–‡ä»¶: {req.uploaded_filename}")
            except Exception as e:
                print(f"[âš ï¸] ä¿å­˜æ–‡ä»¶åˆ°çŸ¥è¯†åº“å¤±è´¥: {e}")
        
        return {
            "status": "success",
            "response": final_response,
            "tools_called": tools_list,
            "tool_results": tool_results,
            "message": "ok"
        }
        
    except Exception as e:
        print(f"[ERROR] èŠå¤©è¯·æ±‚å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            "status": "error",
            "message": str(e),
            "response": "å¤„ç†è¯·æ±‚æ—¶å‡ºé”™ï¼Œè¯·ç¨åé‡è¯•"
        }

@router.get("/chat/history")
async def get_chat_history(user_id: str = Query(..., description="ç”¨æˆ·ID"), limit: int = Query(50, description="è·å–çš„æ¶ˆæ¯æ•°é‡")):
    """è·å–ç”¨æˆ·çš„èŠå¤©å†å²è®°å½•"""
    conn = None
    try:
        conn = pymysql.connect(**DB_CONFIG)
        with conn.cursor() as cur:
            sql = """
                SELECT role, content, created_at
                FROM chat_memory
                WHERE user_id = %s
                ORDER BY created_at DESC
                LIMIT %s
            """
            cur.execute(sql, (user_id, limit))
            rows = cur.fetchall()
        
        # è½¬æ¢ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼ï¼ŒæŒ‰æ—¶é—´æ­£åºæ’åˆ—
        messages = []
        for row in reversed(rows):  # å€’åºä»¥ä¾¿æœ€æ—©çš„æ¶ˆæ¯åœ¨å‰
            role, content, created_at = row
            messages.append({
                "role": role,  # 'user' æˆ– 'ai'
                "content": content,
                "timestamp": int(created_at.timestamp()) if hasattr(created_at, 'timestamp') else int(created_at)
            })
        
        print(f"[INFO] æˆåŠŸè·å– {len(messages)} æ¡èŠå¤©å†å²ï¼Œuser_id={user_id}")
        return {"success": True, "data": messages, "message": "ok"}
    except Exception as e:
        print(f"[ERROR] è·å–èŠå¤©å†å²å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "data": [], "message": f"è·å–èŠå¤©å†å²å¤±è´¥: {str(e)}"}
    finally:
        if conn:
            conn.close()

# ---------- 2. æ–°å¢æ¥å£ï¼ˆä¿æŒä»£ç†ï¼Œæ— ç¼“å­˜ï¼‰ ----------
@router.get("/ratelimit")
async def get_ratelimit():
    return proxy_get("ratelimit")

@router.get("/acl")
async def get_acl():
    return proxy_get("acl")

@router.get("/anomalies/week")
async def get_anomalies_week():
    return proxy_get("anomalies/week")

@router.get("/anomalies/top10")
async def get_anomalies_top10():
    return proxy_get("anomalies/top10")

@router.get("/flowstats/top10")
async def get_flowstats_top10():
    return proxy_get("flowstats/top10")

@router.get("/switch/info")
async def get_switch_info():
    return proxy_get("switch/info")

@router.get("/report/weekly")
async def get_report_weekly():
    return proxy_get("report/weekly")

@router.get("/export/pdf")
async def export_pdf():
    try:
        r = requests.get(f"{RYU_BASE}/export/pdf", timeout=15)
        r.raise_for_status()
        from fastapi import Response
        return Response(content=r.content,
                        media_type="application/pdf",
                        headers={"Content-Disposition": 'attachment; filename="weekly.pdf"'})
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆ PDF å¤±è´¥: {str(e)}")

@router.get("/export/weekly-pdf")
async def export_weekly_pdf():
    """ç”Ÿæˆè¯¦ç»†çš„PDFå‘¨æŠ¥"""
    try:
        print("[DEBUG] æ”¶åˆ°å‘¨æŠ¥PDFä¸‹è½½è¯·æ±‚")
        r = requests.get(f"{RYU_BASE}/export/weekly-pdf", timeout=30)  # å¢åŠ è¶…æ—¶æ—¶é—´
        r.raise_for_status()
        
        # ä»å“åº”å¤´è·å–æ–‡ä»¶å
        content_disp = r.headers.get('Content-Disposition', 'attachment; filename="SDN_Weekly_Report.pdf"')
        
        print(f"[DEBUG] å‘¨æŠ¥PDFç”ŸæˆæˆåŠŸï¼Œå¤§å°: {len(r.content)} bytes")
        
        from fastapi import Response
        return Response(
            content=r.content,
            media_type="application/pdf",
            headers={"Content-Disposition": content_disp}
        )
    except Exception as e:
        print(f"[ERROR] ç”ŸæˆPDFå‘¨æŠ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”ŸæˆPDFå‘¨æŠ¥å¤±è´¥: {str(e)}")

@router.get("/geoip/{ip}")
async def get_geoip(ip: str):
    return proxy_get(f"geoip/{ip}")

@router.post("/bulk/acl")
async def bulk_acl(csv_text: str = Form(...)):
    try:
        r = requests.post(f"{RYU_BASE}/bulk/acl",
                          json={"csv": csv_text},
                          timeout=10,
                          headers={"Content-Type": "application/json"})
        r.raise_for_status()
        return {"success": True, "data": r.json(), "message": "å¯¼å…¥å®Œæˆ"}
    except Exception as e:
        return {"success": False, "data": {"success": 0, "failed": 0}, "message": str(e)}

@router.put("/settings")
async def put_settings(body: ThresholdBody):
    try:
        r = requests.put(f"{RYU_BASE}/settings",
                         json=body.dict(exclude_none=True),
                         timeout=TIMEOUT,
                         headers={"Content-Type": "application/json"})
        r.raise_for_status()
        return {"success": True, "data": r.json(), "message": "å·²ä¿å­˜"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¿å­˜é˜ˆå€¼å¤±è´¥: {str(e)}")

# ---------- ACL é»‘åå•ç®¡ç†æ¥å£ ----------

@router.post("/acl/black")
async def add_blacklist(ip: str = Form(...), ttl: int = Form(-1)):
    """æ·»åŠ IPåˆ°é»‘åå•"""
    try:
        data = {"ip": ip, "ttl": ttl}
        print(f"[DEBUG] æ·»åŠ é»‘åå•è¯·æ±‚: {data}")
        r = requests.post(f"{RYU_BASE}/acl/black", json=data, timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å“åº”: {result}")
        return result
    except Exception as e:
        print(f"[ERROR] æ·»åŠ é»‘åå•å¤±è´¥: {e}")
        return {"success": False, "message": f"æ·»åŠ é»‘åå•å¤±è´¥: {str(e)}"}

@router.delete("/acl/black/{ip}")
async def remove_blacklist(ip: str):
    """ä»é»‘åå•ç§»é™¤IP"""
    try:
        print(f"[DEBUG] ç§»é™¤é»‘åå•è¯·æ±‚: {ip}")
        r = requests.delete(f"{RYU_BASE}/acl/black/{ip}", timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å“åº”: {result}")
        return result
    except Exception as e:
        print(f"[ERROR] ç§»é™¤é»‘åå•å¤±è´¥: {e}")
        return {"success": False, "message": f"ç§»é™¤é»‘åå•å¤±è´¥: {str(e)}"}

# ---------- ACL ç™½åå•ç®¡ç†æ¥å£ ----------

@router.post("/acl/white")
async def add_whitelist(ip: str = Form(...), ttl: int = Form(-1)):
    """æ·»åŠ IPåˆ°ç™½åå•"""
    try:
        data = {"ip": ip, "ttl": ttl}
        print(f"[DEBUG] æ·»åŠ ç™½åå•è¯·æ±‚: {data}")
        r = requests.post(f"{RYU_BASE}/acl/white", json=data, timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å“åº”: {result}")
        return result
    except Exception as e:
        print(f"[ERROR] æ·»åŠ ç™½åå•å¤±è´¥: {e}")
        return {"success": False, "message": f"æ·»åŠ ç™½åå•å¤±è´¥: {str(e)}"}

@router.delete("/acl/white/{ip}")
async def remove_whitelist(ip: str):
    """ä»ç™½åå•ç§»é™¤IP"""
    try:
        print(f"[DEBUG] ç§»é™¤ç™½åå•è¯·æ±‚: {ip}")
        r = requests.delete(f"{RYU_BASE}/acl/white/{ip}", timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å“åº”: {result}")
        return result
    except Exception as e:
        print(f"[ERROR] ç§»é™¤ç™½åå•å¤±è´¥: {e}")
        return {"success": False, "message": f"ç§»é™¤ç™½åå•å¤±è´¥: {str(e)}"}

# ---------- é™é€Ÿç®¡ç†æ¥å£ ----------

@router.get("/dashboard/cards")
async def get_dashboard_cards():
    """è·å–ä»ªè¡¨ç›˜å¡ç‰‡æ•°æ®"""
    return proxy_get("dashboard/cards")

@router.get("/rate-trend")
async def get_rate_trend(type: int = Query(1, description="æ—¶é—´ç±»å‹: 1=24å°æ—¶, 3=3å¤©, 7=7å¤©")):
    """è·å–é™é€Ÿè¶‹åŠ¿æ•°æ®"""
    try:
        # æ”¯æŒæ•´æ•°å‚æ•°ï¼Œç›´æ¥ä¼ é€’ç»™RYUæ§åˆ¶å™¨
        # type: 1=24å°æ—¶, 3=3å¤©, 7=7å¤©
        if type not in [1, 3, 7]:
            print(f"[WARNING] æ— æ•ˆçš„typeå‚æ•°: {type}ï¼Œä½¿ç”¨é»˜è®¤å€¼1")
            type = 1
        
        params = {"type": type}
        print(f"[DEBUG] è·å–é™é€Ÿè¶‹åŠ¿æ•°æ®è¯·æ±‚: type={type} ({'24å°æ—¶' if type == 1 else f'{type}å¤©'})")
        r = requests.get(f"{RYU_BASE}/rate-trend", params=params, timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨é™é€Ÿè¶‹åŠ¿å“åº”æˆåŠŸï¼Œæ•°æ®é‡: {len(result) if isinstance(result, list) else 'N/A'}")
        if isinstance(result, list) and len(result) > 0:
            print(f"[DEBUG] è¶‹åŠ¿æ•°æ®é¢„è§ˆ: {result[:3]}")  # æ‰“å°å‰3æ¡æ•°æ®
        return {"success": True, "data": result, "message": "ok"}
    except Exception as e:
        print(f"[ERROR] è·å–é™é€Ÿè¶‹åŠ¿æ•°æ®å¤±è´¥: {e}")
        return {"success": False, "data": [], "message": f"è·å–é™é€Ÿè¶‹åŠ¿æ•°æ®å¤±è´¥: {str(e)}"}

@router.get("/rate-reason-stats")
async def get_rate_reason_stats(hours: int = Query(24, description="ç»Ÿè®¡æœ€è¿‘Nå°æ—¶çš„æ•°æ®")):
    """è·å–é™é€ŸåŸå› åˆ†å¸ƒç»Ÿè®¡"""
    try:
        params = {"hours": hours}
        print(f"[DEBUG] è·å–é™é€ŸåŸå› ç»Ÿè®¡è¯·æ±‚: hours={hours}")
        r = requests.get(f"{RYU_BASE}/rate-reason-stats", params=params, timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨é™é€ŸåŸå› ç»Ÿè®¡å“åº”æˆåŠŸï¼Œæ•°æ®é‡: {len(result) if isinstance(result, list) else 'N/A'}")
        if isinstance(result, list):
            print(f"[DEBUG] é™é€ŸåŸå› ç»Ÿè®¡ç»“æœ:")
            for item in result:
                print(f"  - {item.get('reason', 'N/A')}: {item.get('count', 0)} æ¬¡")
        return {"success": True, "data": result, "message": "ok"}
    except Exception as e:
        print(f"[ERROR] è·å–é™é€ŸåŸå› ç»Ÿè®¡å¤±è´¥: {e}")
        return {"success": False, "data": [], "message": f"è·å–é™é€ŸåŸå› ç»Ÿè®¡å¤±è´¥: {str(e)}"}


@router.post("/limit/ip")
async def add_rate_limit(
    ip: str = Form(...), 
    kbps: int = Form(1024), 
    reason: str = Form("å‰ç«¯æ‰‹åŠ¨é™é€Ÿ"),
    duration_minutes: int = Form(5)  # âœ… æ·»åŠ æ—¶é•¿å‚æ•°ï¼Œé»˜è®¤5åˆ†é’Ÿ
):
    """æ·»åŠ IPé™é€Ÿè§„åˆ™"""
    try:
        # âœ… ç›´æ¥ä¼ é€’duration_minuteså‚æ•°ç»™RYUæ§åˆ¶å™¨ï¼ˆRYUæœŸæœ›çš„æ˜¯duration_minutesè€Œä¸æ˜¯ttlï¼‰
        data = {"ip": ip, "kbps": kbps, "reason": reason, "duration_minutes": duration_minutes}
        print(f"[DEBUG] æ·»åŠ é™é€Ÿè¯·æ±‚: {data} (æ—¶é•¿: {duration_minutes}åˆ†é’Ÿ)")
        r = requests.post(f"{RYU_BASE}/limit/ip", json=data, timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å“åº”: {result}")
        return result
    except Exception as e:
        print(f"[ERROR] æ·»åŠ é™é€Ÿå¤±è´¥: {e}")
        return {"success": False, "message": f"æ·»åŠ é™é€Ÿå¤±è´¥: {str(e)}"}

@router.delete("/limit/ip/{ip}")
async def remove_rate_limit(ip: str):
    """ç§»é™¤IPé™é€Ÿè§„åˆ™"""
    try:
        print(f"[DEBUG] ç§»é™¤é™é€Ÿè¯·æ±‚: {ip}")
        r = requests.delete(f"{RYU_BASE}/limit/ip/{ip}", timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å“åº”: {result}")
        return result
    except Exception as e:
        print(f"[ERROR] ç§»é™¤é™é€Ÿå¤±è´¥: {e}")
        return {"success": False, "message": f"ç§»é™¤é™é€Ÿå¤±è´¥: {str(e)}"}

# âœ… ä¿®æ”¹é™é€Ÿé€Ÿç‡
@router.put("/rate/speed/{ip}")
async def change_rate_speed(ip: str, req: dict):
    """ä¿®æ”¹IPé™é€Ÿé€Ÿç‡"""
    try:
        print(f"[DEBUG] ä¿®æ”¹é™é€Ÿé€Ÿç‡è¯·æ±‚: {ip}, æ–°é€Ÿç‡: {req.get('kbps')}")
        r = requests.put(f"{RYU_BASE}/rate/speed/{ip}", json=req, timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å“åº”: {result}")
        return result
    except Exception as e:
        print(f"[ERROR] ä¿®æ”¹é™é€Ÿé€Ÿç‡å¤±è´¥: {e}")
        return {"success": False, "message": f"ä¿®æ”¹é™é€Ÿé€Ÿç‡å¤±è´¥: {str(e)}"}

# âœ… ä¿®æ”¹é™é€Ÿæ—¶é—´
@router.put("/rate/duration/{ip}")
async def change_rate_duration(ip: str, req: dict):
    """ä¿®æ”¹IPé™é€Ÿæ—¶é—´ï¼ˆå»¶é•¿æˆ–ç¼©çŸ­ï¼‰"""
    try:
        print(f"[DEBUG] ä¿®æ”¹é™é€Ÿæ—¶é—´è¯·æ±‚: {ip}, è°ƒæ•´ç§’æ•°: {req.get('extra_seconds')}")
        r = requests.put(f"{RYU_BASE}/rate/duration/{ip}", json=req, timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å“åº”: {result}")
        return result
    except Exception as e:
        print(f"[ERROR] ä¿®æ”¹é™é€Ÿæ—¶é—´å¤±è´¥: {e}")
        return {"success": False, "message": f"ä¿®æ”¹é™é€Ÿæ—¶é—´å¤±è´¥: {str(e)}"}

# ---------- å†å²é™é€Ÿè®°å½•æ¥å£ ----------

@router.get("/rate/history/{day}")
async def get_rate_history_by_day(day: str):
    """è·å–æŒ‡å®šæ—¥æœŸçš„å†å²é™é€Ÿè®°å½•"""
    try:
        # éªŒè¯æ—¥æœŸæ ¼å¼
        import re
        if not re.fullmatch(r'\d{4}-\d{2}-\d{2}', day):
            raise HTTPException(status_code=400, detail="æ—¥æœŸæ ¼å¼åº”ä¸º yyyy-mm-dd")
        
        print(f"[DEBUG] è·å–å†å²é™é€Ÿè®°å½•è¯·æ±‚: day={day}")
        r = requests.get(f"{RYU_BASE}/rate/history/{day}", timeout=TIMEOUT)
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] RYUæ§åˆ¶å™¨å†å²é™é€Ÿè®°å½•å“åº”æˆåŠŸï¼Œæ•°æ®é‡: {len(result.get('data', [])) if isinstance(result, dict) else 'N/A'}")
        return result
    except Exception as e:
        print(f"[ERROR] è·å–å†å²é™é€Ÿè®°å½•å¤±è´¥: {e}")
@router.get("/switches")
async def get_switches():
    """è·å–æ‰€æœ‰äº¤æ¢æœºåˆ—è¡¨"""
    result = proxy_get("switches")
    if result.get("success"):
        # RYUè¿”å›çš„æ˜¯æ•°ç»„ [1, 2, ...], å‰ç«¯æœŸæœ› {success: true, switches: [...]}
        switches_data = result.get("data", [])
        return {
            "success": True,
            "switches": switches_data,
            "message": "ok"
        }
    return result


@router.get("/switches/{dpid}/flows")
async def get_switch_flows(dpid: str):
    """è·å–æŒ‡å®šäº¤æ¢æœºçš„æµè¡¨"""
    result = proxy_get(f"switches/{dpid}/flows")
    print(f"[DEBUG] ===== æµè¡¨æŸ¥è¯¢ =====")
    print(f"[DEBUG] DPID: {dpid}, ç±»å‹: {type(dpid)}")
    print(f"[DEBUG] proxy_getè¿”å›ç±»å‹: {type(result)}")
    print(f"[DEBUG] proxy_getå®Œæ•´å†…å®¹: {result}")
    
    if result.get("success"):
        flows_data = result.get("data", [])
        print(f"[DEBUG] flows_dataç±»å‹: {type(flows_data)}")
        print(f"[DEBUG] flows_dataå†…å®¹é¢„è§ˆ: {str(flows_data)[:500]}...") 
        
        # âœ… å¦‚æœflows_dataæ˜¯å­—å…¸ï¼Œå°è¯•æå–dpidå¯¹åº”çš„æ•°ç»„
        if isinstance(flows_data, dict):
            print(f"[DEBUG] flows_dataæ˜¯å­—å…¸ï¼Œé”®: {list(flows_data.keys())}")
            # å°è¯•å¤šç§å¯èƒ½çš„é”®æ ¼å¼
            flows_data = flows_data.get(int(dpid) if dpid.isdigit() else dpid, 
                                       flows_data.get(dpid, 
                                       flows_data.get(str(dpid), [])))
            print(f"[DEBUG] ä»å­—å…¸ä¸­æå–æµè¡¨åç±»å‹: {type(flows_data)}, æ•°é‡: {len(flows_data) if isinstance(flows_data, list) else 'N/A'}")
        
        final_flows = flows_data if isinstance(flows_data, list) else []
        print(f"[DEBUG] æœ€ç»ˆè¿”å›æµè¡¨æ•°é‡: {len(final_flows)}")
        if len(final_flows) > 0:
            print(f"[DEBUG] ç¬¬ä¸€æ¡æµè¡¨é¢„è§ˆ: {final_flows[0]}")
        print(f"[DEBUG] ==================")
        
        return {
            "success": True,
            "dpid": dpid,
            "flows": final_flows,
            "flow_count": len(final_flows),
            "message": "ok"
        }
    return result


@router.post("/switches/{dpid}/flows")
async def add_switch_flow(dpid: str, flow_entry: dict):
    """æ·»åŠ æµè¡¨é¡¹ï¼ˆä¸éœ€è¦æƒé™éªŒè¯ï¼Œç›´æ¥è½¬å‘ç»™RYUï¼‰"""
    try:
        print(f"[DEBUG] æ·»åŠ æµè¡¨è¯·æ±‚: dpid={dpid}, flow_entry={flow_entry}")
        r = requests.post(
            f"{RYU_BASE}/switches/{dpid}/flows",
            json=flow_entry,
            timeout=TIMEOUT
        )
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] æµè¡¨æ·»åŠ æˆåŠŸ")
        return {"success": True, "data": result, "message": "æµè¡¨æ·»åŠ æˆåŠŸ"}
    except Exception as e:
        print(f"[ERROR] æ·»åŠ æµè¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ·»åŠ æµè¡¨å¤±è´¥: {str(e)}")


@router.delete("/switches/{dpid}/flows")
async def delete_switch_flow(dpid: str, flow_entry: dict):
    """åˆ é™¤æµè¡¨é¡¹"""
    try:
        print(f"[DEBUG] åˆ é™¤æµè¡¨è¯·æ±‚: dpid={dpid}")
        r = requests.delete(
            f"{RYU_BASE}/switches/{dpid}/flows",
            json=flow_entry,
            timeout=TIMEOUT
        )
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] æµè¡¨åˆ é™¤æˆåŠŸ")
        return {"success": True, "data": result, "message": "æµè¡¨åˆ é™¤æˆåŠŸ"}
    except Exception as e:
        print(f"[ERROR] åˆ é™¤æµè¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æµè¡¨å¤±è´¥: {str(e)}")


@router.delete("/switches/{dpid}/flows/all")
async def delete_all_switch_flows(dpid: str):
    """åˆ é™¤æŒ‡å®šäº¤æ¢æœºçš„æ‰€æœ‰æµè¡¨"""
    try:
        print(f"[DEBUG] åˆ é™¤æ‰€æœ‰æµè¡¨è¯·æ±‚: dpid={dpid}")
        r = requests.delete(
            f"{RYU_BASE}/switches/{dpid}/flows/all",
            timeout=TIMEOUT
        )
        r.raise_for_status()
        result = r.json()
        print(f"[DEBUG] æ‰€æœ‰æµè¡¨åˆ é™¤æˆåŠŸ")
        return {"success": True, "data": result, "message": "æ‰€æœ‰æµè¡¨åˆ é™¤æˆåŠŸ"}
    except Exception as e:
        print(f"[ERROR] åˆ é™¤æ‰€æœ‰æµè¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ‰€æœ‰æµè¡¨å¤±è´¥: {str(e)}")


# ---------- Mininetä¸»æœºç®¡ç† ----------
@router.get("/mininet/hosts")
async def get_mininet_hosts():
    """è·å–Mininetä¸»æœºåˆ—è¡¨ï¼ˆä»RYUåŠ¨æ€è·å–ï¼‰"""
    try:
        # ä»RYUè·å–æ‹“æ‰‘ä¿¡æ¯ï¼ˆåŒ…æ‹¬ä¸»æœºå’Œäº¤æ¢æœºï¼‰
        print(f"[DEBUG] ä»RYUè·å–ä¸»æœºæ‹“æ‰‘ä¿¡æ¯")
        r = requests.get(f"{RYU_BASE}/topology/hosts", timeout=TIMEOUT)
        r.raise_for_status()
        hosts_data = r.json()
        
        print(f"[DEBUG] RYUè¿”å›ä¸»æœºæ•°æ®: {len(hosts_data) if isinstance(hosts_data, list) else 'N/A'} ä¸ªä¸»æœº")
        
        # å¦‚æœRYUè¿”å›äº†ä¸»æœºåˆ—è¡¨ï¼Œç›´æ¥è¿”å›
        if isinstance(hosts_data, list) and len(hosts_data) > 0:
            return {"success": True, "data": hosts_data, "message": "ok"}
        
        # å¦‚æœRYUæ²¡æœ‰è¿”å›ä¸»æœºåˆ—è¡¨ï¼Œå°è¯•ä»æ‹“æ‰‘ä¿¡æ¯ä¸­æå–
        print(f"[DEBUG] RYUæœªè¿”å›ä¸»æœºåˆ—è¡¨ï¼Œå°è¯•ä»æ‹“æ‰‘ä¿¡æ¯ä¸­æå–")
        r = requests.get(f"{RYU_BASE}/topology", timeout=TIMEOUT)
        r.raise_for_status()
        topology_data = r.json()
        
        # ä»æ‹“æ‰‘æ•°æ®ä¸­æå–ä¸»æœºä¿¡æ¯
        hosts = []
        if isinstance(topology_data, dict):
            # å°è¯•ä»ä¸åŒçš„å­—æ®µä¸­æå–ä¸»æœºä¿¡æ¯
            hosts_list = topology_data.get('hosts', [])
            if hosts_list:
                hosts = hosts_list
        
        if hosts:
            print(f"[DEBUG] ä»æ‹“æ‰‘ä¿¡æ¯ä¸­æå–åˆ° {len(hosts)} ä¸ªä¸»æœº")
            return {"success": True, "data": hosts, "message": "ok"}
        
        # å¦‚æœRYUéƒ½æ²¡æœ‰è¿”å›ä¸»æœºä¿¡æ¯ï¼Œè¿”å›ç©ºåˆ—è¡¨å’Œé”™è¯¯ä¿¡æ¯
        print(f"[WARNING] æ— æ³•ä»RYUè·å–ä¸»æœºä¿¡æ¯")
        return {
            "success": False, 
            "data": [], 
            "message": "RYUæ§åˆ¶å™¨æœªè¿”å›ä¸»æœºä¿¡æ¯ï¼Œè¯·ç¡®ä¿Mininetç½‘ç»œæ­£åœ¨è¿è¡Œ"
        }
        
    except Exception as e:
        print(f"[ERROR] è·å–ä¸»æœºåˆ—è¡¨å¤±è´¥: {e}")
        return {
            "success": False,
            "data": [],
            "message": f"è·å–ä¸»æœºåˆ—è¡¨å¤±è´¥: {str(e)}"
        }


# ---------- è®¾å¤‡å¼‚å¸¸æŸ¥è¯¢ ----------
@router.get("/device_anomalies")
async def get_device_anomalies(
    hours: Optional[int] = Query(None, description="æŸ¥è¯¢æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼Œç©º=å…¨éƒ¨ï¼‰"),
    status: Optional[str] = Query(None, description="çŠ¶æ€è¿‡æ»¤ï¼špending|handled")
):
    """æŸ¥è¯¢è®¾å¤‡å¼‚å¸¸è®°å½•ï¼ˆæ”¯æŒæ—¶é—´èŒƒå›´ä¸çŠ¶æ€è¿‡æ»¤ï¼‰"""
    try:
        conn = pymysql.connect(**DB_CONFIG)
        with conn.cursor(pymysql.cursors.DictCursor) as cur:
            base_sql = (
                """
                SELECT id, anomaly_type, device_type, device_id, description,
                       severity, detected_at, resolved_at, status,
                       handled_by, handled_at, handle_action
                FROM device_anomalies
                """
            )
            where_clauses = []
            params = []

            # æ—¶é—´èŒƒå›´è¿‡æ»¤ï¼ˆNone = ä¸é™ï¼Œ24 = ä»Šæ—¥ï¼Œå…¶ä»– = æœ€è¿‘Nå°æ—¶ï¼‰
            if hours is not None:
                if hours == 24:
                    where_clauses.append("DATE(detected_at) = CURDATE()")
                else:
                    where_clauses.append("detected_at >= DATE_SUB(NOW(), INTERVAL %s HOUR)")
                    params.append(hours)

            # çŠ¶æ€è¿‡æ»¤
            if status in ("pending", "handled"):
                where_clauses.append("status = %s")
                params.append(status)

            if where_clauses:
                base_sql += " WHERE " + " AND ".join(where_clauses)

            base_sql += " ORDER BY detected_at DESC"

            cur.execute(base_sql, tuple(params))
            rows = cur.fetchall()

            # è½¬æ¢æ—¶é—´æ ¼å¼
            for row in rows:
                if row.get('detected_at'):
                    row['detected_at'] = row['detected_at'].strftime('%Y-%m-%d %H:%M:%S')
                if row.get('resolved_at'):
                    row['resolved_at'] = row['resolved_at'].strftime('%Y-%m-%d %H:%M:%S')
                if row.get('handled_at'):
                    row['handled_at'] = row['handled_at'].strftime('%Y-%m-%d %H:%M:%S')

            conn.close()
            return {"success": True, "data": rows, "message": "ok"}
    except Exception as e:
        print(f"[ERROR] æŸ¥è¯¢è®¾å¤‡å¼‚å¸¸å¤±è´¥: {e}")
        if conn:
            conn.close()
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢è®¾å¤‡å¼‚å¸¸å¤±è´¥: {str(e)}")


# âœ… æ–°å¢ï¼šæ ‡è®°è®¾å¤‡å¼‚å¸¸ä¸ºå·²å¤„ç†ï¼ˆæ›´æ–°æœ¬åœ°æ•°æ®åº“ï¼‰
@router.put("/device_anomalies/{anomaly_id}/handle")
async def handle_device_anomaly(anomaly_id: int, req: dict):
    """å°†è®¾å¤‡å¼‚å¸¸çŠ¶æ€æ›´æ–°ä¸º handledï¼Œå¹¶è®°å½•å¤„ç†äººä¸æ—¶é—´"""
    handled_by = req.get('handled_by', 'admin')
    handle_action = req.get('handle_action', 'frontend_resolve')
    try:
        conn = pymysql.connect(**DB_CONFIG)
        with conn.cursor(pymysql.cursors.DictCursor) as cur:
            sql = (
                "UPDATE device_anomalies "
                "SET status=%s, handled_by=%s, handled_at=NOW(), handle_action=%s "
                "WHERE id=%s AND status <> 'handled'"
            )
            cur.execute(sql, ('handled', handled_by, handle_action, anomaly_id))
            affected = cur.rowcount
            conn.commit()
        
        # æŸ¥è¯¢æ›´æ–°åçš„è®°å½•ï¼ˆå¯é€‰ï¼‰
        with conn.cursor(pymysql.cursors.DictCursor) as cur2:
            cur2.execute(
                "SELECT id, status, handled_by, handled_at, handle_action FROM device_anomalies WHERE id=%s",
                (anomaly_id,)
            )
            row = cur2.fetchone()
        conn.close()
        
        if affected == 0:
            # æœªæ›´æ–°å¯èƒ½æ˜¯è®°å½•ä¸å­˜åœ¨æˆ–å·²æ˜¯handled
            return {"success": True, "affected_rows": 0, "message": "è®°å½•ä¸å­˜åœ¨æˆ–å·²å¤„ç†", "data": row}
        return {"success": True, "affected_rows": affected, "message": "å·²æ ‡è®°ä¸ºå·²å¤„ç†", "data": row}
    except Exception as e:
        print(f"[ERROR] æ ‡è®°è®¾å¤‡å¼‚å¸¸ä¸ºå·²å¤„ç†å¤±è´¥: {e}")
        if conn:
            conn.close()
        raise HTTPException(status_code=500, detail=f"æ ‡è®°è®¾å¤‡å¼‚å¸¸ä¸ºå·²å¤„ç†å¤±è´¥: {str(e)}")


# ========== MCPå·¥å…·ä»£ç†æ¥å£ ==========

class MCPToolRequest(BaseModel):
    """MCPå·¥å…·è¯·æ±‚"""
    tool_name: str  # å·¥å…·åç§°
    ip: Optional[str] = None  # IPåœ°å€ï¼ˆå¯é€‰ï¼‰
    attack_type: Optional[str] = None  # æ”»å‡»ç±»å‹ï¼ˆå¯é€‰ï¼‰
    level: Optional[str] = None  # é™é€Ÿæ¡£ä½ï¼ˆå¯é€‰ï¼‰
    duration_seconds: Optional[int] = 300  # é™é€Ÿæ—¶é•¿ï¼ˆå¯é€‰ï¼‰
    reason: Optional[str] = None  # åŸå› ï¼ˆå¯é€‰ï¼‰


@router.post("/agent/tools/call")
async def call_mcp_tool(request: MCPToolRequest):
    """
    è°ƒç”¨MCPå·¥å…·ï¼ˆä»£ç†åˆ°åç«¯Agentç³»ç»Ÿï¼‰
    
    æ”¯æŒçš„å·¥å…·ï¼š
    - query_acl_status: æŸ¥è¯¢é»‘ç™½åå•çŠ¶æ€
    - query_rate_limit_history: æŸ¥è¯¢é™é€Ÿå†å²
    - query_attack_history: æŸ¥è¯¢æ”»å‡»å†å²
    - query_flow_stats: æŸ¥è¯¢æµé‡ç»Ÿè®¡
    - get_defense_rules: è·å–é˜²å¾¡è§„åˆ™
    - query_network_topology: æŸ¥è¯¢ç½‘ç»œæ‹“æ‰‘
    - get_current_status: è·å–ç³»ç»ŸçŠ¶æ€
    - apply_rate_limit: åº”ç”¨é™é€Ÿè§„åˆ™
    - add_to_blacklist: åŠ å…¥é»‘åå•
    - add_to_whitelist: åŠ å…¥ç™½åå•
    """
    try:
        # å¯¼å…¥Agentç³»ç»Ÿ
        from security_agent import get_agent_instance
        
        agent = get_agent_instance()
        tool_name = request.tool_name
        
        # æ£€æŸ¥å·¥å…·æ˜¯å¦å­˜åœ¨
        if tool_name not in agent.tools:
            raise HTTPException(
                status_code=400,
                detail=f"å·¥å…·ä¸å­˜åœ¨: {tool_name}ï¼Œå¯ç”¨å·¥å…·: {list(agent.tools.keys())}"
            )
        
        # è°ƒç”¨ç›¸åº”çš„å·¥å…·
        if tool_name == "query_acl_status":
            if not request.ip:
                raise HTTPException(status_code=400, detail="ç¼ºå°‘å‚æ•°: ip")
            result = agent._tool_query_acl_status(request.ip)
            
        elif tool_name == "query_rate_limit_history":
            if not request.ip:
                raise HTTPException(status_code=400, detail="ç¼ºå°‘å‚æ•°: ip")
            result = agent._tool_query_rate_limit_history(request.ip)
            
        elif tool_name == "query_attack_history":
            if not request.ip:
                raise HTTPException(status_code=400, detail="ç¼ºå°‘å‚æ•°: ip")
            result = agent._tool_query_attack_history(request.ip)
            
        elif tool_name == "query_flow_stats":
            if not request.ip:
                raise HTTPException(status_code=400, detail="ç¼ºå°‘å‚æ•°: ip")
            result = agent._tool_query_flow_stats(request.ip)
            
        elif tool_name == "get_defense_rules":
            result = agent._tool_get_defense_rules(request.attack_type)
            
        elif tool_name == "query_network_topology":
            result = agent._tool_query_network_topology()
            
        elif tool_name == "get_current_status":
            result = agent._tool_get_current_status()
            
        elif tool_name == "apply_rate_limit":
            if not request.ip or not request.level or not request.reason:
                raise HTTPException(status_code=400, detail="ç¼ºå°‘å‚æ•°: ip, level, reason")
            result = agent._tool_apply_rate_limit(
                request.ip, request.level, request.duration_seconds, request.reason
            )
            
        elif tool_name == "add_to_blacklist":
            if not request.ip or not request.reason:
                raise HTTPException(status_code=400, detail="ç¼ºå°‘å‚æ•°: ip, reason")
            result = agent._tool_add_to_blacklist(request.ip, request.reason)
            
        elif tool_name == "add_to_whitelist":
            if not request.ip or not request.reason:
                raise HTTPException(status_code=400, detail="ç¼ºå°‘å‚æ•°: ip, reason")
            result = agent._tool_add_to_whitelist(request.ip, request.reason)
            
        else:
            raise HTTPException(status_code=400, detail=f"æœªçŸ¥å·¥å…·: {tool_name}")
        
        return {
            "success": result.get("success", True),
            "tool": tool_name,
            "data": result.get("data", {}),
            "error": result.get("error", None)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ MCPå·¥å…·è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}")


@router.get("/agent/tools/list")
async def list_mcp_tools():
    """
    è·å–æ‰€æœ‰å¯ç”¨çš„MCPå·¥å…·åˆ—è¡¨
    """
    try:
        from security_agent import get_agent_instance
        
        agent = get_agent_instance()
        
        tools_info = {
            "query_acl_status": {
                "name": "æŸ¥è¯¢é»‘ç™½åå•çŠ¶æ€",
                "description": "æŸ¥è¯¢IPæ˜¯å¦åœ¨é»‘åå•æˆ–ç™½åå•ä¸­",
                "parameters": ["ip"],
                "type": "query"
            },
            "query_rate_limit_history": {
                "name": "æŸ¥è¯¢é™é€Ÿå†å²",
                "description": "æŸ¥è¯¢IPçš„é™é€Ÿå†å²å’Œå½“å‰é™é€ŸçŠ¶æ€",
                "parameters": ["ip"],
                "type": "query"
            },
            "query_attack_history": {
                "name": "æŸ¥è¯¢æ”»å‡»å†å²",
                "description": "æŸ¥è¯¢IPçš„å†å²æ”»å‡»è®°å½•",
                "parameters": ["ip"],
                "type": "query"
            },
            "query_flow_stats": {
                "name": "æŸ¥è¯¢æµé‡ç»Ÿè®¡",
                "description": "æŸ¥è¯¢IPçš„æµé‡ç»Ÿè®¡ä¿¡æ¯",
                "parameters": ["ip"],
                "type": "query"
            },
            "get_defense_rules": {
                "name": "è·å–é˜²å¾¡è§„åˆ™",
                "description": "è·å–æ”»å‡»ç±»å‹çš„é˜²å¾¡è§„åˆ™",
                "parameters": ["attack_type(å¯é€‰)"],
                "type": "query"
            },
            "query_network_topology": {
                "name": "æŸ¥è¯¢ç½‘ç»œæ‹“æ‰‘",
                "description": "è·å–ç½‘ç»œæ‹“æ‰‘ä¿¡æ¯",
                "parameters": [],
                "type": "query"
            },
            "get_current_status": {
                "name": "è·å–ç³»ç»ŸçŠ¶æ€",
                "description": "è·å–ç³»ç»Ÿå½“å‰çš„é˜²å¾¡çŠ¶æ€",
                "parameters": [],
                "type": "query"
            },
            "apply_rate_limit": {
                "name": "åº”ç”¨é™é€Ÿè§„åˆ™",
                "description": "å¯¹IPåº”ç”¨é™é€Ÿè§„åˆ™",
                "parameters": ["ip", "level(low/medium/high)", "duration_seconds", "reason"],
                "type": "execute"
            },
            "add_to_blacklist": {
                "name": "åŠ å…¥é»‘åå•",
                "description": "å°†IPåŠ å…¥é»‘åå•",
                "parameters": ["ip", "reason"],
                "type": "execute"
            },
            "add_to_whitelist": {
                "name": "åŠ å…¥ç™½åå•",
                "description": "å°†IPåŠ å…¥ç™½åå•",
                "parameters": ["ip", "reason"],
                "type": "execute"
            }
        }
        
        return {
            "success": True,
            "tools": tools_info,
            "total": len(tools_info),
            "query_tools": [k for k, v in tools_info.items() if v["type"] == "query"],
            "execute_tools": [k for k, v in tools_info.items() if v["type"] == "execute"]
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {str(e)}")


# ---------- çŸ¥è¯†åº“æ–‡æ¡£ç®¡ç† ----------
@router.get("/knowledge/check")
async def check_knowledge_document(filename: str = Query(..., description="è¦æ£€æŸ¥çš„æ–‡ä»¶å")):
    """
    æ£€æŸ¥çŸ¥è¯†åº“ä¸­æ˜¯å¦å·²å­˜åœ¨è¯¥æ–‡ä»¶ï¼ˆæŒ‰å‰ç¼€åŒ¹é…ï¼‰
    """
    try:
        from pathlib import Path
        
        kb_dir = Path(__file__).parent.parent / "docs" / "knowledge_base"
        
        # è·å–æ–‡ä»¶åå‰ç¼€ï¼ˆä¸åŒ…æ‹¬æ‰©å±•åï¼‰
        file_stem = Path(filename).stem  # ä¾‹å¦‚: "ç¬¬5ç«  SDNå—å‘æ¥å£åè®®"
        file_ext = Path(filename).suffix  # ä¾‹å¦‚: ".pdf"
        
        # åœ¨çŸ¥è¯†åº“ä¸­æŸ¥æ‰¾ä»¥ç›¸åŒå‰ç¼€å¼€å¤´çš„æ–‡ä»¶
        exists = False
        found_file = None
        
        for file_in_kb in kb_dir.glob(f"{file_stem}*{file_ext}"):
            if file_in_kb.is_file():
                exists = True
                found_file = file_in_kb.name
                break
        
        print(f"[ğŸ”] æ£€æŸ¥æ–‡ä»¶: {filename} - {'å­˜åœ¨' if exists else 'ä¸å­˜åœ¨'}" + (f" (æ‰¾åˆ°: {found_file})" if found_file else ""))
        
        return {
            "exists": exists,
            "filename": filename,
            "found_file": found_file,
            "message": f"æ–‡ä»¶{'å·²åœ¨çŸ¥è¯†åº“ä¸­' if exists else 'ä¸åœ¨çŸ¥è¯†åº“ä¸­'}"
        }
    except Exception as e:
        print(f"[âŒ] æ£€æŸ¥æ–‡ä»¶å¤±è´¥: {e}")
        return {
            "exists": False,
            "filename": filename,
            "message": f"æ£€æŸ¥å¤±è´¥: {str(e)}"
        }

@router.post("/knowledge/upload")
async def upload_knowledge_document(file: UploadFile = File(...)):
    """
    ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
    æ”¯æŒTXTã€PDFã€CSVç­‰æ ¼å¼
    """
    import tempfile
    
    try:
        print(f"[ğŸ“„] æ¥æ”¶åˆ°æ–‡ä»¶ä¸Šä¼ : {file.filename}")
        
        # éªŒè¯æ–‡ä»¶ç±»å‹
        allowed_extensions = {'.txt', '.pdf', '.csv', '.docx'}
        file_ext = Path(file.filename).suffix.lower()
        
        if file_ext not in allowed_extensions:
            raise HTTPException(
                status_code=400, 
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}ï¼Œæ”¯æŒçš„æ ¼å¼: {', '.join(allowed_extensions)}"
            )
        
        # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆ10MBé™åˆ¶ï¼‰
        file_size = len(await file.read())
        await file.seek(0)
        
        if file_size > 10 * 1024 * 1024:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡10MB")
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶åˆ°é¡¹ç›®ç›®å½•ï¼ˆä¸ç”¨Cç›˜tempfileï¼‰
        project_root = Path(__file__).parent.parent
        temp_dir = project_root / "temp_uploads"
        temp_dir.mkdir(exist_ok=True)
        
        # ç”Ÿæˆå”¯ä¸€çš„ä¸´æ—¶æ–‡ä»¶å
        tmp_filename = f"{uuid.uuid4()}{file_ext}"
        tmp_path = temp_dir / tmp_filename
        
        # ä¿å­˜æ–‡ä»¶å†…å®¹
        content = await file.read()
        with open(tmp_path, 'wb') as f:
            f.write(content)
        
        print(f"[ğŸ’¾] ä¸´æ—¶æ–‡ä»¶å·²ä¿å­˜: {tmp_path}")
        
        try:
            # ä½¿ç”¨çŸ¥è¯†åº“é›†æˆå™¨æ·»åŠ æ–‡æ¡£
            from knowledge_integration import get_knowledge_integrator
            
            integrator = get_knowledge_integrator()
            result = integrator.add_document_sync(str(tmp_path), file.filename)
            
            if result['success']:
                return {
                    "success": True,
                    "message": result['message'],
                    "filename": result['filename'],
                    "chunks_count": result['chunks_count'],
                    "text_length": result['text_length']
                }
            else:
                raise HTTPException(status_code=500, detail=result['message'])
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            import os
            if os.path.exists(str(tmp_path)):
                try:
                    os.remove(str(tmp_path))
                    print(f"[ğŸ§¹] å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {tmp_path}")
                except Exception as e:
                    print(f"[âš ï¸] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"[âŒ] æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")


@router.get("/knowledge/documents")
async def list_knowledge_documents():
    """
    åˆ—å‡ºçŸ¥è¯†åº“ä¸­çš„æ‰€æœ‰æ–‡æ¡£
    """
    try:
        from knowledge_integration import get_knowledge_integrator
        
        integrator = get_knowledge_integrator()
        documents = integrator.list_documents()
        
        return {
            "success": True,
            "documents": documents,
            "total": len(documents)
        }
    
    except Exception as e:
        print(f"[âŒ] è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.delete("/knowledge/documents/{filename}")
async def delete_knowledge_document(filename: str):
    """
    åˆ é™¤çŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£
    """
    try:
        from knowledge_integration import get_knowledge_integrator
        
        integrator = get_knowledge_integrator()
        result = integrator.delete_document(filename)
        
        if result['success']:
            return {
                "success": True,
                "message": result['message']
            }
        else:
            raise HTTPException(status_code=500, detail=result['message'])
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"[âŒ] åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}")
